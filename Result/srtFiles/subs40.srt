
1
00:00:01.110 --> 00:00:04.130
So far we have seen two versions
of the Dijkstra Algorithm.

2
00:00:05.200 --> 00:00:09.680
Both these versions assume that the edge
weights provided by the network

3
00:00:09.680 --> 00:00:10.850
must be used as is.

4
00:00:11.890 --> 00:00:14.430
Now that can lead to some
interesting problems.

5
00:00:14.430 --> 00:00:16.570
We saw one such problem before.

6
00:00:16.570 --> 00:00:19.810
Remember we were trying to decide
whether we should go from G to D or

7
00:00:19.810 --> 00:00:24.060
from F to E because both options
had the same total weight?

8
00:00:24.060 --> 00:00:26.670
Now had we chosen to go from G to D,

9
00:00:26.670 --> 00:00:30.070
it would take us a few extra steps
to arrive at correct solution.

10
00:00:31.190 --> 00:00:35.110
One way of handling this problem
is to use additional knowledge.

11
00:00:35.110 --> 00:00:39.690
So intuitively, we want to say that
we know that we want to go to B.

12
00:00:39.690 --> 00:00:42.800
So traversing through
D is not a good idea.

13
00:00:42.800 --> 00:00:45.530
Because it will take us away from B.

14
00:00:45.530 --> 00:00:50.700
In other words we use the knowledge
of the destination of B's location

15
00:00:50.700 --> 00:00:52.650
to steer the direction of search.

16
00:00:53.930 --> 00:00:57.400
This variant is called
Goal-Directed Dijkstra Algorithm because

17
00:00:57.400 --> 00:01:02.440
it is using the information about the
target known at any point in the search.

18
00:01:02.440 --> 00:01:06.919
The trick to use this information is to
change the edge weights as we diverse.

19
00:01:08.000 --> 00:01:09.350
How do we change the weight?

20
00:01:09.350 --> 00:01:12.040
We use a formula, where the new weight

21
00:01:12.040 --> 00:01:16.560
is the original weight together with
a function called the potential function.

22
00:01:16.560 --> 00:01:18.340
Now we'll show this in our example.

23
00:01:18.340 --> 00:01:19.950
Since our graph is a proxy for

24
00:01:19.950 --> 00:01:24.190
a road network, we can assume that we
know the coordinates of every node.

25
00:01:24.190 --> 00:01:27.810
Therefore, we can compute
the distance between any two nodes.

26
00:01:27.810 --> 00:01:30.630
In practice, we will choose a few nodes so

27
00:01:30.630 --> 00:01:35.210
that we can compute the distance of every
other node from these chosen nodes.

28
00:01:35.210 --> 00:01:37.450
These chosen nodes are called landmarks.

29
00:01:37.450 --> 00:01:41.280
Let's assume B, which is our target,
is a landmark node, and

30
00:01:41.280 --> 00:01:44.430
let's rewind to the state where
we are trying to choose between

31
00:01:44.430 --> 00:01:47.780
the GD expansion or the FE expansion.

32
00:01:47.780 --> 00:01:53.172
So we calculate the distance of F,
G and E from B.

33
00:01:53.172 --> 00:01:56.730
BF is 20, BG is 80, and BE is 15.

34
00:01:56.730 --> 00:01:59.312
Now we'll apply the formula like this.

35
00:01:59.312 --> 00:02:03.900
For the FG case,
we subtract the BF distance

36
00:02:03.900 --> 00:02:07.950
from the weight and
add the BD distance to the weight.

37
00:02:07.950 --> 00:02:12.180
This gives us 70 because G is far from B.

38
00:02:12.180 --> 00:02:16.210
Similarly for the FE case,
we subtract the BF distance and

39
00:02:16.210 --> 00:02:20.000
add the BE distance to the weight and
it gives us 15.

40
00:02:20.000 --> 00:02:23.960
Now, with these modified weights
we choose the FE expansion.

41
00:02:23.960 --> 00:02:29.060
In practice this significantly improves
the actual performance of the algorithm.

42
00:02:29.060 --> 00:02:33.201
So, this technique is used by many online
mapping services when they give you

43
00:02:33.201 --> 00:02:33.973
directions.

1
00:00:00.530 --> 00:00:04.710
So now let's bring back the constraints
that we have ignored so far.

2
00:00:05.820 --> 00:00:10.230
There are two constraints here,
parts of the graph to include and

3
00:00:10.230 --> 00:00:12.280
parts of the graph to exclude.

4
00:00:12.280 --> 00:00:16.840
In this example we have to go to B, but

5
00:00:16.840 --> 00:00:21.020
we should go to J first, and
then travel from B to J.

6
00:00:22.380 --> 00:00:25.850
Also, we cannot use any
of the paths through E.

7
00:00:26.960 --> 00:00:28.650
This really means two things.

8
00:00:29.930 --> 00:00:35.610
First, we split the problem into two
independent shortest path problems

9
00:00:35.610 --> 00:00:38.670
that we can solve in parallel if needed.

10
00:00:38.670 --> 00:00:43.440
Second, when we go from J
to B We need to extract

11
00:00:44.630 --> 00:00:48.240
the useful subgraph that
we need to consider.

12
00:00:48.240 --> 00:00:51.960
For a large network and
a complex exclusion condition,

13
00:00:53.010 --> 00:00:56.160
we will essentially operate
over a smaller graph,

14
00:00:56.160 --> 00:00:58.640
thereby reducing the effective
size of the problem.

15
00:01:00.130 --> 00:01:04.770
As we'll see in module three,
this kind of subgraph extraction operation

16
00:01:04.770 --> 00:01:09.460
can be done effectively and
efficiently with a graph database system.

17
00:01:09.460 --> 00:01:12.738
This concludes our short
tour of path analytics.

1
00:00:00.690 --> 00:00:05.620
So, in this optional module, we'll look
at the two key player problems again.

2
00:00:07.160 --> 00:00:11.178
The goal of the first problem is
to identify a small set of nodes,

3
00:00:11.178 --> 00:00:15.120
whose removal will create
maximum disruption.

4
00:00:16.710 --> 00:00:21.540
Now, in this case, a traditional
centrality algorithm may not work,

5
00:00:21.540 --> 00:00:24.310
because the optimization goal
is to break up the network.

6
00:00:26.040 --> 00:00:28.810
So we need a quantitive
measure of the breakage.

7
00:00:30.090 --> 00:00:32.980
If dij is the distance between nodes i and

8
00:00:32.980 --> 00:00:37.920
j, then 1 over dij is
the closeness of these two nodes.

9
00:00:39.360 --> 00:00:43.980
If we add the closeness of all nodes and
normalize it by the number of node pairs,

10
00:00:43.980 --> 00:00:47.150
we'll get a measure of
cohesiveness as a fraction.

11
00:00:48.420 --> 00:00:54.070
So, 1 minus this value is
a measure of fragmentation.

12
00:00:55.300 --> 00:00:58.880
Our goal is to maximize
this fragmentation metric.

13
00:01:00.660 --> 00:01:06.599
In the model terrorist network shown here,
removing the red nodes A,

14
00:01:06.599 --> 00:01:11.530
B, and C will break up the network
into seven components,

15
00:01:11.530 --> 00:01:14.669
with F reaching a value of 0.59.

16
00:01:14.669 --> 00:01:20.026
The second key player problem, is trying
to find a group of S influencers,

17
00:01:20.026 --> 00:01:24.120
which can reach a maximum
number of nodes within K steps.

18
00:01:25.920 --> 00:01:29.850
The number of unique nodes reachable from
a starting node is called the reach,

19
00:01:29.850 --> 00:01:30.510
of the starting node.

20
00:01:32.240 --> 00:01:37.420
For this we need to adapt the concept
of reach to limit it to k steps.

21
00:01:38.820 --> 00:01:43.570
We also need to adapt it to measure
the distance of an arbitrary node

22
00:01:43.570 --> 00:01:45.891
from a group of nodes
between our influences.

23
00:01:47.530 --> 00:01:53.120
The distance from one node to a group
of nodes can be defined as a maximum,

24
00:01:53.120 --> 00:01:58.100
or average, or minimum distance,
of the node from the members of the group.

25
00:01:59.220 --> 00:02:01.530
Often, the minimum
distance is a good choice.

26
00:02:03.560 --> 00:02:05.400
So the distance, we could reach,

27
00:02:05.400 --> 00:02:10.280
can then be through of, as the proportion
of all nodes reached by the group,

28
00:02:10.280 --> 00:02:12.810
where the nodes are weighted
by the distance from the set.

29
00:02:14.090 --> 00:02:17.630
And only nodes at distance
1 are given full rate.

30
00:02:18.920 --> 00:02:22.270
Hence, a distance we could reach
that use a maximum value of 1,

31
00:02:22.270 --> 00:02:27.730
where every outside node is adjacent to at
least one member of the set of influences.

32
00:02:28.970 --> 00:02:33.340
In the network shown,
just three nodes, A, C, and D,

33
00:02:33.340 --> 00:02:38.340
are sufficient to reach every other
member within just four steps.

34
00:02:40.120 --> 00:02:44.150
Now this concludes this module, where we
looked at several analytic techniques and

35
00:02:44.150 --> 00:02:48.090
measures to extract different
kinds of insights from a network.

1
00:00:04.060 --> 00:00:08.180
We saw how a community
in a graph can evolve.

2
00:00:09.540 --> 00:00:11.940
To track the nature of evolution,

3
00:00:11.940 --> 00:00:15.180
we need to measure how
the community changes over time.

4
00:00:16.430 --> 00:00:18.800
So here are three cases.

5
00:00:18.800 --> 00:00:25.670
One, two and three of a community
changing between two observation points.

6
00:00:25.670 --> 00:00:31.060
The goal is to figure out whether these
are normal fluctuations in the network or

7
00:00:31.060 --> 00:00:32.610
are more drastic changes occurring.

8
00:00:34.040 --> 00:00:34.990
Look at them for a second.

9
00:00:36.400 --> 00:00:41.138
Just visually, the first case
seems to show just minor changes.

10
00:00:41.138 --> 00:00:47.770
Whereas case two shows a merger,
and case three shows a split.

11
00:00:50.280 --> 00:00:54.660
Now, to come up with a quantitative
measure of change over time, we need to

12
00:00:54.660 --> 00:00:59.210
take two observations from two consecutive
time points and fuse the graph.

13
00:01:00.400 --> 00:01:03.910
If you do it for case one,
you'll find one new node,

14
00:01:05.000 --> 00:01:07.870
one living node, and
the rest will come on over time.

15
00:01:09.320 --> 00:01:14.060
For case two, you will see
that two previous communities,

16
00:01:14.060 --> 00:01:19.150
colored differently, are internally
connected the same way as before.

17
00:01:19.150 --> 00:01:23.170
But some members of the two communities
have created new crosslinks.

18
00:01:24.470 --> 00:01:27.520
Now can you tell me what
you observe in case three?

19
00:01:27.520 --> 00:01:31.060
Well I see one join node, color purple.

20
00:01:32.130 --> 00:01:36.470
Apart from it, there are just two
edges connecting the two groups.

21
00:01:37.830 --> 00:01:42.820
Now with these observations,
we can now compute the autocorrelation

22
00:01:42.820 --> 00:01:46.930
between the graphs across time t and
t plus 1.

23
00:01:46.930 --> 00:01:51.770
This is just a measure of
the number of common nodes

24
00:01:51.770 --> 00:01:54.090
divided by the number of
nodes in the combined graph.

25
00:01:55.560 --> 00:01:59.010
If the community does not change at all,
this number is 1.

26
00:01:59.010 --> 00:02:02.860
If a community has only a few connection,
the number is lower.

27
00:02:04.400 --> 00:02:09.360
After computing autocorrelation
over every pair of time steps,

28
00:02:09.360 --> 00:02:11.570
we can then compute stationarity,

29
00:02:12.770 --> 00:02:17.040
which measures the overall change in
the autocorrelation over a period of time.

30
00:02:18.250 --> 00:02:21.300
So if we measure over 100 time steps,

31
00:02:21.300 --> 00:02:27.990
we will add the 99 correlation values
from the steps and then divide it by 99.

32
00:02:27.990 --> 00:02:32.000
This will tell us what fraction
of members remain unchanged

33
00:02:32.000 --> 00:02:34.110
on an average over these 100 time steps.

34
00:02:35.590 --> 00:02:40.380
Therefore, the 1 minus zeta tells
us the average ratio of members

35
00:02:40.380 --> 00:02:41.940
that are changed in a time step.

36
00:02:44.642 --> 00:02:46.060
Let's take three cases.

37
00:02:47.310 --> 00:02:51.010
In the first plot,
the size of the graph is small and

38
00:02:51.010 --> 00:02:52.890
nothing much is happening here.

39
00:02:52.890 --> 00:02:57.180
A note occasionally joins or leaves,
keeping the stationarity pretty flat.

40
00:02:59.420 --> 00:03:05.320
In the second case, the graph is small,
but there are a lot of changes, especially

41
00:03:05.320 --> 00:03:10.710
at time step seven a whole bunch of purple
nodes have joined and then they went away.

42
00:03:11.750 --> 00:03:14.320
The size of the graph
clearly reflects this

43
00:03:14.320 --> 00:03:18.440
with a purple spike that you see
on the size versus the time graph.

44
00:03:21.123 --> 00:03:24.078
This spike on the time series
by the way is called a burst.

45
00:03:24.078 --> 00:03:30.640
The third plot shows a large graph
with many nodes joining and leaving.

46
00:03:31.690 --> 00:03:36.683
The stationarity of this graph will be
quite low given the abrupt changes we

47
00:03:36.683 --> 00:03:38.039
observe over time.

1
00:00:01.320 --> 00:00:05.140
In this video,
we'll discuss what paths are and

2
00:00:05.140 --> 00:00:08.420
how to find your way as it travels
along the nodes and edges of the graph.

3
00:00:10.080 --> 00:00:11.020
Let's start with an example.

4
00:00:12.480 --> 00:00:13.260
For this example,

5
00:00:13.260 --> 00:00:17.740
we'll consider an edge weighted
graph with no loops as shown here.

6
00:00:17.740 --> 00:00:21.180
Term edge weighted means
the edges have weights.

7
00:00:22.520 --> 00:00:26.320
The weight of the edge I to J is 15.

8
00:00:26.320 --> 00:00:30.770
We can think of this graph as a small road
network, where the nodes are cities, and

9
00:00:30.770 --> 00:00:33.190
the edge weights are highway
distances between them.

10
00:00:34.630 --> 00:00:38.470
To walk, or traverse, through this
graph we'll define what a walk is.

11
00:00:39.940 --> 00:00:43.040
A walk is an arbitrary
sequence of nodes and

12
00:00:43.040 --> 00:00:46.860
edges that starts from some node and
ends on some node.

13
00:00:46.860 --> 00:00:52.158
Here we can go from H to F

14
00:00:52.158 --> 00:00:58.935
to G to C to

15
00:00:58.935 --> 00:01:05.750
F to E to B.

16
00:01:05.750 --> 00:01:09.880
Notice that in this walk,
we went through the node F twice.

17
00:01:11.230 --> 00:01:16.280
In many applications, we do not want
to consider arbitrary walks but

18
00:01:16.280 --> 00:01:19.640
consider a walk where
we do not repeat nodes

19
00:01:19.640 --> 00:01:21.510
unless we need to come back
to the starting point.

20
00:01:22.710 --> 00:01:25.640
Such a constrained walk is called a path.

21
00:01:25.640 --> 00:01:28.920
The green arrows indicate
a path from J to B.

22
00:01:30.330 --> 00:01:34.580
We said on the last slide that a path
can start from a node and end on it.

23
00:01:34.580 --> 00:01:39.074
Such a path is called a cycle when
the path has a three or more nodes.

24
00:01:39.074 --> 00:01:43.694
The J, G, C,

25
00:01:43.694 --> 00:01:48.260
F, J, is a four node cycle,
sometimes called a four cycle.

26
00:01:49.620 --> 00:01:52.010
C, F, E is a three cycle.

27
00:01:53.650 --> 00:01:59.030
However, although there is an edge from
F to J and another from J back to F,

28
00:01:59.030 --> 00:02:03.590
this two node path is not
a cycle by our definition.

29
00:02:04.980 --> 00:02:08.680
A network with no cycles
is called acyclic.

30
00:02:10.440 --> 00:02:13.110
A graph that is both directed and

31
00:02:13.110 --> 00:02:18.600
acyclic is called a directed
acyclic graph, in short, a deck.

32
00:02:19.780 --> 00:02:26.470
A trail is a concept similar to a path,
it is a walk with no repeating edges.

33
00:02:27.500 --> 00:02:33.211
In the graph shown in the walk,
H, F, G, C, F, E,

34
00:02:33.211 --> 00:02:38.500
C, F, J, is not a trail.

35
00:02:38.500 --> 00:02:41.470
Because C, F Is traversed twice.

36
00:02:43.130 --> 00:02:46.050
Remember the seven bridges of
the Konigsberg problem that we described

37
00:02:46.050 --> 00:02:47.580
in module one?

38
00:02:47.580 --> 00:02:48.840
In that problem,

39
00:02:48.840 --> 00:02:52.260
we had the constraint that one
cannot cross the same bridge twice.

40
00:02:54.200 --> 00:02:57.090
Often we see such constraints
in path planning problems.

41
00:02:58.510 --> 00:03:02.190
A common notion in directive
graphs is called reachability.

42
00:03:03.710 --> 00:03:08.280
If there is a path from node U to node V,
V is reachable from U.

43
00:03:09.460 --> 00:03:10.770
Reachability is not symmetric.

44
00:03:11.860 --> 00:03:15.800
Even if V is reachable from U,
U may or may not be reachable from V.

45
00:03:16.960 --> 00:03:21.220
As we can see in this graph,
I is not reachable from A.

46
00:03:23.030 --> 00:03:25.300
Look at A more carefully.

47
00:03:25.300 --> 00:03:27.560
There is no outgoing edge from A at all.

48
00:03:28.570 --> 00:03:31.590
So no node in this graph
is reachable from A.

49
00:03:32.770 --> 00:03:35.790
A is a terminal, a leaf node of the graph.

50
00:03:37.300 --> 00:03:39.480
Where do we see this in real life?

51
00:03:39.480 --> 00:03:43.040
Think of road network with one way streets
and road blocks through the construction.

52
00:03:44.040 --> 00:03:46.610
This can make some areas
unreachable by cars.

53
00:03:48.370 --> 00:03:51.810
In biology,
there are gene regulation networks,

54
00:03:51.810 --> 00:03:53.930
in which the nodes represent genes and

55
00:03:53.930 --> 00:03:58.479
edges represent the fact that gene
A regulates gene B and not visa verse.

56
00:03:59.530 --> 00:04:00.940
This makes it a directed graph.

57
00:04:02.090 --> 00:04:06.930
We can easily think of a case where
A regulates B, and B regulates C, but

58
00:04:06.930 --> 00:04:09.270
C does not regulate B or A.

59
00:04:09.270 --> 00:04:12.800
That's making A unreachable from C.

60
00:04:12.800 --> 00:04:15.050
The final concept you will
explore in this graph,

61
00:04:15.050 --> 00:04:19.220
in this lecture,
is that of a graph diameter.

62
00:04:19.220 --> 00:04:24.950
The diameter of a graph measures the
maximum number of steps, also called hops,

63
00:04:24.950 --> 00:04:29.320
want us to traverse to go to
the most distant node in the graph.

64
00:04:30.580 --> 00:04:33.630
That means,
if you go from an arbitrary node

65
00:04:33.630 --> 00:04:39.160
to any other arbitrary node in the graph,
following only the shortest paths roots,

66
00:04:39.160 --> 00:04:41.790
what is the maximum number
of steps you have to take?

67
00:04:43.000 --> 00:04:44.520
Let's see how this is computed.

68
00:04:45.670 --> 00:04:50.350
For this task, we'll create a matrix
called the shortest hop distance matrix.

69
00:04:51.790 --> 00:04:57.060
Just like the adjacency matrix, the rows
and columns here represent graph nodes.

70
00:04:58.070 --> 00:05:01.930
And each cell contains the distance
from the I eighth node,

71
00:05:01.930 --> 00:05:03.780
to the G eighth node
via the shortest path.

72
00:05:05.000 --> 00:05:09.700
The distance from any
node to itself is zero.

73
00:05:09.700 --> 00:05:12.870
So all diagonal elements
of the matrix are zero.

74
00:05:14.570 --> 00:05:18.440
If a node I cannot reach
node J through any path,

75
00:05:18.440 --> 00:05:21.200
the distance is marked as infinity.

76
00:05:21.200 --> 00:05:25.600
Thus, the distance from
B to C is infinity.

77
00:05:25.600 --> 00:05:30.203
You can go from E to F in two steps,
E to C to F.

78
00:05:30.203 --> 00:05:36.670
Therefore, the wait at the C cell is two.

79
00:05:36.670 --> 00:05:41.830
If you fill this matrix, you will
notice that the largest reachable value

80
00:05:41.830 --> 00:05:44.610
is 4 in doing the infinite distance.

81
00:05:45.840 --> 00:05:50.463
Thus, the diameter of this graph is
4 where It represents the part from I

82
00:05:50.463 --> 00:05:55.020
to A, through J, G and D.

83
00:05:55.020 --> 00:05:59.000
There are a few noteworthy
items in this Distance Matrix.

84
00:05:59.000 --> 00:06:05.310
The row of A has a value of 0 with itself
and infinity for every other node.

85
00:06:05.310 --> 00:06:08.230
This happens because A is a leaf node.

86
00:06:09.740 --> 00:06:13.040
Similarly, except for
the 0 distance with itself,

87
00:06:13.040 --> 00:06:17.810
the H column has infinity for
all of the nodes.

88
00:06:17.810 --> 00:06:21.984
This happens because H
has no incoming edges and

89
00:06:21.984 --> 00:06:25.226
therefore no other node can reach H.
