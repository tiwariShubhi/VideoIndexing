WEBVTT

1
00:00:03.148 --> 00:00:05.208
When to reconsider Hadoop?

2
00:00:19.098 --> 00:00:22.960
The Hadoop ecosystem is
growing at a fast pace.

3
00:00:23.970 --> 00:00:26.937
This means a lot of stuff
that was difficult, or

4
00:00:26.937 --> 00:00:30.180
not supportive, is becoming possible.

5
00:00:32.480 --> 00:00:33.990
In this lecture,

6
00:00:33.990 --> 00:00:37.730
we will look at some aspects that
clearly make a good match for Hadoop.

7
00:00:39.200 --> 00:00:43.220
We will also look at several
aspects that might motivate you

8
00:00:43.220 --> 00:00:45.510
to evaluate Hadoop at a deeper level.

9
00:00:47.060 --> 00:00:51.560
And does Hadoop really make sense for
your specific problem?

10
00:00:54.190 --> 00:00:58.790
First let's look at the key features
that make a problem Hadoop friendly.

11
00:00:59.950 --> 00:01:04.390
If you see a large scale growth in
amount of data you will tackle,

12
00:01:04.390 --> 00:01:06.310
probably it makes sense to use Hadoop.

13
00:01:07.610 --> 00:01:12.230
When you want quick access to your old
data which would otherwise go on tape

14
00:01:12.230 --> 00:01:17.180
drives for archival storage,
Hadoop might provide a good alternative.

15
00:01:20.080 --> 00:01:22.650
Other Hadoop friendly features include

16
00:01:22.650 --> 00:01:28.020
scenarios when you want to use multiple
applications over the same data store.

17
00:01:28.020 --> 00:01:31.683
High volume or
high variety are also great indicators for

18
00:01:31.683 --> 00:01:33.598
Hadoop as a platform choice.

19
00:01:37.148 --> 00:01:40.860
Small data set processing
should raise your eyebrows.

20
00:01:40.860 --> 00:01:42.410
Do you really need Hadoop for that?

21
00:01:43.560 --> 00:01:49.178
Dig deeper, and find out exactly why you
want to use Hadoop before going ahead.

22
00:01:53.238 --> 00:01:56.330
Hadoop is good for data parallelism.

23
00:01:56.330 --> 00:02:01.320
As you know, data parallelism is
the simultaneous execution of the same

24
00:02:01.320 --> 00:02:05.520
function on multiple nodes across
the elements of a dataset.

25
00:02:06.630 --> 00:02:11.060
On the other hand, task parallelism,
as you see in this graph,

26
00:02:12.640 --> 00:02:17.160
is the simultaneous execution
of many different functions

27
00:02:17.160 --> 00:02:21.260
on multiple nodes across the same or
different data sets.

28
00:02:22.930 --> 00:02:26.950
If your problem has task-level
parallelism, you must do further

29
00:02:26.950 --> 00:02:30.990
analysis as to which tools you plan
to deploy from the Hadoop ecosystem.

30
00:02:32.910 --> 00:02:36.260
What are the precise benefits
that these tools provide?

31
00:02:37.790 --> 00:02:38.920
Proceed with caution.

32
00:02:41.330 --> 00:02:44.330
Not all algorithms are scalable in Hadoop,
or

33
00:02:44.330 --> 00:02:48.030
reducible to one of the programming
models supported by YARN.

34
00:02:50.090 --> 00:02:55.590
Hence, if you are looking to deploy
highly coupled data processing algorithms

35
00:02:55.590 --> 00:02:56.860
proceed with caution.

36
00:02:58.300 --> 00:03:01.270
Do a thorough analysis
before using Hadoop.

37
00:03:01.270 --> 00:03:05.680
Are you thinking of

38
00:03:05.680 --> 00:03:10.350
throwing away your existing database
solutions and replacing them with Hadoop?

39
00:03:10.350 --> 00:03:10.850
Think again.

40
00:03:12.130 --> 00:03:17.100
Hadoop may be a good platform where
your diverse data sets can land and

41
00:03:17.100 --> 00:03:21.210
get processed into a form
digestible with your database.

42
00:03:22.660 --> 00:03:27.070
Hadoop may not be the best data store
solution for your business case.

43
00:03:27.070 --> 00:03:29.470
Evaluate, and proceed with caution.

44
00:03:30.960 --> 00:03:35.560
HDFS stores data in blocks
of 64 megabytes or larger,

45
00:03:35.560 --> 00:03:40.940
so you may have to read an entire
file just to pick one data entry.

46
00:03:42.580 --> 00:03:45.858
That makes it a bit harder to
perform random data access.

47
00:03:48.078 --> 00:03:52.370
The Hadoop ecosystem is growing
at a faster pace than ever.

48
00:03:53.820 --> 00:03:57.530
This slide shows some of the moving
targets in the Hadoop ecosystem and

49
00:03:57.530 --> 00:04:00.650
the additional needs which
must be addressed by new tools

50
00:04:00.650 --> 00:04:02.470
to the Hadoop ecosystem.

51
00:04:02.470 --> 00:04:05.260
Mainly, advanced analytical queries,

52
00:04:06.270 --> 00:04:10.580
latency sensitive tasks, and
cyber security of sensitive data.

53
00:04:12.050 --> 00:04:16.510
Here, we give pointers to tools you
might want to look into further

54
00:04:16.510 --> 00:04:19.090
to understand the challenges
these need tools address.

55
00:04:21.000 --> 00:04:27.590
As a summary, although Hadoop is good with
scalability of many algorithms, it is just

56
00:04:27.590 --> 00:04:32.520
one model and does not solve all issues
in managing and processing big data.

57
00:04:33.630 --> 00:04:38.590
Although it would be possible to find
counterexamples, we can generally say

58
00:04:38.590 --> 00:04:43.110
that the Hadoop framework is not the best
for working with small data sets,

59
00:04:43.110 --> 00:04:47.120
advanced algorithms that require
a specific hardware type,

60
00:04:47.120 --> 00:04:52.190
task level parallelism, infrastructure
replacement, or random data access.