WEBVTT

1
00:00:02.060 --> 00:00:04.400
How does data science happen?

2
00:00:04.400 --> 00:00:05.850
Five P's of data science.

3
00:00:07.810 --> 00:00:13.220
Now that we identified what data science
is and how companies can strategize around

4
00:00:13.220 --> 00:00:18.660
big data to start building a purpose,
let's come back to using data science

5
00:00:18.660 --> 00:00:23.870
to get value out of big data around
the purpose or questions they defined.

6
00:00:41.348 --> 00:00:43.591
Our experience with building and

7
00:00:43.591 --> 00:00:49.040
observing successful data science projects
led to a method around the craft with

8
00:00:49.040 --> 00:00:55.255
five distinct components that can be
defined as components of data science.

9
00:00:55.255 --> 00:00:59.859
Here we define data science
as a multi-disciplinary

10
00:00:59.859 --> 00:01:03.972
craft that combines
people teaming up around

11
00:01:03.972 --> 00:01:08.910
application-specific purpose that
can be achieved through a process,

12
00:01:10.420 --> 00:01:14.100
big data computing platforms,
and programmability.

13
00:01:17.260 --> 00:01:22.460
All of these should lead to
products where the focus really

14
00:01:22.460 --> 00:01:26.760
is on the questions or purpose that are
defined by your big data strategy ideas.

15
00:01:28.960 --> 00:01:33.540
There are many technology,
data and analytical research, and

16
00:01:33.540 --> 00:01:37.110
development related activities
around the questions.

17
00:01:37.110 --> 00:01:41.490
But in the end, everything we do
in this phase is to reach to that

18
00:01:41.490 --> 00:01:43.820
final product based on our purposes.

19
00:01:44.950 --> 00:01:47.830
So, it makes sense to start with it and

20
00:01:47.830 --> 00:01:50.860
build a process around how
we make this product happen.

21
00:01:52.740 --> 00:01:55.520
Remember the wild fire
prediction project I described?

22
00:01:56.830 --> 00:02:01.070
One of the products we described
there was the rate of spread and

23
00:02:01.070 --> 00:02:02.870
direction of an ongoing fire.

24
00:02:04.460 --> 00:02:06.780
We have identified questions and

25
00:02:06.780 --> 00:02:11.060
the process that led us to
the product in the end to solve it.

26
00:02:12.960 --> 00:02:17.280
We brought together experts around
the table for fire modeling,

27
00:02:17.280 --> 00:02:21.620
data management, time series analysis,
scalable computing,

28
00:02:21.620 --> 00:02:25.060
Geographical Information Systems,
and emergency response.

29
00:02:28.050 --> 00:02:31.770
I asked them,
let's not dive into the techniques yet.

30
00:02:31.770 --> 00:02:33.080
What is the problem at large?

31
00:02:34.100 --> 00:02:40.380
How do we see ourselves solving it?

32
00:02:40.380 --> 00:02:44.780
A typical conversation around
the process starts with this question.

33
00:02:46.230 --> 00:02:51.600
Then from then on,
drilling down to many areas of expertise,

34
00:02:51.600 --> 00:02:53.830
often we blur lines between the steps.

35
00:02:55.510 --> 00:03:00.280
My wildfire team would start listing
things like, we don't have an integrated

36
00:03:00.280 --> 00:03:05.400
system or we don't have real-time
access to data programmatically,

37
00:03:05.400 --> 00:03:08.210
so we can't analyze fires on the fly.

38
00:03:08.210 --> 00:03:12.950
Or they can say, I can't integrate
sensor data with satellite data.

39
00:03:14.370 --> 00:03:20.080
All of this leads me to challenges
I can then use to define problems.

40
00:03:21.300 --> 00:03:25.560
There are many dimensions of data science
to think about within this discussion.

41
00:03:26.570 --> 00:03:31.700
Let's start with the obvious ones,
people and purpose.

42
00:03:34.535 --> 00:03:39.800
People refers to a data science team or
the projects stakeholders.

43
00:03:39.800 --> 00:03:42.700
As you know by now,
they're expert in data and

44
00:03:42.700 --> 00:03:47.028
analytics, business, computing,
science, or big data management,

45
00:03:47.028 --> 00:03:53.154
like all the set of experts I
listed in my wildfire scenario.

46
00:03:53.154 --> 00:03:59.560
The purpose refers to the challenge or
set of challenges defined by your

47
00:03:59.560 --> 00:04:04.940
big data strategy, like solving the
question related to the rate of spread and

48
00:04:04.940 --> 00:04:08.170
direction of the fire perimeter
in the wildfire case.

49
00:04:12.003 --> 00:04:17.099
Since there's a predefined team
with a purpose, a great place for

50
00:04:17.099 --> 00:04:22.190
this team to start with is
a process they could iterate on.

51
00:04:22.190 --> 00:04:27.470
We can simply say, people with purpose
will define a process to collaborate and

52
00:04:27.470 --> 00:04:28.360
communicate around.

53
00:04:30.010 --> 00:04:33.500
The process is conceptual
in the beginning and

54
00:04:33.500 --> 00:04:37.390
defines the set of steps an how
everyone can contribute to it.

55
00:04:41.060 --> 00:04:43.230
There are many ways to
look at the process.

56
00:04:44.890 --> 00:04:50.250
One way of looking at it is
as two distinct activities,

57
00:04:50.250 --> 00:04:53.130
mainly big data engineering and

58
00:04:53.130 --> 00:04:57.500
big data analytics, or
computational big data science,

59
00:04:57.500 --> 00:05:01.910
as I like to call it, as more than simple
analytics is being performed here.

60
00:05:03.840 --> 00:05:10.180
A more detailed way of looking at
the process reveals five distinct steps or

61
00:05:10.180 --> 00:05:15.214
activities of this data science process,

62
00:05:15.214 --> 00:05:21.018
namely acquire, prepare,

63
00:05:21.018 --> 00:05:26.540
analyze, report, and act.

64
00:05:26.540 --> 00:05:29.190
We can simply say that
data science happens

65
00:05:29.190 --> 00:05:31.950
at the boundary of all these steps.

66
00:05:31.950 --> 00:05:36.510
Ideally, this process should
support experimental work and

67
00:05:36.510 --> 00:05:40.980
dynamic scalability on the big data and
computing platforms.

68
00:05:44.220 --> 00:05:49.050
This five step process can be used in
alternative ways in real life big data

69
00:05:49.050 --> 00:05:53.580
applications, if we add the dependencies
of different tools to each other.

70
00:05:54.930 --> 00:05:58.490
The influence of big data pushes for

71
00:05:58.490 --> 00:06:02.930
alternative scalability approaches
at each step of the process.

72
00:06:04.010 --> 00:06:07.080
Just like you would scale
each step on its own,

73
00:06:07.080 --> 00:06:10.780
you can scale the whole
process as a whole in the end.

74
00:06:14.613 --> 00:06:20.900
One can simply say, all of these steps
have reporting needs in different forms.

75
00:06:23.280 --> 00:06:30.290
Or there is a need to draw all these
activities as an iterating process,

76
00:06:30.290 --> 00:06:35.710
including build, explore, and
scale for big data as steps.

77
00:06:38.550 --> 00:06:42.550
Big data analysis needs alternative
data management techniques and

78
00:06:42.550 --> 00:06:47.290
systems, as well as analytical tools and
methods.

79
00:06:49.160 --> 00:06:54.730
Multiple modes of scalability is needed
based on dynamic data and computing loads.

80
00:06:55.750 --> 00:06:59.800
In addition,
change in physical infrastructure,

81
00:06:59.800 --> 00:07:04.320
streaming data specific urgencies
arising from special events

82
00:07:04.320 --> 00:07:07.780
can also require multiple
modes of scalability.

83
00:07:09.230 --> 00:07:11.490
In this intro course, for simplicity,

84
00:07:11.490 --> 00:07:17.470
we will refer to the process as a set of
five sequential activities that iterate.

85
00:07:18.500 --> 00:07:23.550
However, we'll touch on scalability as
needed in our example applications.

86
00:07:26.840 --> 00:07:30.190
As a part of building
your big data process,

87
00:07:30.190 --> 00:07:34.230
it's important to simply
mention two other P's.

88
00:07:34.230 --> 00:07:39.620
The first one is big data platforms,
like the ones in the Hadoop framework,

89
00:07:39.620 --> 00:07:43.610
or other computing platforms
to scale different steps.

90
00:07:43.610 --> 00:07:47.060
The scalability should be in
the mind of all team members and

91
00:07:47.060 --> 00:07:49.030
get communicated as an expectation.

92
00:07:51.390 --> 00:07:55.970
In addition, the scalable process
should be programmable through

93
00:07:55.970 --> 00:08:01.830
utilization of reusable and
reproducible programming interfaces

94
00:08:01.830 --> 00:08:06.308
to libraries, like systems middleware,
analytical tools,

95
00:08:06.308 --> 00:08:10.395
visualization environments, and
end user reporting environments.

96
00:08:14.010 --> 00:08:16.980
Thinking of big data
applications as a process,

97
00:08:16.980 --> 00:08:22.150
including a set of activities that
the team members can collaborate over,

98
00:08:22.150 --> 00:08:26.720
also helps to build metrics for
accountability to be built into it.

99
00:08:26.720 --> 00:08:31.000
This way, expectations on cost, time,

100
00:08:31.000 --> 00:08:34.610
optimization of deliverables,
and time lines can be discussed

101
00:08:34.610 --> 00:08:39.210
between the the members starting with
the beginning of the data science process.

102
00:08:42.325 --> 00:08:45.890
Sometimes we may not be able
to do this in one step.

103
00:08:47.550 --> 00:08:52.420
And joint explorations like statistical
evaluations of intermediate results or

104
00:08:52.420 --> 00:08:55.060
accuracy of sample data
sets become important.

105
00:08:57.150 --> 00:09:02.430
As a summary, data science can be
defined as a craft of using the five P's

106
00:09:02.430 --> 00:09:07.380
identified in this lecture,
leading to a sixth P, the data product.

107
00:09:08.580 --> 00:09:12.870
Having a process within the more
business-driven Ps, like people and

108
00:09:12.870 --> 00:09:17.120
purpose, and the more technically
driven P's, like platforms and

109
00:09:17.120 --> 00:09:22.220
programmability, leads to
a streamlined approach that starts and

110
00:09:22.220 --> 00:09:26.630
ends with the product, team
accountability, and collaboration in mind.

111
00:09:27.740 --> 00:09:31.311
Data science process
provides guidelines for

112
00:09:31.311 --> 00:09:36.621
implementing big data solution,
as it helps to organize efforts and

113
00:09:36.621 --> 00:09:43.137
ensures all critical steps taken conforms
to pre-define and agreed upon metrics.