WEBVTT

1
00:00:00.090 --> 00:00:03.478
Characteristics of Big Data- Velocity.

2
00:00:19.075 --> 00:00:23.612
Velocity refers to the increasing
speed at which big data is created and

3
00:00:23.612 --> 00:00:28.160
the increasing speed at which the data
needs to be stored and analyzed.

4
00:00:29.250 --> 00:00:34.310
Processing of data in real-time to match
its production rate as it gets generated

5
00:00:34.310 --> 00:00:37.810
is a particular goal
of big data analytics.

6
00:00:37.810 --> 00:00:41.090
For example,
this type of capability allows for

7
00:00:41.090 --> 00:00:45.110
personalization of advertisement
on the web pages you visit

8
00:00:45.110 --> 00:00:49.610
based on your recent search,
viewing, and purchase history.

9
00:00:49.610 --> 00:00:55.350
If a business cannot take advantage
of the data as it gets generated, or

10
00:00:55.350 --> 00:00:59.540
at the speed analysis of it is needed,
they often miss opportunities.

11
00:01:00.620 --> 00:01:05.540
In order to build a case for the
importance of this dimension of big data,

12
00:01:05.540 --> 00:01:07.290
let's imagine we are taking a road trip.

13
00:01:08.850 --> 00:01:12.610
You're looking for
some better information to start packing.

14
00:01:12.610 --> 00:01:14.730
In this case, the newer the information,

15
00:01:14.730 --> 00:01:19.140
the higher its relevance
in deciding what to pack.

16
00:01:19.140 --> 00:01:21.420
Would you use last month's
weather information or

17
00:01:21.420 --> 00:01:24.310
data from last year at this time?

18
00:01:24.310 --> 00:01:29.550
Or, would you use the weather
information from this week, yesterday or

19
00:01:29.550 --> 00:01:30.630
better, today?

20
00:01:31.820 --> 00:01:35.750
It makes sense to obtain the latest
information about weather and

21
00:01:35.750 --> 00:01:38.830
process it in a way that
makes your decisions easier.

22
00:01:38.830 --> 00:01:44.600
If the information is old,
it doesn't matter how accurate it is.

23
00:01:45.950 --> 00:01:49.190
Being able to catch up with
the velocity of big data and

24
00:01:49.190 --> 00:01:54.640
analyzing it as it gets generated can
even impact the quality of human life.

25
00:01:54.640 --> 00:02:00.700
Sensors and smart devices monitoring
the human body can detect abnormalities

26
00:02:00.700 --> 00:02:06.510
in real time and trigger immediate action,
potentially saving lives.

27
00:02:06.510 --> 00:02:10.950
This type of processing is what
we call real time processing.

28
00:02:10.950 --> 00:02:15.210
Real-time processing is quite
different from its remote relative,

29
00:02:15.210 --> 00:02:15.800
batch processing.

30
00:02:18.270 --> 00:02:22.320
Batch processing was the norm
until a couple of years ago.

31
00:02:22.320 --> 00:02:26.160
Large amounts of data would be
fed into large machines and

32
00:02:26.160 --> 00:02:27.870
processed for days at a time.

33
00:02:29.230 --> 00:02:33.870
While this type of processing is still
very common today, decisions based on

34
00:02:33.870 --> 00:02:39.490
information that is even few days old
can be catastrophic to some businesses.

35
00:02:41.620 --> 00:02:45.320
Organizations which make
decisions on latest data

36
00:02:45.320 --> 00:02:46.960
are more likely to hit the target.

37
00:02:48.860 --> 00:02:52.780
For this reason it's important
to match the speed of processing

38
00:02:52.780 --> 00:02:57.345
with the speed of information generation,
and get real time decision making power.

39
00:02:57.345 --> 00:03:01.497
In addition, today's sensor-powered

40
00:03:01.497 --> 00:03:06.843
socioeconomic climate
requires faster decisions.

41
00:03:06.843 --> 00:03:11.332
Hence, we can not wait for
all the data to be first produced,

42
00:03:11.332 --> 00:03:13.190
then fed into a machine.

43
00:03:14.480 --> 00:03:18.830
There are many applications where
new information is streaming and

44
00:03:18.830 --> 00:03:22.120
needs to be integrated
with existing data to

45
00:03:22.120 --> 00:03:26.825
produce decisions such as emergency
response planning in a tornado, or

46
00:03:26.825 --> 00:03:32.500
deciding trading strategies in real time,
or getting estimates in advertising.

47
00:03:34.520 --> 00:03:40.340
We have to digest chunks of data as they
are produced and give meaningful results.

48
00:03:42.900 --> 00:03:44.385
As more data comes in,

49
00:03:44.385 --> 00:03:48.930
your results will need to adapt to
reflect this change in the input.

50
00:03:50.060 --> 00:03:56.160
Decisions based on processing of already
acquired data such as batch processing,

51
00:03:56.160 --> 00:03:58.660
may give an incomplete picture.

52
00:03:58.660 --> 00:04:04.550
And hence, the applications need real
time status of the context at hand.

53
00:04:04.550 --> 00:04:05.910
That is, streaming analysis.

54
00:04:07.280 --> 00:04:12.420
Fortunately, with the event
of cheap sensors technology,

55
00:04:12.420 --> 00:04:17.520
mobile phones, and social media,
we can obtain the latest information

56
00:04:17.520 --> 00:04:21.940
at a much rapid rate and
in real time in comparison with the past.

57
00:04:22.990 --> 00:04:26.650
So how do you make sure we match
the velocity of the expectations

58
00:04:26.650 --> 00:04:28.910
to gain insights from big data?

59
00:04:28.910 --> 00:04:31.900
With the velocity of the big data.

60
00:04:31.900 --> 00:04:34.050
Rate of generation, retrieval,

61
00:04:34.050 --> 00:04:37.650
or processing of data is
application specific.

62
00:04:38.760 --> 00:04:43.660
The need for real time data-driven
actions within a business case is

63
00:04:43.660 --> 00:04:48.620
what in the end dictates the velocity
of analytics over big data.

64
00:04:49.920 --> 00:04:53.620
Sometimes precision of a minute is needed.

65
00:04:53.620 --> 00:04:55.750
Sometimes half a day.

66
00:04:55.750 --> 00:05:00.710
Let's look at these four paths and
discuss when to pick the right one for

67
00:05:00.710 --> 00:05:02.270
your analysis.

68
00:05:02.270 --> 00:05:06.937
The dollar signs next to the numbers
in this example indicate how costly

69
00:05:06.937 --> 00:05:09.000
the operation is.

70
00:05:09.000 --> 00:05:11.160
The more dollars, the higher the cost.

71
00:05:12.600 --> 00:05:16.750
When the timeliness of processed
information plays no role in decision

72
00:05:16.750 --> 00:05:21.950
making, the speed at which data
is generated becomes irrelevant.

73
00:05:21.950 --> 00:05:27.220
In other words, you can wait for
as long as it takes to process data.

74
00:05:27.220 --> 00:05:29.730
Days, months, weeks.

75
00:05:29.730 --> 00:05:33.120
And once processing is over,
you will look at the results and

76
00:05:33.120 --> 00:05:34.550
probably share them with someone.

77
00:05:35.680 --> 00:05:40.640
When timeliness is not an issue,
you can choose any of the four paths.

78
00:05:41.800 --> 00:05:44.150
You will likely pick the cheapest one.

79
00:05:45.290 --> 00:05:48.720
When timeliness of end result is an issue

80
00:05:48.720 --> 00:05:52.810
deciding which of the four paths
to choose is not so simple.

81
00:05:52.810 --> 00:05:56.620
You will have to make a decision
based on cost of hardware,

82
00:05:56.620 --> 00:06:01.110
time sensitivity of information,
future scenarios.

83
00:06:01.110 --> 00:06:06.480
In other words,
this becomes a business driven question.

84
00:06:06.480 --> 00:06:12.930
For example, if speed is really important
at all costs, you will pick path four.

85
00:06:12.930 --> 00:06:19.130
As a summary, we need to pay attention
to the velocity of big data.

86
00:06:19.130 --> 00:06:23.460
Streaming data gives information
on what's going on right now.

87
00:06:23.460 --> 00:06:28.670
Streaming data has velocity, meaning
it gets generated at various rates.

88
00:06:28.670 --> 00:06:33.370
And analysis of such data in
real time gives agility and

89
00:06:33.370 --> 00:06:37.620
adaptability to maximize
benefits you want to extract.