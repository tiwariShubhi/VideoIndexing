WEBVTT

1
00:00:01.860 --> 00:00:06.740
In this video we will provide a quick
summary of the main points from our

2
00:00:06.740 --> 00:00:08.960
first course on introduction to big data.

3
00:00:10.310 --> 00:00:12.930
If you have just completed
our first course and

4
00:00:12.930 --> 00:00:16.810
do not need a refresher,
you may now skip to the next lecture.

5
00:00:18.480 --> 00:00:23.000
After this video,
you will be able to recall

6
00:00:23.000 --> 00:00:27.480
what started the big data era and
the three main big data sources.

7
00:00:29.310 --> 00:00:32.830
Summarize the volume,
variety, velocity and

8
00:00:32.830 --> 00:00:35.350
veracity issues related to each source.

9
00:00:36.790 --> 00:00:42.140
Explain the five step data science
process to gain value from big data.

10
00:00:43.510 --> 00:00:46.680
Remember the main elements
of the Hadoop Stack.

11
00:00:49.670 --> 00:00:54.950
We began our first course with
an explanation of how a lead torrent of

12
00:00:54.950 --> 00:01:00.690
big data combined with cloud computing
capabilities to process data anytime and

13
00:01:00.690 --> 00:01:05.450
anywhere has been at the core of
the launch of the Big Data Era.

14
00:01:08.470 --> 00:01:13.240
This big torrent of big data is often
boil down to a few varieties of data

15
00:01:13.240 --> 00:01:18.282
generated by machines, people and

16
00:01:18.282 --> 00:01:23.810
organizations with machine generated data.

17
00:01:23.810 --> 00:01:28.650
We refer to the data generated from real
time sensors and industrial machinery or

18
00:01:28.650 --> 00:01:30.020
vehicles.

19
00:01:30.020 --> 00:01:33.350
Web logs that track user behavior online.

20
00:01:33.350 --> 00:01:35.470
environmental sensors,

21
00:01:35.470 --> 00:01:38.680
personal health trackers among
many other sense data sources.

22
00:01:40.220 --> 00:01:46.050
With human generated data, we really refer
to the vast amount of social media data,

23
00:01:46.050 --> 00:01:49.760
status updates, tweets, photos and videos.

24
00:01:51.260 --> 00:01:56.600
With organization generated data,
we refer to more traditional types of data

25
00:01:56.600 --> 00:01:59.770
including transaction
information data bases and

26
00:01:59.770 --> 00:02:02.740
structure data often
stored in data warehouses.

27
00:02:03.960 --> 00:02:10.180
Note that big data can be structured,
semi-structured, and unstructured.

28
00:02:10.180 --> 00:02:15.030
Which is a topic we will talk about
more and in depth later in this course.

29
00:02:18.775 --> 00:02:23.975
Whatever your big data application is and
the types of big data you're using,

30
00:02:23.975 --> 00:02:29.905
the real value will come from integrating
different types of data sources and

31
00:02:29.905 --> 00:02:31.755
analyzing them at scale.

32
00:02:33.225 --> 00:02:36.355
Overall, by modeling, managing and

33
00:02:36.355 --> 00:02:40.700
integrating diverse streams
to improve our business and

34
00:02:40.700 --> 00:02:44.880
add value to our big data even
before we start analyzing it.

35
00:02:45.910 --> 00:02:47.591
As a part of modeling and

36
00:02:47.591 --> 00:02:52.804
managing big data is focusing on
the dimensions of scale availability and

37
00:02:52.804 --> 00:02:58.959
considering the challenges associated with
this dimensions to pick the right tools.

38
00:03:02.138 --> 00:03:07.460
Volume, variety and
velocity are the main dimensions which

39
00:03:07.460 --> 00:03:12.480
we characterized big data and
describe its challenges.

40
00:03:13.710 --> 00:03:18.550
We have huge amounts of data
in different formats and

41
00:03:18.550 --> 00:03:21.940
varying quality which
must be processed quickly

42
00:03:24.750 --> 00:03:30.810
veracity refers to the biases,
noise, and abnormality in data,

43
00:03:30.810 --> 00:03:36.190
or the unmeasurable certainty is in the
truthfulness and trustworthiness of data,

44
00:03:37.270 --> 00:03:41.470
and valence refers to
the connectedness of big data.

45
00:03:41.470 --> 00:03:43.790
Such as in the form of graph networks.

46
00:03:46.340 --> 00:03:52.500
Each V presents a challenging
dimension of big data mainly of size,

47
00:03:52.500 --> 00:03:57.160
complexity, speed, quality,
and consecutiveness.

48
00:03:57.160 --> 00:04:00.910
Although we can list some
other v' based on the context.

49
00:04:00.910 --> 00:04:05.390
We prefer to list these five as
fundamental dimensions which

50
00:04:05.390 --> 00:04:08.350
this big data specialization
helps you work on.

51
00:04:09.570 --> 00:04:15.130
Moreover, we must be sure to
never forget the sixth V: Value,

52
00:04:15.130 --> 00:04:18.220
at the heart of the big
data challenge is turning

53
00:04:18.220 --> 00:04:21.590
all of the other dimensions into
truly useful business value.

54
00:04:22.760 --> 00:04:26.490
How will Big Data benefit you and
your organization?

55
00:04:26.490 --> 00:04:30.960
The idea behind processing all
this Big Data in the first place

56
00:04:30.960 --> 00:04:33.100
is to bring value to the problem at hand.

57
00:04:34.360 --> 00:04:38.310
We need to take steps into
Big Data engineering and

58
00:04:38.310 --> 00:04:42.030
scalable data science to
generate value out of Big Data.

59
00:04:43.910 --> 00:04:44.900
We have all heard it.

60
00:04:44.900 --> 00:04:50.370
Data signs turns big data into insides,
or even actions.

61
00:04:51.490 --> 00:04:52.940
But what does that really mean?

62
00:04:54.340 --> 00:04:59.180
Data signs can be taught of as
the basis for empirical research.

63
00:04:59.180 --> 00:05:02.940
Like data is used to induce
information on the observations.

64
00:05:04.120 --> 00:05:06.830
These observations are mainly data.

65
00:05:06.830 --> 00:05:12.280
In our case, big data related to
a business or scientific use case.

66
00:05:14.550 --> 00:05:20.100
Inside is a term we use to refer to
the data products of data science.

67
00:05:20.100 --> 00:05:23.450
It is extracted from
a diverse amount of data

68
00:05:23.450 --> 00:05:27.620
through a combination of exploratory
data analysis and modeling.

69
00:05:28.830 --> 00:05:33.560
The questions are sometimes less
specific and it can require looking

70
00:05:33.560 --> 00:05:38.140
carefully at the data for patterns in
it to come up with a specific question.

71
00:05:40.400 --> 00:05:45.470
Another important point to recognize
is that data science is not static

72
00:05:45.470 --> 00:05:47.450
one time analysis.

73
00:05:47.450 --> 00:05:52.990
It involves a process where models
where you generate give us insights

74
00:05:52.990 --> 00:05:57.155
are constantly improve to a further and
prequel evidence and iterations.