WEBVTT

1
00:00:01.280 --> 00:00:04.810
Now that we have seen what
streaming data means,

2
00:00:04.810 --> 00:00:08.690
letâ€™s look at what makes streaming data
different and what some management and

3
00:00:08.690 --> 00:00:11.320
processing challenges for
streaming data are.

4
00:00:12.510 --> 00:00:16.130
After this video you will
be able to compare and

5
00:00:16.130 --> 00:00:18.980
contrast data in motion and data at rest.

6
00:00:20.450 --> 00:00:23.990
Differentiate between streaming and
batch data processing.

7
00:00:25.250 --> 00:00:31.070
And list management and
processing challenges for streaming data.

8
00:00:31.070 --> 00:00:33.560
We often hear the terms data addressed and

9
00:00:33.560 --> 00:00:36.665
data in motion,
when talking about big data management.

10
00:00:36.665 --> 00:00:43.260
Data-at-rest refers to mostly
static data collected from one or

11
00:00:43.260 --> 00:00:49.186
more data sources, and the analysis
happens after the data is collected.

12
00:00:49.186 --> 00:00:54.920
The term data-in-motion refers to a mode

13
00:00:54.920 --> 00:00:58.210
although similar data
collection methods apply,

14
00:00:58.210 --> 00:01:02.490
the data gets analyzed at the same
time it is being generated.

15
00:01:03.670 --> 00:01:09.300
Just like the sensor data processing
in a plane or a self-driving car.

16
00:01:09.300 --> 00:01:14.610
Analysis of data addressed is called
batch or static processing and

17
00:01:14.610 --> 00:01:18.080
the analysis of streaming data
is called stream processing.

18
00:01:19.640 --> 00:01:24.633
The run time and memory usage of most
algorithms that process static data,

19
00:01:24.633 --> 00:01:28.890
is usually dependent on the data size, and

20
00:01:28.890 --> 00:01:33.010
this size can easily be calculated
from files or databases.

21
00:01:34.670 --> 00:01:41.200
A key property, of streaming data
processing is the size of the data

22
00:01:41.200 --> 00:01:46.650
is unbounded and this changes the types
of algorithms that can be used.

23
00:01:48.050 --> 00:01:52.760
Algorithms that require iterating or
looping over the whole data set are not

24
00:01:52.760 --> 00:01:57.470
possible since with stream data,
you never get to the end.

25
00:01:58.730 --> 00:02:04.710
The modeling and management of streaming
data should enable computations on

26
00:02:04.710 --> 00:02:09.720
one data element or a small window
of group of recent data elements.

27
00:02:10.880 --> 00:02:14.820
These computations can update metrics,
monitor and

28
00:02:14.820 --> 00:02:18.050
plot statistics on the streaming data.

29
00:02:18.050 --> 00:02:22.120
Or apply analysis techniques
to the streaming data

30
00:02:22.120 --> 00:02:26.010
to learn about the dynamics of
the system as a time series.

31
00:02:27.120 --> 00:02:30.820
Since computations need to
be completed in real time,

32
00:02:30.820 --> 00:02:35.460
the analysis tasks processing
streaming data should be quicker or

33
00:02:35.460 --> 00:02:39.370
not much longer than
the streaming rate of the data.

34
00:02:39.370 --> 00:02:41.200
Which we define by it's velocity.

35
00:02:42.460 --> 00:02:45.970
In most streaming systems,
the management, and

36
00:02:45.970 --> 00:02:51.020
processing system subscribe to
the data source, but doesn't

37
00:02:51.020 --> 00:02:55.310
send anything back to the stream source
in terms of feedback or interactions.

38
00:02:57.070 --> 00:03:01.530
These requirements for streaming data
processing are quite different than batch

39
00:03:01.530 --> 00:03:06.330
processing where the analytical steps
have access to often, all data and

40
00:03:06.330 --> 00:03:11.890
can take more time to complete a complex
analytical task with less pressure

41
00:03:11.890 --> 00:03:16.360
on the completion time of individual
data management and processing tasks.

42
00:03:18.120 --> 00:03:21.756
Most organizations today
use a hybrid architecture.

43
00:03:21.756 --> 00:03:26.990
Sometimes get referred to as
the lambda architecture for

44
00:03:26.990 --> 00:03:31.490
processing streaming and
back jobs at the same time.

45
00:03:31.490 --> 00:03:38.130
In these systems, streaming wheel over
the real-time data is managed and

46
00:03:38.130 --> 00:03:43.230
kept until those data elements are pushed

47
00:03:43.230 --> 00:03:48.510
to a batch system and become available
to access and process as batch data.

48
00:03:49.870 --> 00:03:54.770
In such systems, a stream storage
layer is used to enable fast

49
00:03:54.770 --> 00:03:59.591
trees of streams and
ensure data ordering and consistency.

50
00:03:59.591 --> 00:04:01.398
And a processing layer for

51
00:04:01.398 --> 00:04:06.076
data is used to retrieve data from
the storage layer to analyze it and

52
00:04:06.076 --> 00:04:11.003
most probably little bit to a batch
data stream and notify the streaming

53
00:04:11.003 --> 00:04:16.810
storage that the data set does no
longer need to be in streaming storage.

54
00:04:16.810 --> 00:04:22.200
The big data challenges we discussed
were scalability, data replication,

55
00:04:22.200 --> 00:04:27.490
and durability, and fault tolerance arise
in this type of data very significantly.

56
00:04:28.690 --> 00:04:34.260
Among many there are two main
challenges that needs to be overcome

57
00:04:34.260 --> 00:04:39.820
to avoid data loss, and
enable real time analytical tasks.

58
00:04:39.820 --> 00:04:44.950
One challenge in streaming data
process is that the size and

59
00:04:44.950 --> 00:04:49.020
frequency of the mean data can
significantly change over time.

60
00:04:50.330 --> 00:04:55.910
These changes can be unpredictable and
may be driven by human behavior.

61
00:04:57.060 --> 00:05:02.340
For example, streaming data found on
social networks such as Facebook and

62
00:05:02.340 --> 00:05:05.025
Twitter can increase in
volume during holidays,

63
00:05:05.025 --> 00:05:08.160
sports matches, or major news events.

64
00:05:09.980 --> 00:05:15.910
These changes can be periodic and occur,
for example, in the evenings or weekends.

65
00:05:17.280 --> 00:05:22.470
For example, people may post messages
on Facebook more in the evening

66
00:05:22.470 --> 00:05:25.940
instead of during the day working hours.

67
00:05:25.940 --> 00:05:30.750
Streaming data changes may also
be unpredictable and sporadic.

68
00:05:30.750 --> 00:05:33.510
There can be an increase in data size and

69
00:05:33.510 --> 00:05:38.930
frequency during during major events,
sporting matches and things like that.

70
00:05:38.930 --> 00:05:44.950
Other changes include dropping or
missing data or even no data

71
00:05:44.950 --> 00:05:50.320
when there are network problems or device
generating the data has hardware problems.

72
00:05:50.320 --> 00:05:52.880
As an example of streaming
data fluctuation,

73
00:05:52.880 --> 00:05:54.964
consider the number of Tweets per second.

74
00:05:54.964 --> 00:06:01.050
On average,
there are 6,000 tweets sent every second.

75
00:06:01.050 --> 00:06:05.810
However, in August 2013,
the world record was

76
00:06:05.810 --> 00:06:10.980
set when over 144,000 tweets
were sent in a second.

77
00:06:10.980 --> 00:06:13.210
That's a factor of 24 increase.

78
00:06:15.320 --> 00:06:20.250
At the end of this lesson we will ask
you to focus on Twitter streams for

79
00:06:20.250 --> 00:06:23.160
trending topics and any other topic.

80
00:06:24.480 --> 00:06:27.810
You will notice how the rates
of Tweets streaming

81
00:06:27.810 --> 00:06:31.600
changes between different times and
different topics.

82
00:06:31.600 --> 00:06:38.010
To summarize, streaming data must be
handled differently than static data.

83
00:06:38.010 --> 00:06:43.150
Unlike static data, where you can
determine the size, streaming data is

84
00:06:43.150 --> 00:06:48.570
continually generated, and
you can not process it all at once.

85
00:06:50.250 --> 00:06:56.580
Streaming data can unpredictably
change in both size and frequency.

86
00:06:56.580 --> 00:06:58.330
This can be due to human behavior.

87
00:06:59.420 --> 00:07:01.910
Finally, algorithms for

88
00:07:01.910 --> 00:07:06.830
processing streaming data must
be relatively fast and simple.

89
00:07:06.830 --> 00:07:09.170
Since you don't know when
the next data arrives.