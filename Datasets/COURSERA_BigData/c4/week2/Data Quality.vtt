WEBVTT

1
00:00:01.220 --> 00:00:05.360
A very important part of data preparation
is to assess the quality of your data.

2
00:00:05.360 --> 00:00:09.120
We will look at some common data
quality issues in this lecture.

3
00:00:09.120 --> 00:00:14.660
After this video, you will be able to
describe three data quality issues,

4
00:00:14.660 --> 00:00:17.680
name three reasons for
poor data quality and

5
00:00:17.680 --> 00:00:21.060
explain why data quality
issues need to be addressed.

6
00:00:21.060 --> 00:00:23.820
Real world data is often very messy, so

7
00:00:23.820 --> 00:00:27.150
it's a given fact that you will need
to clean your data by identifying and

8
00:00:27.150 --> 00:00:30.660
addressing many issues that
affect the quality of your data.

9
00:00:30.660 --> 00:00:33.130
Let's take a closer look at what
these data quality issues are.

10
00:00:34.330 --> 00:00:37.770
A very common data quality
issue is missing data.

11
00:00:37.770 --> 00:00:41.410
Recall that a sample in your dataset
typically contains several variables or

12
00:00:41.410 --> 00:00:45.170
features like name, age and income.

13
00:00:45.170 --> 00:00:48.960
For some samples, some of these
variables may not have a value.

14
00:00:48.960 --> 00:00:53.420
These are referred to as
missing values in the data.

15
00:00:53.420 --> 00:00:57.650
Missing values are also referred
to as N/A for not available.

16
00:00:57.650 --> 00:01:00.810
So you will see N/A and
missing values used interchangeably.

17
00:01:01.910 --> 00:01:05.462
You may have missing values in your data
if you have an optional field in your

18
00:01:05.462 --> 00:01:06.500
data set.

19
00:01:06.500 --> 00:01:11.471
For example, the field age is often
an optional field on a survey.

20
00:01:11.471 --> 00:01:15.590
Also many people may choose not
to provide a response for income.

21
00:01:15.590 --> 00:01:20.470
And so you will end up with missing values
for the variable income in your data set.

22
00:01:20.470 --> 00:01:24.390
In some cases, a variable may
not be applicable to all cases.

23
00:01:24.390 --> 00:01:29.120
For example, income may not be
applicable to people who are retired or

24
00:01:29.120 --> 00:01:31.430
unemployed or to children.

25
00:01:31.430 --> 00:01:34.350
So you will not have an entry for
income in all of your samples.

26
00:01:35.490 --> 00:01:39.930
You can also have missing values, due to a
data collecting device that malfunctions,

27
00:01:39.930 --> 00:01:43.240
a network problem that affects
how the data was transmitted, or

28
00:01:43.240 --> 00:01:47.120
something else that goes wrong during
the data collection process itself, or

29
00:01:47.120 --> 00:01:49.930
the process of transmitting the data or
storing the data.

30
00:01:51.360 --> 00:01:55.680
Duplicate data occurs when your data set
has data objects that are duplicates or

31
00:01:55.680 --> 00:01:57.030
new duplicates of one another.

32
00:01:58.280 --> 00:02:01.090
An example of this is when there
are two different records for

33
00:02:01.090 --> 00:02:03.470
the same customer with
different addresses.

34
00:02:04.860 --> 00:02:06.590
This can come about, for example,

35
00:02:06.590 --> 00:02:10.510
if a customer's address has changed,
but the second address was simply

36
00:02:10.510 --> 00:02:15.160
added to this customer's records instead
of used to update the first address.

37
00:02:15.160 --> 00:02:18.220
Duplicate data can occur when
merging data from multiple sources.

38
00:02:19.470 --> 00:02:20.260
Invalid or

39
00:02:20.260 --> 00:02:24.720
inconsistent data occurs when you have
an impossible value for a variable.

40
00:02:24.720 --> 00:02:29.810
Some common examples are when you have
a six digit zip code, the letters AB for

41
00:02:29.810 --> 00:02:33.570
state abbreviations, or
a negative numbers for age.

42
00:02:33.570 --> 00:02:36.460
These invalid data values can
come about when there is a data

43
00:02:36.460 --> 00:02:38.860
entry error during data collection.

44
00:02:38.860 --> 00:02:41.460
For example, if you allow people
to type in their zip code and

45
00:02:41.460 --> 00:02:45.650
someone accidentally includes an extra
digit to their five digit zip code,

46
00:02:45.650 --> 00:02:47.915
then you will end up with
an invalid six digit zipcode.

47
00:02:49.240 --> 00:02:52.710
Noise refers to anything
that can distort your data.

48
00:02:52.710 --> 00:02:55.780
Noise can be introduced during
the data collection process or

49
00:02:55.780 --> 00:02:57.910
data transmission process.

50
00:02:57.910 --> 00:03:01.590
An example is buzzing in the background
when an audio message is recorded

51
00:03:01.590 --> 00:03:04.920
due to background noise or
a faulty microphone.

52
00:03:04.920 --> 00:03:08.470
Another example is an overly bright
image due to an incorrect light

53
00:03:08.470 --> 00:03:09.290
exposure setting.

54
00:03:10.690 --> 00:03:14.150
An Outlier is a data sample with
values that are considerably different

55
00:03:14.150 --> 00:03:16.550
than the rest of the other
data samples in a data set.

56
00:03:17.670 --> 00:03:21.110
An example scenario, that can create
Outliers is when there's a sense of

57
00:03:21.110 --> 00:03:26.650
failure that causes values being recorded
to be much higher or lower than normal.

58
00:03:26.650 --> 00:03:30.130
In this case, you want to remove
the Outliers from your data.

59
00:03:30.130 --> 00:03:33.580
In other applications however,
such as fraud detection,

60
00:03:33.580 --> 00:03:38.080
outliers are the important samples
that should be examined more closely.

61
00:03:38.080 --> 00:03:41.460
So depending on the application,
outliers may need to be removed or

62
00:03:41.460 --> 00:03:43.270
be kept for further analysis.

63
00:03:44.400 --> 00:03:47.000
If you simply ignore these
data quality issues,

64
00:03:47.000 --> 00:03:51.300
any analysis that is performed
will produce misleading results.

65
00:03:51.300 --> 00:03:54.220
In addition, some implementations
of analysis techniques

66
00:03:54.220 --> 00:03:57.030
cannot handle some of these
problems such as missing values.

67
00:03:58.160 --> 00:04:01.231
So, problems that we've discussed
in this lecture need to be

68
00:04:01.231 --> 00:04:04.312
addressed before any meaningful
analysis can be performed.

69
00:04:04.312 --> 00:04:05.813
We will discuss some techniques for

70
00:04:05.813 --> 00:04:07.970
handling data quality
issues in the next lecture.