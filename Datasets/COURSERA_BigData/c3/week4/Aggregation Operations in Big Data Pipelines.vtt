WEBVTT

1
00:00:02.630 --> 00:00:04.630
Aggregations in Big Data Pipelines.

2
00:00:07.220 --> 00:00:10.680
After this video you will
be able to compare and

3
00:00:10.680 --> 00:00:15.740
select the aggregation operation that
you require to solve your problem.

4
00:00:15.740 --> 00:00:21.650
Explain how you can use aggregations to
compact your dataset and reduce volume.

5
00:00:21.650 --> 00:00:22.890
That is in many cases.

6
00:00:24.260 --> 00:00:29.586
And design complex operations in your
pipeline, using a series of aggregations.

7
00:00:32.313 --> 00:00:39.189
Aggregation is any operation on a data set
that performs a specific transformation,

8
00:00:39.189 --> 00:00:43.979
taking all the related data
elements into consideration.

9
00:00:45.060 --> 00:00:49.550
Let's say we have a bunch of stars
which are of different colors.

10
00:00:50.570 --> 00:00:54.550
Different colors denote diversity or
variety in the data.

11
00:00:56.260 --> 00:01:02.610
To keep things simple, we will use
letter 'f' to denote a transformation.

12
00:01:03.700 --> 00:01:04.720
In the following slides,

13
00:01:04.720 --> 00:01:10.360
we will see examples of how 'f' can take
the shape of different transformations.

14
00:01:13.550 --> 00:01:18.390
If we apply a transformation that does
something using the information of

15
00:01:18.390 --> 00:01:22.430
all the stars here,
we are performing an aggregation.

16
00:01:24.070 --> 00:01:29.850
Loosely speaking, we can say
that applying a transformation 'f'

17
00:01:29.850 --> 00:01:34.830
that takes all the elements of data
as input is called 'aggregation'.

18
00:01:38.490 --> 00:01:44.400
One of the simplest aggregations is
summation over all the data elements.

19
00:01:44.400 --> 00:01:48.750
In this case,
let's say every star counted as 1.

20
00:01:48.750 --> 00:01:52.586
Summing over all the stars gives 14,

21
00:01:52.586 --> 00:01:57.119
which is the summation of 3 stars for
yellow,

22
00:01:57.119 --> 00:02:01.897
5 stars for green, and
6 stars for color pink.

23
00:02:04.779 --> 00:02:10.513
Another aggregation that you could perform
is summation of individual star colors,

24
00:02:10.513 --> 00:02:13.070
that is, grouping the sums by color.

25
00:02:14.200 --> 00:02:20.360
So, If each star is a 1,
adding each group will result in 3 for

26
00:02:20.360 --> 00:02:25.530
yellow stars, 5 for green stars,
and 6 for pink stars.

27
00:02:26.860 --> 00:02:27.952
In this case,

28
00:02:27.952 --> 00:02:33.611
the aggregation function 'f' will output
3 tuples of star colors and counts.

29
00:02:36.065 --> 00:02:41.190
In a sales scenario, each color could
denote a different product type.

30
00:02:42.470 --> 00:02:47.320
And the number 1 could be replaced
by revenue generated by a product

31
00:02:47.320 --> 00:02:49.230
in each city the product is sold.

32
00:02:50.600 --> 00:02:54.250
In fact,
we will keep coming back to this analogy.

33
00:02:56.420 --> 00:03:01.188
You can also perform average
over items of similar kind,

34
00:03:01.188 --> 00:03:06.150
such as sums grouped by color.

35
00:03:08.060 --> 00:03:10.630
Continuing the example earlier,

36
00:03:10.630 --> 00:03:15.060
you can calculate average revenue per
product type using this aggregation.

37
00:03:17.530 --> 00:03:22.270
Other simple yet useful aggregational
operations to help you extract meaning

38
00:03:22.270 --> 00:03:29.010
from large data sets are maximum,
minimum, and standard deviation.

39
00:03:29.010 --> 00:03:34.090
Remember, you can always perform
aggregation as a series of operations,

40
00:03:34.090 --> 00:03:38.140
such as maximum of the sums per product.

41
00:03:38.140 --> 00:03:41.510
That is, summation followed by maximum.

42
00:03:42.725 --> 00:03:46.920
If you first sum sales for
each city, that is for

43
00:03:46.920 --> 00:03:51.640
each product,
then you can take the maximum of it

44
00:03:51.640 --> 00:03:57.050
by applying maximum function to
the result of the summation function.

45
00:03:57.050 --> 00:04:01.870
In this case, you get the product,
which has maximum sales in the country.

46
00:04:04.040 --> 00:04:08.084
Aggregation over Boolean data
sets that can have true-false or

47
00:04:08.084 --> 00:04:14.430
one-zero values could be a complex mixture
of AND, OR, and NOT logical operations.

48
00:04:16.030 --> 00:04:20.110
A lot of problems become easy
to manipulate using sets.

49
00:04:20.110 --> 00:04:24.008
Because sets don't allow duplicate values.

50
00:04:24.008 --> 00:04:27.710
Depending on your application,
this could be very useful.

51
00:04:28.800 --> 00:04:33.730
For example, to count the number
of products from a sales table,

52
00:04:33.730 --> 00:04:38.920
you can simply take all
the sales tables and create sets

53
00:04:38.920 --> 00:04:44.130
of these products in those tables,
and take a union of these sets.

54
00:04:46.090 --> 00:04:52.130
To summarize, by choosing the right
aggregation, you can generate compact and

55
00:04:52.130 --> 00:04:58.720
meaningful insights that enable faster and
effective decision making in business.

56
00:04:58.720 --> 00:05:00.960
You will find that in most cases,

57
00:05:00.960 --> 00:05:04.270
aggregation results in
smaller output data sets.

58
00:05:05.450 --> 00:05:10.140
Hence, aggregation is an important tool
set to keep in pocket when dealing with

59
00:05:10.140 --> 00:05:12.669
large data sets, and big data pipelines.