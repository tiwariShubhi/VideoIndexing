WEBVTT

1
00:00:00.820 --> 00:00:02.600
Hello, my name is Victor Lou.

2
00:00:02.600 --> 00:00:07.090
I am the Solutions Engineer of
Global Philanthropy of Daameer.org.

3
00:00:07.090 --> 00:00:08.440
Helping researchers, academia,

4
00:00:08.440 --> 00:00:11.750
and non-profits find the insights
that matter using data.

5
00:00:11.750 --> 00:00:15.280
Today I am here to give you
a production environment,

6
00:00:15.280 --> 00:00:17.410
personalized music recommendation project.

7
00:00:17.410 --> 00:00:21.150
That was done for PonoMusic and
so what is Pono Music?

8
00:00:23.120 --> 00:00:26.355
Pono Music is revolutionizing music
listening by bringing back native,

9
00:00:26.355 --> 00:00:28.290
high-resolution audio.

10
00:00:28.290 --> 00:00:31.550
It's the way that artists intended and
recorded their music.

11
00:00:31.550 --> 00:00:36.710
Neil Young, the iconic artist and
musician is also the founder and CEO.

12
00:00:36.710 --> 00:00:40.020
Pono Music is the only complete
high-resolution music ecosystem.

13
00:00:40.020 --> 00:00:43.950
That includes the Pono player, the Pono
Music store, the Pono Music community.

14
00:00:45.200 --> 00:00:48.030
They have been super
generous in allowing us to

15
00:00:48.030 --> 00:00:51.020
take a look behind the scenes as how
we built out the recommendations.

16
00:00:53.630 --> 00:00:56.540
So, David Meer supports their mission
by providing a music recommendation

17
00:00:56.540 --> 00:01:00.900
engine that is both scalable and
flexible as Pono grows their user base.

18
00:01:00.900 --> 00:01:05.220
Let's begin by visiting Pono
music's website as you can see,

19
00:01:05.220 --> 00:01:07.740
they have a few shelves that focus on

20
00:01:07.740 --> 00:01:11.320
various recommendations that are not
tailored to each individual user.

21
00:01:11.320 --> 00:01:14.670
If you login,
then an additional shelf would appear

22
00:01:14.670 --> 00:01:17.690
that would deliver the recommendations
that are created in data gear.

23
00:01:17.690 --> 00:01:19.029
So how does DataMirror accomplish this.

24
00:01:19.029 --> 00:01:24.279
In a nutshell, DataMirror is a end to end,
antalis platform which contains ingestion,

25
00:01:24.279 --> 00:01:29.543
preparation analysis, visualization and
operationalization all the same platform.

26
00:01:29.543 --> 00:01:32.300
And having all the capabilities
in one platform is superior to

27
00:01:32.300 --> 00:01:34.240
traditional technology stack.

28
00:01:34.240 --> 00:01:39.300
Integration between disparate technologies
brings a lot of unnecessary challenges.

29
00:01:39.300 --> 00:01:41.880
We take advantage of open
source big data technologies.

30
00:01:41.880 --> 00:01:46.261
Specifically, we run natively and
Hadoop and Spark for our back end.

31
00:01:46.261 --> 00:01:49.600
And we leverage D3JS on the front end for
visualizations.

32
00:01:49.600 --> 00:01:51.821
Our Excel-like interface makes it easy for

33
00:01:51.821 --> 00:01:55.960
folks who don't know how to code to
also get in with the data modeling.

34
00:01:55.960 --> 00:01:57.720
It is very much self-service.

35
00:01:57.720 --> 00:02:00.001
In the case of Pono Music's
data mirror deployment,

36
00:02:00.001 --> 00:02:02.790
we have deployed a Hadoop
on Amazon on web services.

37
00:02:02.790 --> 00:02:04.410
But we can also be deployed off premise if

38
00:02:04.410 --> 00:02:06.290
needed it doesn't have
to be in the clouds.

39
00:02:06.290 --> 00:02:09.820
In fact, we could work with many many
different distributions of Hadoop.

40
00:02:09.820 --> 00:02:12.320
We can access dean rear through
any modern web browser.

41
00:02:12.320 --> 00:02:16.300
As you can see here we're using Google
Chrome but it works on any browser, right?

42
00:02:16.300 --> 00:02:18.460
So lets go ahead and take a look at
the a; let's log into data grip,

43
00:02:18.460 --> 00:02:21.640
so we're going to go ahead and
log in here..

44
00:02:23.390 --> 00:02:28.250
So what you're seeing here is the browser
tab and we can see various artifacts

45
00:02:28.250 --> 00:02:32.364
which include connections such
as connections to the pull nose,

46
00:02:32.364 --> 00:02:36.434
salesforce.com instance or
a connection to AWS S3 instance.

47
00:02:36.434 --> 00:02:38.226
Because DataMirror comes with so

48
00:02:38.226 --> 00:02:42.708
many prebuilt connectors which include
Connections to salesforce.com and S3.

49
00:02:42.708 --> 00:02:46.034
We can easily grant access to
those systems in order to pull or

50
00:02:46.034 --> 00:02:48.550
push data in and out of the dev.

51
00:02:48.550 --> 00:02:51.760
For example, let's take a quick look at
the salesforce.com configuration here.

52
00:02:51.760 --> 00:02:59.290
As you can see, we've already configured
salesforce as the connector type.

53
00:02:59.290 --> 00:03:00.530
When we hit next here,

54
00:03:00.530 --> 00:03:04.370
we'll we that you can authorize
a data manager to retrieve data.

55
00:03:04.370 --> 00:03:06.380
We're not going to do it because
this is a production environment, so

56
00:03:06.380 --> 00:03:09.300
I don't want to disrupt the pools.

57
00:03:09.300 --> 00:03:13.210
But if we were to click it, it'll give
us a salesfloor.com blogging stream.

58
00:03:13.210 --> 00:03:17.830
And so as soon as we login, the Datameer
would have access via the O-Off token.

59
00:03:17.830 --> 00:03:20.130
And so this is valid for a period of time.

60
00:03:20.130 --> 00:03:20.650
I'm going to go ahead and

61
00:03:20.650 --> 00:03:23.910
hit the cancel button as this
is a production environment.

62
00:03:23.910 --> 00:03:28.290
And so now we're ready to look
at an import job artifact.

63
00:03:28.290 --> 00:03:31.888
So this is the sales force import job and

64
00:03:31.888 --> 00:03:36.152
as you can see we go in here and
we configure it.

65
00:03:36.152 --> 00:03:41.830
We can see that it's connected to
the Pono Music SMDC connection.

66
00:03:44.753 --> 00:03:49.269
I'm going to go ahead and
hit next here.with salesforce.com,

67
00:03:49.269 --> 00:03:52.079
we just have to simply define the SOQL,

68
00:03:52.079 --> 00:03:56.526
which is basically a querying
language that's based on SQL.

69
00:03:56.526 --> 00:03:59.860
To locate data contained within
the salesforce.com objects.

70
00:03:59.860 --> 00:04:04.997
You can see the select statement here,
you can also see the familiar

71
00:04:04.997 --> 00:04:10.059
from statement, and you can also
see the where statement as well.

72
00:04:10.059 --> 00:04:12.459
So in order to protect
the privacy of the users,

73
00:04:12.459 --> 00:04:16.830
Datameer has the capability to obfuscate
sort of columns that are sensitive.

74
00:04:16.830 --> 00:04:19.770
And so in other words, we can scramble
sensitive fields such as email or

75
00:04:19.770 --> 00:04:21.370
physical addresses.

76
00:04:21.370 --> 00:04:25.228
And at this point in time, I'm going to
go ahead and cancel out, and I'm going to

77
00:04:25.228 --> 00:04:28.866
show the next part of this demo in
an obfuscated workbook environment.

78
00:04:28.866 --> 00:04:33.813
The artifacts contained in the obfuscated
folders are duplicates of the import job

79
00:04:33.813 --> 00:04:38.130
of the workbook from their production
counterparts as you can see here.

80
00:04:40.360 --> 00:04:44.510
So as you can see in the import
job settings we have configured

81
00:04:44.510 --> 00:04:51.320
the same connections here but
for the obfuscated columns here.

82
00:04:51.320 --> 00:04:54.970
Now we're obfuscating the owner
email as well as the street address.

83
00:04:54.970 --> 00:04:55.690
Now we hit Next here.

84
00:04:59.259 --> 00:05:03.140
And so you can see, various fields are
being pulled here from Salesforce, right.

85
00:05:03.140 --> 00:05:05.130
And in particular,
I want to highlight the.

86
00:05:06.150 --> 00:05:09.780
The owner email, that field, so as you
can see these are the obfuscated fields.

87
00:05:09.780 --> 00:05:13.420
Similarly, the actual street address,
that's also masked as well.

88
00:05:13.420 --> 00:05:17.375
I'm going to go ahead and hit Cancel.

89
00:05:17.375 --> 00:05:20.780
I will go back to, rather we're going to
go check out the workbook environment,

90
00:05:20.780 --> 00:05:23.300
which is where we do the preparation and
analysis.

91
00:05:28.465 --> 00:05:31.070
To the obfuscated workbook environment.

92
00:05:31.070 --> 00:05:34.260
As you can see we're starting
with a raw source of data here.

93
00:05:34.260 --> 00:05:38.930
This was the data that was
contained in the data sheet.

94
00:05:38.930 --> 00:05:43.500
Take note that there's a variety of icons
that indicate different types of sheets.

95
00:05:43.500 --> 00:05:45.610
So you could see here this
is the raw data type.

96
00:05:45.610 --> 00:05:48.360
This is a regular worksheet.

97
00:05:48.360 --> 00:05:51.400
You have a union sheet and
you have a joint sheet and

98
00:05:51.400 --> 00:05:54.440
we'll go into a little bit
more detail as we get to them.

99
00:05:54.440 --> 00:05:57.700
So, as you can see,
the interface is very much like Excel.

100
00:05:57.700 --> 00:06:02.830
Looking at the second sheet pairs, and
it's using a function called group by.

101
00:06:02.830 --> 00:06:07.380
So the group by function is a type of
aggregation function in Datameer speak.

102
00:06:07.380 --> 00:06:10.640
As you can see, you can build
the functions by pointing and clicking.

103
00:06:10.640 --> 00:06:14.040
But you can also enter the formula
to create nested functions or

104
00:06:14.040 --> 00:06:19.310
Apply arithmetic
operations just as a cell.

105
00:06:19.310 --> 00:06:21.770
We take all the unique combinations
of albums purchased for

106
00:06:21.770 --> 00:06:24.730
each of the unique email
using a group pair function.

107
00:06:25.890 --> 00:06:28.710
Then we pull out each of the elements
of the pairings using a list element

108
00:06:28.710 --> 00:06:30.310
function, so let's see here.

109
00:06:31.360 --> 00:06:34.230
If you were to build a function
from scratch, you can see this.

110
00:06:34.230 --> 00:06:39.950
So then you create a group by function,
and then direct it at a column.

111
00:06:39.950 --> 00:06:41.120
You basically pass it to argument.

112
00:06:43.890 --> 00:06:47.856
To find out the occurrence
of each pairing of albums,

113
00:06:47.856 --> 00:06:52.188
we're going to go ahead and
look at this LR sheet.

114
00:06:52.188 --> 00:06:55.477
And so these are, we're using group
by functions as well here, so

115
00:06:55.477 --> 00:06:58.372
we're grouping by the first item one,
and then item two.

116
00:06:58.372 --> 00:07:00.088
And then, we're doing a group count,

117
00:07:00.088 --> 00:07:03.430
which is counting the frequency
of occurrences of those cells.

118
00:07:03.430 --> 00:07:06.350
Similarly, we're going to
do a similar thing but

119
00:07:06.350 --> 00:07:11.096
with the item two first now, and then
item one, and then doing a group count.

120
00:07:11.096 --> 00:07:13.780
And the reason is,
we don't care about the order.

121
00:07:13.780 --> 00:07:17.810
And so, we repeat this on the next sheet
reversing the order of the albums to make

122
00:07:17.810 --> 00:07:21.460
sure that we capture all the combinations
since the order doesn't matter to us.

123
00:07:24.260 --> 00:07:28.887
And then we use our unit sheet function
to append the second frequency

124
00:07:28.887 --> 00:07:34.140
counting sheet to the first frequency
counting sheet, as you can see here.

125
00:07:34.140 --> 00:07:36.962
It's drag and drop, of course, and
so we've connected them together.

126
00:07:36.962 --> 00:07:39.248
You can do multi-sheets but
in this case we only have two, right.

127
00:07:39.248 --> 00:07:42.260
So it's, okay.

128
00:07:42.260 --> 00:07:47.770
We ignore the co-occurrent set sheet as it
is currently not used in the final output.

129
00:07:47.770 --> 00:07:51.010
We were kind of experimenting
with other recommendation models.

130
00:07:51.010 --> 00:07:52.660
We're rebuilding those workbooks.

131
00:07:52.660 --> 00:07:56.780
So one of the really cool features for
we can execute the workbook, but

132
00:07:56.780 --> 00:07:59.162
deselect the storage of
intermediary sheets.

133
00:07:59.162 --> 00:08:02.958
This means that we only need
relevant functions are executed

134
00:08:02.958 --> 00:08:07.740
at a to the data lineage of columns that
are contained in the selector sheet.

135
00:08:07.740 --> 00:08:12.620
Moving on, we have to create
a separate sheet from the raw data,

136
00:08:12.620 --> 00:08:16.770
that counts the number of times an album
occurs across all of the purchases.

137
00:08:16.770 --> 00:08:20.780
So you can see here, which students will
buy an album and then we do a count.

138
00:08:24.890 --> 00:08:29.768
We bring the code occurrences and
the frequency together using the join

139
00:08:29.768 --> 00:08:33.599
feature as you can see,
it is a drag and drop interface.

140
00:08:33.599 --> 00:08:36.601
You got the obfuscated workbook
each of the worksheets here and

141
00:08:36.601 --> 00:08:39.100
within each worksheets,
you got various columns.

142
00:08:39.100 --> 00:08:45.484
You can bring those, you can drag and
drop them into here to do the joins.

143
00:08:45.484 --> 00:08:50.730
You can do different types of joins,
you got the inner, outer, etc.

144
00:08:50.730 --> 00:08:53.206
You can also do multi column joins.

145
00:08:53.206 --> 00:08:54.491
You can do multi sheet joins.

146
00:08:54.491 --> 00:08:59.168
You can also select which columns
you want to keep during the join.

147
00:08:59.168 --> 00:09:02.705
Go ahead and cancel out here.

148
00:09:02.705 --> 00:09:06.580
Datameer does not allow us to add
additional functions to a joint sheet so

149
00:09:06.580 --> 00:09:09.269
we duplicate it by right clicking and
then hitting the duplicate button.

150
00:09:11.820 --> 00:09:14.780
And then we create the next sheet,
which contains a link to columns, so

151
00:09:14.780 --> 00:09:17.570
it will be linked to the rating sheet.

152
00:09:17.570 --> 00:09:22.480
This is, see the link columns back
to the joint sheets and then.

153
00:09:23.760 --> 00:09:28.880
We simply add a calculation
where it's the number of times

154
00:09:28.880 --> 00:09:32.730
the co-occurrence occurs divided by
the number of times that the first album

155
00:09:32.730 --> 00:09:35.950
in the column appears
throughout the data set.

156
00:09:35.950 --> 00:09:40.284
The idea is to give a high recommendation
for albums that appear frequently

157
00:09:40.284 --> 00:09:44.503
together While simultaneously
penalizing albums that are too common.

158
00:09:44.503 --> 00:09:48.513
And so at this point,
I would like to write a few more joins

159
00:09:48.513 --> 00:09:51.773
that bring together the album ID,
the email,

160
00:09:51.773 --> 00:09:56.980
recommended album ID based on the album
ID and email, so take a look here.

161
00:09:59.310 --> 00:10:03.472
So, as you can see here and then,

162
00:10:03.472 --> 00:10:08.460
before we finish,
we also do an anti joint by performing

163
00:10:08.460 --> 00:10:14.170
the outer left joint with
the almighty in the email.

164
00:10:14.170 --> 00:10:18.830
And then filtering, so this is,
by the way, this is a double column joint.

165
00:10:20.090 --> 00:10:24.060
And then we do a filter, so
then we filter out all the, for

166
00:10:24.060 --> 00:10:26.840
the obfuscated owner
fields that are empty.

167
00:10:26.840 --> 00:10:30.192
We apply a filter to it.

168
00:10:30.192 --> 00:10:35.996
So finally, we use a few group I
functions to do some deep duplication,

169
00:10:35.996 --> 00:10:38.915
so we use group by functions again.

170
00:10:38.915 --> 00:10:42.637
And then, so we make sure that the album
functions are unique for each user and

171
00:10:42.637 --> 00:10:44.250
then we use a group max function.

172
00:10:45.780 --> 00:10:49.292
In order to preserve the highest
rating for each of the unique

173
00:10:50.950 --> 00:10:55.310
recommendations the final desired
output is on the recommenders sheet.

174
00:10:55.310 --> 00:11:01.710
It leverages the group top end function,
so you can see here group top numbers.

175
00:11:01.710 --> 00:11:05.349
So we only want to look at the to
20 recommendations for each user.

176
00:11:05.349 --> 00:11:09.759
And in addition,
we also create a email row number field,

177
00:11:09.759 --> 00:11:13.720
which is a key that needed for
salesforce.com, and

178
00:11:13.720 --> 00:11:18.142
it is generated by a simple
concatenation function here.

179
00:11:18.142 --> 00:11:22.642
Something that note that [SOUND] is
big on data governance, data lineage.

180
00:11:22.642 --> 00:11:26.632
As you can see, we can keep track of
how all the raw data flows through

181
00:11:26.632 --> 00:11:29.650
from the raw data set all
the way to the end product.

182
00:11:31.950 --> 00:11:36.651
So each workbook functions can be
also exported in JSON format to keep

183
00:11:36.651 --> 00:11:38.605
track of revision history.

184
00:11:38.605 --> 00:11:41.470
We're not ready to operationalize
things and so how do we do it?

185
00:11:41.470 --> 00:11:45.700
Get our workbook configurations.

186
00:11:45.700 --> 00:11:46.860
Go ahead and exit out of the workbook.

187
00:11:49.420 --> 00:11:50.710
Let's go back to
the production environment.

188
00:11:56.340 --> 00:11:57.128
As you can see,

189
00:11:57.128 --> 00:12:01.670
the workbook recalculation retriggers
when the import job is completed.

190
00:12:01.670 --> 00:12:03.820
We also only retain the latest results, so

191
00:12:03.820 --> 00:12:09.440
we select purge historical results,
as you can see here.

192
00:12:09.440 --> 00:12:14.970
As I mentioned earlier, a data mirror
makes it easy to operationalize a workbook

193
00:12:14.970 --> 00:12:17.630
because we only select
the final output sheets.

194
00:12:17.630 --> 00:12:21.000
And, so you see everything's unchecked
except for the recommended sheet.

195
00:12:22.730 --> 00:12:26.420
And Datameer basically will automatically
determine what is a critical path

196
00:12:26.420 --> 00:12:28.990
of the intermediary sheets to
produce the desired output sheet.

197
00:12:30.430 --> 00:12:33.031
Once the recommendation
workbook is calculated,

198
00:12:33.031 --> 00:12:35.029
then this triggers the export job run.

199
00:12:35.029 --> 00:12:38.032
I'm going to go ahead and
move to the export job artifact.

200
00:12:38.032 --> 00:12:40.194
Exit out of this.

201
00:12:40.194 --> 00:12:42.361
Go ahead and save, or not save.

202
00:12:42.361 --> 00:12:47.223
We'll see the export job,
let's go ahead and configure that.

203
00:12:52.087 --> 00:12:55.127
Hit Next, Share.

204
00:12:55.127 --> 00:13:00.240
CSV outputs, so.

205
00:13:02.817 --> 00:13:04.557
This triggers the export job to run,

206
00:13:04.557 --> 00:13:08.600
which is how we basically push
the results of the recommendations to S3.

207
00:13:08.600 --> 00:13:14.310
We elected to use S3 because we
are already hosting at services and

208
00:13:14.310 --> 00:13:16.630
S3 is an affordable storage solution.

209
00:13:16.630 --> 00:13:19.695
We cannot push directly to
salesforce.com at the present because

210
00:13:19.695 --> 00:13:22.920
It's a only connection.

211
00:13:22.920 --> 00:13:26.726
Therefore, we need to push
data to the storage area,

212
00:13:26.726 --> 00:13:30.123
which can be scheduled for using Apex.

213
00:13:30.123 --> 00:13:33.796
A general challenge for
is the role limitation on each pool.

214
00:13:33.796 --> 00:13:38.386
Fortunately, DataMirror comes
with the option to push

215
00:13:38.386 --> 00:13:41.873
files that are broken
into one megabyte chunks.

216
00:13:41.873 --> 00:13:46.796
So as you can see here in
advanced settings 1 megabyte, and

217
00:13:46.796 --> 00:13:51.140
then we set a type of
consecutive numbering scheme.

218
00:13:51.140 --> 00:13:53.852
And so it's dynamic naming conventions
using time stamps and numbering for

219
00:13:53.852 --> 00:13:55.530
each of the chunks.

220
00:13:55.530 --> 00:13:58.830
So that sums up the current
co-curds/d deployment.

221
00:13:58.830 --> 00:14:03.018
As you've seen, we have easily
integrated data from Salesforce.com,

222
00:14:03.018 --> 00:14:07.272
created a recommendation model, and
set up a push to S3 automatically for

223
00:14:07.272 --> 00:14:09.856
easy consumption back to Salesforce.com.

224
00:14:09.856 --> 00:14:13.469
Finally, we operationalized this by
triggering each of the steps sequentially

225
00:14:13.469 --> 00:14:16.297
all in sitting on top of
the powerful Hadoop platform.

226
00:14:16.297 --> 00:14:19.070
What's next?

227
00:14:19.070 --> 00:14:23.590
Well, Pono Music is working on
implementing Google Analytics tracking for

228
00:14:23.590 --> 00:14:26.450
each user at the Apple pages.

229
00:14:26.450 --> 00:14:29.450
So let's go back to
the Apple Music Store here.

230
00:14:29.450 --> 00:14:32.620
Just for an example, let's take a look
at the Train Led Zeppelin Two Album.

231
00:14:33.670 --> 00:14:36.650
As you can see all of those album
IDs that we were looking at earlier,

232
00:14:36.650 --> 00:14:38.390
these are actually embedded in the URL.

233
00:14:40.300 --> 00:14:44.517
This means that in the near future, we
can actually adapt recommendations based

234
00:14:44.517 --> 00:14:49.053
on the buying behavior to recommendations
based on both buying and browser behavior.

235
00:14:49.053 --> 00:14:53.313
We can look at recommendations based on
genre, perhaps we can try to look at most

236
00:14:53.313 --> 00:14:57.526
recent purchases or browsing behavior in
the last three to six to nine months.

237
00:14:57.526 --> 00:15:01.541
Or we could use album metadata such as
album release date to give additional

238
00:15:01.541 --> 00:15:03.270
recommendations.

239
00:15:03.270 --> 00:15:07.698
Also, it is quite simple to just
duplicate the recommendations workbook in

240
00:15:07.698 --> 00:15:10.409
[INAUDIBLE] to try any
number of these options.

241
00:15:10.409 --> 00:15:13.172
And so,
that means we can do a lot of AB testing,

242
00:15:13.172 --> 00:15:18.600
as we track how users react to each of
the modified recommendation algorithms.

243
00:15:18.600 --> 00:15:21.170
The possibilities are literally endless.

244
00:15:21.170 --> 00:15:24.051
So anyhow, thanks again for
checking out how Data Mirror

245
00:15:24.051 --> 00:15:27.305
builds a simple code current
recommendation engine for music.

246
00:15:27.305 --> 00:15:29.636
Please feel free to direction questions or

247
00:15:29.636 --> 00:15:32.492
comments to me at
victor.liu@datamirror.com.

248
00:15:32.492 --> 00:15:34.220
Thanks again.