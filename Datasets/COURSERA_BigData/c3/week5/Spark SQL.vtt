WEBVTT

1
00:00:02.072 --> 00:00:04.356
Over the next couple of videos,

2
00:00:04.356 --> 00:00:09.020
we will introduce you to the basic
components of the Spark stack.

3
00:00:10.660 --> 00:00:13.440
In this lecture, we start with Spark SQL.

4
00:00:15.000 --> 00:00:20.610
After this video, you will be able to
process structured data using Spark's SQL

5
00:00:20.610 --> 00:00:25.140
module and explain the numerous
benefits of Spark SQL.

6
00:00:28.240 --> 00:00:34.150
Spark SQL is the component of Spark
that enables querying structured and

7
00:00:34.150 --> 00:00:37.510
unstructured data through
a common query language.

8
00:00:38.630 --> 00:00:43.720
It can connect to many data sources and
provides APIs to convert

9
00:00:43.720 --> 00:00:48.430
the query results to RDDs in Python,
Scala, and Java programs.

10
00:00:50.670 --> 00:00:53.991
Spark SQL gives a mechanism for

11
00:00:53.991 --> 00:00:58.467
SQL users to deploy SQL queries on Spark.

12
00:01:01.047 --> 00:01:05.806
Spark SQL enables business
intelligence tools to connect to

13
00:01:05.806 --> 00:01:10.854
Spark using standard connection
protocols like JDBC and ODBC.

14
00:01:13.379 --> 00:01:18.346
Spark SQL also provides APIs to
convert the query data into DataFrames

15
00:01:18.346 --> 00:01:20.290
to hold distributed data.

16
00:01:21.410 --> 00:01:26.757
DataFrames are organized as named
columns and basically look like tables.

17
00:01:30.248 --> 00:01:36.320
The first step to run any SQL Spark
is to create a SQLContext.

18
00:01:38.580 --> 00:01:43.360
Once you have an SQLContext,
you want to leverage it

19
00:01:43.360 --> 00:01:48.200
to create a DataFrame so you can deploy
complex operations on the data set.

20
00:01:49.200 --> 00:01:52.480
DataFrames can be created
from existing RDDs,

21
00:01:52.480 --> 00:01:55.270
Hive tables or many other data sources.

22
00:01:57.910 --> 00:02:05.020
A file can be read and converted into
a DataFrame using a single command.

23
00:02:06.610 --> 00:02:14.440
The show function here will display
the DataFrame in your Spark show.

24
00:02:14.440 --> 00:02:18.950
RDDs can be converted to DataFrames but
require a little more work.

25
00:02:19.980 --> 00:02:23.130
First you will have to
convert each line into a row.

26
00:02:24.410 --> 00:02:28.640
Once your data is in a DataFrame,
you can perform all sorts of

27
00:02:28.640 --> 00:02:33.640
transformation operations on it
as shown here, including show,

28
00:02:33.640 --> 00:02:37.590
printSchema, select, filter and groupBy.

29
00:02:39.850 --> 00:02:44.910
To summarize, Spark SQL lets you
run relational queries on Spark.

30
00:02:46.500 --> 00:02:51.110
It also lets you connect to
a variety of databases, and

31
00:02:51.110 --> 00:02:54.750
deploy business intelligence
tools over Spark.

32
00:02:54.750 --> 00:02:58.707
We will go through some of this
functionality in one of the readings and

33
00:02:58.707 --> 00:03:00.795
in the upcoming hands-on session.