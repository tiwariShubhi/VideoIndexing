1
00:00:00,469 --> 00:00:03,360
hi and welcome to the machine learning

2
00:00:03,360 --> 00:00:06,569
peek of the grief and audacity so we're

3
00:00:06,569 --> 00:00:08,639
going to talk about today is what is

4
00:00:08,639 --> 00:00:12,420
machine learning well this is the world

5
00:00:12,420 --> 00:00:15,660
and in the world we add humans and we

6
00:00:15,660 --> 00:00:17,970
got computers and one of the main

7
00:00:17,970 --> 00:00:19,500
differences between humans and computers

8
00:00:19,500 --> 00:00:21,510
is that humans learn from past

9
00:00:21,510 --> 00:00:23,369
experience whereas computers need to be

10
00:00:23,369 --> 00:00:25,859
told what to do need to be programmed so

11
00:00:25,859 --> 00:00:27,750
they follow instructions now the

12
00:00:27,750 --> 00:00:29,519
question is can we get computers to

13
00:00:29,519 --> 00:00:32,668
learn from experience too and the answer

14
00:00:32,668 --> 00:00:35,250
is yes we can and that's precisely with

15
00:00:35,250 --> 00:00:37,770
machine learning is of course for

16
00:00:37,770 --> 00:00:39,510
computers fast experiences have a name

17
00:00:39,510 --> 00:00:42,390
called data so in the next few minutes

18
00:00:42,390 --> 00:00:44,489
I'm going to show you a few examples in

19
00:00:44,489 --> 00:00:46,800
which we can teach the computer how to

20
00:00:46,800 --> 00:00:49,440
learn from previous data and most

21
00:00:49,440 --> 00:00:50,550
importantly I'm going to show you that

22
00:00:50,550 --> 00:00:51,899
these algorithms are actually pretty

23
00:00:51,899 --> 00:00:54,120
easy and the machine learning is really

24
00:00:54,120 --> 00:00:58,770
nothing to fear so let's go to the first

25
00:00:58,770 --> 00:01:00,210
example let's say we're studying the

26
00:01:00,210 --> 00:01:02,940
housing market on our task is to predict

27
00:01:02,940 --> 00:01:05,729
the price of a house given its size so

28
00:01:05,729 --> 00:01:08,210
we have a small house that cost $70,000

29
00:01:08,210 --> 00:01:10,560
we have a big house that cost one

30
00:01:10,560 --> 00:01:12,380
hundred and sixty thousand dollars and

31
00:01:12,380 --> 00:01:14,820
we'd like to estimate the price of this

32
00:01:14,820 --> 00:01:18,119
medium-sized house here so how do we do

33
00:01:18,119 --> 00:01:20,850
it well first put them in a grid where

34
00:01:20,850 --> 00:01:22,740
the x-axis represents the size of the

35
00:01:22,740 --> 00:01:25,290
house and square feet and the y-axis

36
00:01:25,290 --> 00:01:27,210
represents the price of the house and

37
00:01:27,210 --> 00:01:29,909
dollars and so to help us out we have

38
00:01:29,909 --> 00:01:31,650
collected some previous data in the form

39
00:01:31,650 --> 00:01:34,049
of these blue dots these are other

40
00:01:34,049 --> 00:01:35,520
houses that we've looked at and we've

41
00:01:35,520 --> 00:01:37,619
recorded their prices with respect to

42
00:01:37,619 --> 00:01:40,740
their size so in this graph we can see

43
00:01:40,740 --> 00:01:43,170
that the small house is priced $70,000

44
00:01:43,170 --> 00:01:45,840
and the big house is priced at a hundred

45
00:01:45,840 --> 00:01:48,659
and sixty thousand dollars so now it's

46
00:01:48,659 --> 00:01:51,509
time for a small quiz what do you think

47
00:01:51,509 --> 00:01:54,509
is the best guess for the price of the

48
00:01:54,509 --> 00:01:58,950
medium house given this data would it be

49
00:01:58,950 --> 00:02:01,020
a thousand dollars one hundred and

50
00:02:01,020 --> 00:02:03,030
twenty thousand dollars or one hundred

51
00:02:03,030 --> 00:02:07,350
and ninety thousand dollars well to help

52
00:02:07,350 --> 00:02:09,119
us out we can see that these blue points

53
00:02:09,119 --> 00:02:11,370
kind of form a line so we can draw the

54
00:02:11,370 --> 00:02:13,290
line that best fits the data

55
00:02:13,290 --> 00:02:15,810
now in this line we can say that our

56
00:02:15,810 --> 00:02:18,150
best guess for the price of the house is

57
00:02:18,150 --> 00:02:21,269
this point over here which corresponds

58
00:02:21,269 --> 00:02:22,500
to one hundred and twenty thousand

59
00:02:22,500 --> 00:02:24,569
dollars so if you set one hundred and

60
00:02:24,569 --> 00:02:27,120
twenty thousand dollars that is correct

61
00:02:27,120 --> 00:02:29,220
this method is known as linear

62
00:02:29,220 --> 00:02:33,180
regression now you may ask how do we

63
00:02:33,180 --> 00:02:37,440
find this line well let's look at a

64
00:02:37,440 --> 00:02:41,010
simple example this three points we're

65
00:02:41,010 --> 00:02:42,900
going to try to find the best line that

66
00:02:42,900 --> 00:02:44,040
fits through those three points

67
00:02:44,040 --> 00:02:46,980
obviously best line is subjective while

68
00:02:46,980 --> 00:02:49,099
we try to find a line that works well

69
00:02:49,099 --> 00:02:51,120
since we're teaching the computer how to

70
00:02:51,120 --> 00:02:53,010
do it computer can't really eyeball the

71
00:02:53,010 --> 00:02:55,079
line so you have to get it to draw a

72
00:02:55,079 --> 00:02:58,109
random line and then see how bad this

73
00:02:58,109 --> 00:03:00,720
line is so in order to see how bad the

74
00:03:00,720 --> 00:03:04,590
line is we calculate the error so we're

75
00:03:04,590 --> 00:03:07,319
gonna for calculate the error look at

76
00:03:07,319 --> 00:03:09,060
the lengths of the distances from the

77
00:03:09,060 --> 00:03:11,970
line to the three points and we're just

78
00:03:11,970 --> 00:03:13,349
going to simply say that the error of

79
00:03:13,349 --> 00:03:15,659
this line is the sum of those three red

80
00:03:15,659 --> 00:03:18,690
lengths now what we're going to do is

81
00:03:18,690 --> 00:03:21,359
move the line around and see if we can

82
00:03:21,359 --> 00:03:23,970
reduce this error so let's say we moved

83
00:03:23,970 --> 00:03:26,579
in this direction and we calculate the

84
00:03:26,579 --> 00:03:28,400
error it's given by the yellow distances

85
00:03:28,400 --> 00:03:31,980
we add them up and realize that we've

86
00:03:31,980 --> 00:03:33,930
increased the error so that's not a good

87
00:03:33,930 --> 00:03:36,419
direction to go let's try moving the

88
00:03:36,419 --> 00:03:39,079
other direction we move it here

89
00:03:39,079 --> 00:03:41,190
calculate the error now it's given by

90
00:03:41,190 --> 00:03:43,260
the sum of these three green distances

91
00:03:43,260 --> 00:03:46,379
and we see that the error is smaller so

92
00:03:46,379 --> 00:03:49,139
we actually reduced it so let's say we

93
00:03:49,139 --> 00:03:51,000
take that step we're a little closer to

94
00:03:51,000 --> 00:03:53,129
our solution if we continue doing this

95
00:03:53,129 --> 00:03:55,500
procedure several times we will always

96
00:03:55,500 --> 00:03:57,299
be decreasing the error and we'll

97
00:03:57,299 --> 00:03:59,310
finally arrive to a good solution in the

98
00:03:59,310 --> 00:04:01,949
form of this line this general procedure

99
00:04:01,949 --> 00:04:05,459
is known as gradient descent now in real

100
00:04:05,459 --> 00:04:07,650
life we don't want to deal with negative

101
00:04:07,650 --> 00:04:10,049
distances corresponding to a point being

102
00:04:10,049 --> 00:04:12,269
on one or the other side of the line so

103
00:04:12,269 --> 00:04:14,370
what we do to solve this is add the

104
00:04:14,370 --> 00:04:16,620
square of the distance from the point to

105
00:04:16,620 --> 00:04:19,048
the line instead and this procedure is

106
00:04:19,048 --> 00:04:22,400
called least squares

107
00:04:25,210 --> 00:04:27,439
so we're going to cover in the census

108
00:04:27,439 --> 00:04:29,509
trying to the central mountain this is

109
00:04:29,509 --> 00:04:32,930
our Mountain Mount Everest this mounting

110
00:04:32,930 --> 00:04:36,169
the hi we are the larger error is so

111
00:04:36,169 --> 00:04:39,860
descending means reducing the error so

112
00:04:39,860 --> 00:04:40,939
what are we doing the credit the

113
00:04:40,939 --> 00:04:42,800
cinematic well look at our surroundings

114
00:04:42,800 --> 00:04:44,900
and try to figure out which way we can

115
00:04:44,900 --> 00:04:47,240
descend more for example here we can go

116
00:04:47,240 --> 00:04:48,979
in two directions to the right or to the

117
00:04:48,979 --> 00:04:52,430
left let's go to the left then we're

118
00:04:52,430 --> 00:04:56,090
going up insert error is ascending this

119
00:04:56,090 --> 00:04:57,289
is equivalent to moving the line

120
00:04:57,289 --> 00:04:58,879
downwards and getting farther from the

121
00:04:58,879 --> 00:05:01,789
three points but if we go to the right

122
00:05:01,789 --> 00:05:03,889
instead then we're actually descending

123
00:05:03,889 --> 00:05:07,039
which means our error is decreasing this

124
00:05:07,039 --> 00:05:08,930
is equivalent to moving the line upwards

125
00:05:08,930 --> 00:05:10,639
and getting closer to the three points

126
00:05:10,639 --> 00:05:13,099
so we decide to take a step towards or

127
00:05:13,099 --> 00:05:15,529
right then we can start this procedure

128
00:05:15,529 --> 00:05:17,930
again and again and again until we

129
00:05:17,930 --> 00:05:19,789
successfully descend from the mountain

130
00:05:19,789 --> 00:05:22,279
this is equivalent to reducing the error

131
00:05:22,279 --> 00:05:24,860
until we find its minimum value which

132
00:05:24,860 --> 00:05:30,589
gives us the best line fit so you can

133
00:05:30,589 --> 00:05:32,060
think of linear regression as a painter

134
00:05:32,060 --> 00:05:34,490
and will look at your data and draw the

135
00:05:34,490 --> 00:05:37,250
best fitting line now this method is

136
00:05:37,250 --> 00:05:38,930
actually much stronger if the data

137
00:05:38,930 --> 00:05:41,300
doesn't form a line with a very very

138
00:05:41,300 --> 00:05:42,710
similar method we can draw a circle

139
00:05:42,710 --> 00:05:46,279
through it or a parabola or even a

140
00:05:46,279 --> 00:05:49,250
higher degree curve for example the data

141
00:05:49,250 --> 00:05:50,659
here we can actually fit a cubic

142
00:05:50,659 --> 00:05:57,919
polynomial okay so let's move to the

143
00:05:57,919 --> 00:06:00,589
next example in this example we're going

144
00:06:00,589 --> 00:06:02,620
to build an email spam detection

145
00:06:02,620 --> 00:06:04,849
classifier so something that will tell

146
00:06:04,849 --> 00:06:08,900
us if an email is spam or not and how do

147
00:06:08,900 --> 00:06:10,759
we do this we do this by looking at

148
00:06:10,759 --> 00:06:14,000
previous data the previous data is 100

149
00:06:14,000 --> 00:06:17,389
emails that we looked at already out of

150
00:06:17,389 --> 00:06:20,389
these 100 emails we have flagged 25 of

151
00:06:20,389 --> 00:06:24,460
them are spam and 75 of them is not spam

152
00:06:24,460 --> 00:06:26,750
now let's try to think of features of

153
00:06:26,750 --> 00:06:29,770
spam emails may be likely to display and

154
00:06:29,770 --> 00:06:33,020
analyze these features so one feature

155
00:06:33,020 --> 00:06:35,759
could be containing the word cheap

156
00:06:35,759 --> 00:06:37,800
seems reasonable to think that an email

157
00:06:37,800 --> 00:06:39,629
containing the word cheap is likely to

158
00:06:39,629 --> 00:06:43,409
be spam so let's analyze this claim we

159
00:06:43,409 --> 00:06:45,539
look for the word cheap in all these 100

160
00:06:45,539 --> 00:06:48,330
emails and find that 20 out of spam

161
00:06:48,330 --> 00:06:50,759
loads and 5 out of the non spam ones

162
00:06:50,759 --> 00:06:53,909
contain that word so we can forget about

163
00:06:53,909 --> 00:06:56,400
all the rest of the emails and focus

164
00:06:56,400 --> 00:06:58,439
only on the ones that contain the word

165
00:06:58,439 --> 00:07:03,839
cheap okay so time for a quiz here's the

166
00:07:03,839 --> 00:07:08,550
question based on our data if an email

167
00:07:08,550 --> 00:07:11,069
contains the word cheap what is the

168
00:07:11,069 --> 00:07:13,969
probability of this email being spam is

169
00:07:13,969 --> 00:07:23,849
it 40% 60% or 80% well to help us out we

170
00:07:23,849 --> 00:07:26,490
can see that out of the 25 emails with

171
00:07:26,490 --> 00:07:29,580
the word cheap 20 of them are spam while

172
00:07:29,580 --> 00:07:34,649
5 of them are not so these form an 80/20

173
00:07:34,649 --> 00:07:38,069
split so the correct answer with 80

174
00:07:38,069 --> 00:07:41,789
if you said 80 you were correct so from

175
00:07:41,789 --> 00:07:43,319
analyzing the data we can conclude a

176
00:07:43,319 --> 00:07:46,020
rule the rule says if an email contains

177
00:07:46,020 --> 00:07:48,899
the word cheap then we're going to say

178
00:07:48,899 --> 00:07:52,849
the probability of it being spam is 80%

179
00:07:52,849 --> 00:07:56,009
so we then associate this feature with

180
00:07:56,009 --> 00:07:58,620
the probability 80% and we're going to

181
00:07:58,620 --> 00:08:01,529
use it to flag future messages as spam

182
00:08:01,529 --> 00:08:04,860
or not spam we can also look at other

183
00:08:04,860 --> 00:08:06,959
features and try to find our Associated

184
00:08:06,959 --> 00:08:09,149
probability let's say we look at emails

185
00:08:09,149 --> 00:08:10,559
containing a spelling mistake and

186
00:08:10,559 --> 00:08:12,180
realize that the probability of an email

187
00:08:12,180 --> 00:08:14,399
containing a spelling mistake being spam

188
00:08:14,399 --> 00:08:17,789
is 70% or let's say we look at emails

189
00:08:17,789 --> 00:08:20,370
that are missing a title and find the

190
00:08:20,370 --> 00:08:22,939
probability of those being spam is 95%

191
00:08:22,939 --> 00:08:27,059
etc etc so now when future emails come

192
00:08:27,059 --> 00:08:28,559
we can combine these features to guess

193
00:08:28,559 --> 00:08:31,319
their spam or not this algorithm is

194
00:08:31,319 --> 00:08:36,779
known as the naive Bayes algorithm okay

195
00:08:36,779 --> 00:08:39,779
so now another example we are the App

196
00:08:39,779 --> 00:08:43,500
Store or Google Play and our goal is to

197
00:08:43,500 --> 00:08:46,079
recommend apps to users so to each user

198
00:08:46,079 --> 00:08:48,230
we're going to try to recommend them

199
00:08:48,230 --> 00:08:49,850
app that they are most likely to

200
00:08:49,850 --> 00:08:52,520
download we have gathered a table of

201
00:08:52,520 --> 00:08:54,200
data that we're going to use to make the

202
00:08:54,200 --> 00:08:57,880
rules on the table contains six people

203
00:08:57,880 --> 00:09:00,320
for each one of those six people we have

204
00:09:00,320 --> 00:09:02,600
recorded their gender and their age and

205
00:09:02,600 --> 00:09:05,560
the app they downloaded so for example

206
00:09:05,560 --> 00:09:08,570
the first person is a 15 year old female

207
00:09:08,570 --> 00:09:13,550
and she downloaded pokemon gold so

208
00:09:13,550 --> 00:09:15,860
here's a small quiz between gender and

209
00:09:15,860 --> 00:09:18,500
age which one seems like the more

210
00:09:18,500 --> 00:09:20,930
decisive feature for predicting what app

211
00:09:20,930 --> 00:09:27,980
will be users download well to help us

212
00:09:27,980 --> 00:09:30,680
out first let's look at gender if we

213
00:09:30,680 --> 00:09:32,360
split them by gender than the females

214
00:09:32,360 --> 00:09:34,220
downloaded Pokemon go on whatsapp

215
00:09:34,220 --> 00:09:36,140
whereas the male is downloaded Pokemon

216
00:09:36,140 --> 00:09:38,390
go and snapchat so not much for split

217
00:09:38,390 --> 00:09:42,500
here on the other hand if we look at age

218
00:09:42,500 --> 00:09:44,990
we realize that everybody who's under 20

219
00:09:44,990 --> 00:09:46,810
years old downloaded pokemon gold

220
00:09:46,810 --> 00:09:49,730
whereas everybody who is 20 or older

221
00:09:49,730 --> 00:09:50,750
didn't

222
00:09:50,750 --> 00:09:53,870
that's a nice split so the feature the

223
00:09:53,870 --> 00:09:57,410
best splits the data is H therefore if

224
00:09:57,410 --> 00:10:00,350
you said age that was correct so we're

225
00:10:00,350 --> 00:10:01,490
going to do is we're going to add a

226
00:10:01,490 --> 00:10:05,270
question here the question is are you

227
00:10:05,270 --> 00:10:08,930
younger than 20 if yes then we'll

228
00:10:08,930 --> 00:10:11,660
recommend Pokemon go to you if not then

229
00:10:11,660 --> 00:10:14,930
we'll see so what happens if you're 20

230
00:10:14,930 --> 00:10:17,750
or older then we look at the gender it

231
00:10:17,750 --> 00:10:19,720
seems like here if you're a female

232
00:10:19,720 --> 00:10:22,760
you've downloaded what's up whereas if

233
00:10:22,760 --> 00:10:25,510
you're a male you download it snapchat

234
00:10:25,510 --> 00:10:28,190
so we add another question here the

235
00:10:28,190 --> 00:10:31,640
question is are you female or male and

236
00:10:31,640 --> 00:10:32,300
if you're female

237
00:10:32,300 --> 00:10:34,970
we recommend what's up and if you're

238
00:10:34,970 --> 00:10:40,250
male then we recommend snapchat so what

239
00:10:40,250 --> 00:10:42,500
we end up here is with a decision tree

240
00:10:42,500 --> 00:10:44,750
and the decisions are given by the

241
00:10:44,750 --> 00:10:48,140
question we asked and this decision tree

242
00:10:48,140 --> 00:10:51,770
was built with the data and now whenever

243
00:10:51,770 --> 00:10:53,630
we have any user we can put them to the

244
00:10:53,630 --> 00:10:55,760
decision tree and recommend them

245
00:10:55,760 --> 00:10:57,260
whatever app the tree suggests is to

246
00:10:57,260 --> 00:11:00,290
recommend for example you have a young

247
00:11:00,290 --> 00:11:01,449
person

248
00:11:01,449 --> 00:11:05,269
you recommend them Pokemon go if you

249
00:11:05,269 --> 00:11:06,680
have an older person you check their

250
00:11:06,680 --> 00:11:09,199
gender if it's a female you recommend

251
00:11:09,199 --> 00:11:13,790
them what's up and it's a male you

252
00:11:13,790 --> 00:11:18,589
recommend them snapchat obviously there

253
00:11:18,589 --> 00:11:20,990
won't always be a tree that perfectly

254
00:11:20,990 --> 00:11:23,209
fits our data but in this class we're

255
00:11:23,209 --> 00:11:24,319
going to learn an algorithm which

256
00:11:24,319 --> 00:11:25,879
actually will help us find the best

257
00:11:25,879 --> 00:11:33,620
fitting tree to your table of data okay

258
00:11:33,620 --> 00:11:35,990
so let's go to the next example

259
00:11:35,990 --> 00:11:37,430
now let's say we're the admissions

260
00:11:37,430 --> 00:11:39,620
office at a university and we're trying

261
00:11:39,620 --> 00:11:41,240
to figure out which students to admit

262
00:11:41,240 --> 00:11:43,370
we're going to admit them or reject them

263
00:11:43,370 --> 00:11:46,670
based on two pieces of information one

264
00:11:46,670 --> 00:11:48,769
is an entrance exam that we provide them

265
00:11:48,769 --> 00:11:52,069
the test and the other one is their

266
00:11:52,069 --> 00:11:56,749
grades from school so for example here

267
00:11:56,749 --> 00:11:59,360
we have student 1 with scores of 9 out

268
00:11:59,360 --> 00:12:02,389
of 10 in the test and 8 out of 10 and

269
00:12:02,389 --> 00:12:05,769
the grades and that student got accepted

270
00:12:05,769 --> 00:12:09,319
we also have student 2 with scores a 3

271
00:12:09,319 --> 00:12:11,809
in the test and 4 in the grades and that

272
00:12:11,809 --> 00:12:14,870
student did not get accepted and then a

273
00:12:14,870 --> 00:12:17,689
new student comes in student 3 this

274
00:12:17,689 --> 00:12:20,089
person has a son has scores of 7 and 6

275
00:12:20,089 --> 00:12:22,730
and the question is should we accept

276
00:12:22,730 --> 00:12:24,879
them or not

277
00:12:24,879 --> 00:12:28,129
so let's first put them in a grid or the

278
00:12:28,129 --> 00:12:30,350
x-axis represents our score on the tests

279
00:12:30,350 --> 00:12:32,920
and the y-axis represents their grades

280
00:12:32,920 --> 00:12:36,110
here we can see that student 1 would lie

281
00:12:36,110 --> 00:12:37,100
over here in the point with coordinates

282
00:12:37,100 --> 00:12:40,579
9 8 since their scores were 9 and 8 and

283
00:12:40,579 --> 00:12:43,100
the student 2 would lie right here in

284
00:12:43,100 --> 00:12:45,889
the point with coordinates 3 4 since

285
00:12:45,889 --> 00:12:48,740
their scores were 3 & 4 so in order to

286
00:12:48,740 --> 00:12:50,360
see if we should accept or reject Stu

287
00:12:50,360 --> 00:12:52,579
and 3 we should try to find it training

288
00:12:52,579 --> 00:12:54,589
that data so we look at the previous

289
00:12:54,589 --> 00:12:56,839
data in the form of all the students

290
00:12:56,839 --> 00:12:59,149
we've already accepted or rejected and

291
00:12:59,149 --> 00:13:00,529
it turns out that the previous data

292
00:13:00,529 --> 00:13:03,339
looks like this the green dots represent

293
00:13:03,339 --> 00:13:05,660
students that we've previously accepted

294
00:13:05,660 --> 00:13:08,509
and the red dots represent students that

295
00:13:08,509 --> 00:13:11,809
we've previously rejected so time for a

296
00:13:11,809 --> 00:13:12,980
quiz

297
00:13:12,980 --> 00:13:15,500
based on the previous data do we think

298
00:13:15,500 --> 00:13:21,620
student 3 gets accepted yes or no so to

299
00:13:21,620 --> 00:13:23,360
answer this question let's look closely

300
00:13:23,360 --> 00:13:25,880
at the data the red and green dots seem

301
00:13:25,880 --> 00:13:29,690
to be nicely separated by a line here's

302
00:13:29,690 --> 00:13:32,630
the line and most of the points over at

303
00:13:32,630 --> 00:13:35,240
are green and most of the points under

304
00:13:35,240 --> 00:13:37,700
it are red with some exceptions which

305
00:13:37,700 --> 00:13:39,530
makes sense since the students who got

306
00:13:39,530 --> 00:13:41,450
high scores are over the line and they

307
00:13:41,450 --> 00:13:42,980
got accepted in soon so what lowest

308
00:13:42,980 --> 00:13:44,780
scores are under the line and they

309
00:13:44,780 --> 00:13:45,980
didn't get accepted so we're going to

310
00:13:45,980 --> 00:13:47,450
say that that line is going to be our

311
00:13:47,450 --> 00:13:49,790
model and now every time we get a new

312
00:13:49,790 --> 00:13:52,400
student we check their scores and plot

313
00:13:52,400 --> 00:13:53,690
them in this graph and if they end up

314
00:13:53,690 --> 00:13:55,700
over the line we predict that they'll

315
00:13:55,700 --> 00:13:57,920
get accepted and if they end up below

316
00:13:57,920 --> 00:13:59,000
the line we predict that they'll get

317
00:13:59,000 --> 00:14:03,500
rejected so since students 3 has grades

318
00:14:03,500 --> 00:14:07,460
7 and 6 a person will end up here at the

319
00:14:07,460 --> 00:14:09,890
point 7 6 which is over the line so we

320
00:14:09,890 --> 00:14:11,030
conclude that this students gets

321
00:14:11,030 --> 00:14:13,550
accepted so if you said yes that's a

322
00:14:13,550 --> 00:14:16,670
correct answer this method is known as

323
00:14:16,670 --> 00:14:22,040
logistic regression another question is

324
00:14:22,040 --> 00:14:24,920
how do you find this line that best cuts

325
00:14:24,920 --> 00:14:28,430
the data and - so let's look at a simple

326
00:14:28,430 --> 00:14:31,970
example is 6 points 3 Green 3 red and

327
00:14:31,970 --> 00:14:33,980
we're going to try to draw a line that

328
00:14:33,980 --> 00:14:35,780
best separates the green points from the

329
00:14:35,780 --> 00:14:38,420
red points and again a computer can't

330
00:14:38,420 --> 00:14:40,160
really eyeball the line so you can just

331
00:14:40,160 --> 00:14:41,870
start by drawing a random line like this

332
00:14:41,870 --> 00:14:45,860
one and given this line let's just

333
00:14:45,860 --> 00:14:47,660
randomly say that we label the region

334
00:14:47,660 --> 00:14:49,610
over the line is green and the region

335
00:14:49,610 --> 00:14:52,910
under line is red so just like with

336
00:14:52,910 --> 00:14:54,470
linear regression we're going to try to

337
00:14:54,470 --> 00:14:58,490
see how bad this first line is and the

338
00:14:58,490 --> 00:15:01,340
measure of how bad the line is would be

339
00:15:01,340 --> 00:15:03,650
how many points are we miss classifying

340
00:15:03,650 --> 00:15:05,240
we're going to call that number

341
00:15:05,240 --> 00:15:09,110
misclassified points the error this line

342
00:15:09,110 --> 00:15:12,980
for example misclassified two points one

343
00:15:12,980 --> 00:15:16,760
red and one green so we'll say that it

344
00:15:16,760 --> 00:15:20,210
has two errors so again like with linear

345
00:15:20,210 --> 00:15:22,970
regression what we'll do is move the

346
00:15:22,970 --> 00:15:24,270
line around

347
00:15:24,270 --> 00:15:25,890
and try to minimize the number of errors

348
00:15:25,890 --> 00:15:29,459
using gradient descent so I've removed

349
00:15:29,459 --> 00:15:31,170
the line a bit in this direction we can

350
00:15:31,170 --> 00:15:32,850
see that we start correctly classifying

351
00:15:32,850 --> 00:15:34,110
one of the points bringing down the

352
00:15:34,110 --> 00:15:37,050
number of errors to one and if we move

353
00:15:37,050 --> 00:15:38,820
it a little more correctly classify the

354
00:15:38,820 --> 00:15:40,200
other one of the points bringing down

355
00:15:40,200 --> 00:15:44,040
the number of errors to zero in reality

356
00:15:44,040 --> 00:15:45,839
since we use calculus for a gradient

357
00:15:45,839 --> 00:15:47,820
descent method it turns out that the

358
00:15:47,820 --> 00:15:49,770
number of errors is not what we need to

359
00:15:49,770 --> 00:15:52,350
minimize but instead something that

360
00:15:52,350 --> 00:15:54,600
captures the number of errors called the

361
00:15:54,600 --> 00:15:57,300
log loss function and the idea behind

362
00:15:57,300 --> 00:15:58,950
the log loss function is that it's a

363
00:15:58,950 --> 00:16:01,680
function which assigns a large value to

364
00:16:01,680 --> 00:16:03,839
the misclassified points and a small

365
00:16:03,839 --> 00:16:10,770
value to the classified points ok so

366
00:16:10,770 --> 00:16:12,540
let's look more carefully at this model

367
00:16:12,540 --> 00:16:14,089
for accepting or rejecting students

368
00:16:14,089 --> 00:16:16,649
let's say we have a student for who got

369
00:16:16,649 --> 00:16:19,940
nine in the test and one on the grades

370
00:16:19,940 --> 00:16:22,110
so the student gets accepted according

371
00:16:22,110 --> 00:16:24,120
to our model since they are over here on

372
00:16:24,120 --> 00:16:27,000
top of the line but that seems wrong

373
00:16:27,000 --> 00:16:28,920
since I student got very low grades you

374
00:16:28,920 --> 00:16:30,300
can get accepted no matter what their

375
00:16:30,300 --> 00:16:32,760
test score was so maybe it's simplistic

376
00:16:32,760 --> 00:16:34,620
to think this data can be separated by

377
00:16:34,620 --> 00:16:37,050
just one line right maybe the real data

378
00:16:37,050 --> 00:16:39,180
should look more like this where these

379
00:16:39,180 --> 00:16:40,170
students over here

380
00:16:40,170 --> 00:16:41,820
we've got a load test score or low

381
00:16:41,820 --> 00:16:46,290
grades don't get accepted so now it

382
00:16:46,290 --> 00:16:48,120
seems like a line won't cut the data

383
00:16:48,120 --> 00:16:50,940
into so what's the next thing after a

384
00:16:50,940 --> 00:16:54,500
line maybe a circle circle could work

385
00:16:54,500 --> 00:16:58,970
maybe two lines that could work too

386
00:16:58,970 --> 00:17:00,810
actually it looks like that works better

387
00:17:00,810 --> 00:17:03,959
so let's go with that now the question

388
00:17:03,959 --> 00:17:07,079
is how do we find these two lines again

389
00:17:07,079 --> 00:17:09,929
we can do it using gradient descent to

390
00:17:09,929 --> 00:17:11,790
minimize a similar log loss function at

391
00:17:11,790 --> 00:17:19,939
the for this is called a neural network

392
00:17:19,939 --> 00:17:22,410
now why is it called a neural network

393
00:17:22,410 --> 00:17:25,140
well let's see we have this green area

394
00:17:25,140 --> 00:17:28,590
here by and about two lines this area

395
00:17:28,590 --> 00:17:30,120
can be constructed as an intersection

396
00:17:30,120 --> 00:17:31,830
namely the intersection between the

397
00:17:31,830 --> 00:17:34,620
green area on top of one lines and the

398
00:17:34,620 --> 00:17:36,059
green area to the right of the other one

399
00:17:36,059 --> 00:17:37,450
of the lines so

400
00:17:37,450 --> 00:17:38,799
we're going to graph it like this we

401
00:17:38,799 --> 00:17:42,100
have two nodes each node is a line that

402
00:17:42,100 --> 00:17:44,200
separates the plane into two regions and

403
00:17:44,200 --> 00:17:46,179
from the two nodes we get the

404
00:17:46,179 --> 00:17:48,480
intersection which is the desired area

405
00:17:48,480 --> 00:17:50,590
the reason why this is called the neural

406
00:17:50,590 --> 00:17:52,149
network is because this mimics the

407
00:17:52,149 --> 00:17:55,570
behavior the brain in the brain we have

408
00:17:55,570 --> 00:17:57,399
the neurons which connect to each other

409
00:17:57,399 --> 00:18:00,480
and they either fire electricity or not

410
00:18:00,480 --> 00:18:02,769
they resemble the nodes in our graph

411
00:18:02,769 --> 00:18:04,450
which split the plane into regions and

412
00:18:04,450 --> 00:18:06,519
fire electricity for given point belongs

413
00:18:06,519 --> 00:18:08,230
to one of those regions and won't fire

414
00:18:08,230 --> 00:18:14,799
if it doesn't so we can't explain your

415
00:18:14,799 --> 00:18:16,840
aggression as a ninja we'll look at your

416
00:18:16,840 --> 00:18:18,850
data and cut it in half based on the

417
00:18:18,850 --> 00:18:21,309
labels and we can think of a neural

418
00:18:21,309 --> 00:18:23,139
network as a team of ninjas who will

419
00:18:23,139 --> 00:18:25,090
look at your data and cut it into

420
00:18:25,090 --> 00:18:29,019
regions based on the labels okay

421
00:18:29,019 --> 00:18:31,510
so let's dive a bit deeper into the art

422
00:18:31,510 --> 00:18:34,269
of splitting data into two we can look

423
00:18:34,269 --> 00:18:36,850
at this points three green and three red

424
00:18:36,850 --> 00:18:39,490
and there seem to be many lines that can

425
00:18:39,490 --> 00:18:41,889
split them for example there is this

426
00:18:41,889 --> 00:18:45,070
yellow line and there is this purple

427
00:18:45,070 --> 00:18:49,570
line so quiz which of these two lines do

428
00:18:49,570 --> 00:18:52,360
athing cuts the data better the purple

429
00:18:52,360 --> 00:18:56,649
or the yellow one well if we look at the

430
00:18:56,649 --> 00:18:58,929
yellow line it seems that it's close to

431
00:18:58,929 --> 00:19:01,029
failing it's too close to two of the

432
00:19:01,029 --> 00:19:03,610
points so if we were to wiggle it a

433
00:19:03,610 --> 00:19:06,010
little bit we would miss classify some

434
00:19:06,010 --> 00:19:09,130
of the points the purple one on the

435
00:19:09,130 --> 00:19:11,950
other hand seems to be nicely spaced and

436
00:19:11,950 --> 00:19:14,409
as far as we can from all the points so

437
00:19:14,409 --> 00:19:16,240
it seems like the best line is a purple

438
00:19:16,240 --> 00:19:19,929
one now the question is how do we find

439
00:19:19,929 --> 00:19:22,269
the purple line well the first

440
00:19:22,269 --> 00:19:24,220
observation is that we don't really need

441
00:19:24,220 --> 00:19:25,570
to worry about these points because

442
00:19:25,570 --> 00:19:28,120
they're too far from the boundary so we

443
00:19:28,120 --> 00:19:30,100
can forget about them and only focus on

444
00:19:30,100 --> 00:19:33,580
the points that are close and now what

445
00:19:33,580 --> 00:19:35,320
we're going to use is not gradient

446
00:19:35,320 --> 00:19:37,029
descent but we're going to use linear

447
00:19:37,029 --> 00:19:39,450
optimization to find the line that

448
00:19:39,450 --> 00:19:42,460
maximizes the distance from the boundary

449
00:19:42,460 --> 00:19:46,029
points this method is called a support

450
00:19:46,029 --> 00:19:48,990
vector machine

451
00:19:49,900 --> 00:19:52,720
so you can think of support vector

452
00:19:52,720 --> 00:19:54,700
machines that surgeon will see your data

453
00:19:54,700 --> 00:19:58,059
and cut it but before she will carefully

454
00:19:58,059 --> 00:19:59,559
look at what's the best way to separate

455
00:19:59,559 --> 00:20:05,800
the data into and then make the cut okay

456
00:20:05,800 --> 00:20:07,990
so now let's say we have these four

457
00:20:07,990 --> 00:20:10,600
points arranged like this and we want to

458
00:20:10,600 --> 00:20:13,180
split them it seems like a line won't do

459
00:20:13,180 --> 00:20:14,890
the job since they're already over the

460
00:20:14,890 --> 00:20:16,780
line and the red ones are on the sides

461
00:20:16,780 --> 00:20:19,090
and the green ones are in the middle so

462
00:20:19,090 --> 00:20:22,210
we need to think outside the box one way

463
00:20:22,210 --> 00:20:24,190
to think outside the box is to use a

464
00:20:24,190 --> 00:20:28,000
curve like this to split them another

465
00:20:28,000 --> 00:20:30,940
one is to actually think outside the

466
00:20:30,940 --> 00:20:34,630
plain and to think of the points is

467
00:20:34,630 --> 00:20:37,059
lying in a three-dimensional space so

468
00:20:37,059 --> 00:20:42,070
here are the points over the plane and

469
00:20:42,070 --> 00:20:45,100
here we add an extra axis the z axis for

470
00:20:45,100 --> 00:20:47,410
the third dimension and if we can find a

471
00:20:47,410 --> 00:20:50,320
way to lift it to green points then we'd

472
00:20:50,320 --> 00:20:54,010
be able to separate them with a plane so

473
00:20:54,010 --> 00:20:56,290
what seems like a better solution the

474
00:20:56,290 --> 00:21:00,780
curve over here or the plane over here

475
00:21:00,780 --> 00:21:03,610
well it turns out that these two are

476
00:21:03,610 --> 00:21:06,130
actually the same method don't worry if

477
00:21:06,130 --> 00:21:08,260
it seems confusing we'll get into a

478
00:21:08,260 --> 00:21:10,809
little bit more detail later this method

479
00:21:10,809 --> 00:21:13,300
is called the kernel trick as very well

480
00:21:13,300 --> 00:21:16,780
used in support vector machines so let's

481
00:21:16,780 --> 00:21:19,120
study one of them in more detail let's

482
00:21:19,120 --> 00:21:21,820
start with the curve trick so let's

483
00:21:21,820 --> 00:21:23,200
start by putting coordinates on the

484
00:21:23,200 --> 00:21:25,210
points this one is the point zero three

485
00:21:25,210 --> 00:21:30,250
this one is 1 2 this one is 2 1 and this

486
00:21:30,250 --> 00:21:33,460
one is 3 0 and what we need is a way to

487
00:21:33,460 --> 00:21:35,710
separate the green points from the red

488
00:21:35,710 --> 00:21:39,750
points so the points coordinates are X Y

489
00:21:39,750 --> 00:21:41,890
then we need an equation on the

490
00:21:41,890 --> 00:21:44,110
variables x and y that gives us large

491
00:21:44,110 --> 00:21:46,360
values for the green points and small

492
00:21:46,360 --> 00:21:49,140
values for the red points or vice versa

493
00:21:49,140 --> 00:21:53,770
so quiz which of the following equations

494
00:21:53,770 --> 00:21:55,710
could come to our rescue

495
00:21:55,710 --> 00:22:01,720
X plus y the product x times y

496
00:22:01,720 --> 00:22:05,049
or x squared the first coordinates

497
00:22:05,049 --> 00:22:08,710
squared this is a not an easy question

498
00:22:08,710 --> 00:22:10,659
so let's actually make a table with the

499
00:22:10,659 --> 00:22:12,700
values of these equations on each of the

500
00:22:12,700 --> 00:22:17,019
four points so here's our table here we

501
00:22:17,019 --> 00:22:19,259
have the four points on the top row and

502
00:22:19,259 --> 00:22:22,600
now each of the other rows will be one

503
00:22:22,600 --> 00:22:25,090
of the functions so here's the sum X

504
00:22:25,090 --> 00:22:29,740
plus y we fill in the first row the

505
00:22:29,740 --> 00:22:33,639
following way 0 plus 3 is 3 1 plus 2 is

506
00:22:33,639 --> 00:22:39,610
3 2 plus 1 3 3 plus 0 3 now for the

507
00:22:39,610 --> 00:22:41,559
second row we're going to get the

508
00:22:41,559 --> 00:22:45,399
products 0 times 3 is 0 1 times 2 is 2 2

509
00:22:45,399 --> 00:22:50,200
times 1 is 2 and 3 times 0 is 0 and for

510
00:22:50,200 --> 00:22:52,960
the third row x squared is the first

511
00:22:52,960 --> 00:22:56,320
coordinate squared so 0 squared is 0 1

512
00:22:56,320 --> 00:22:59,679
squared is 1 2 squared is 4 and 3

513
00:22:59,679 --> 00:23:04,240
squared is 9 so let's think which one of

514
00:23:04,240 --> 00:23:07,149
these equations separates the green and

515
00:23:07,149 --> 00:23:12,009
the red points we look at the sum X plus

516
00:23:12,009 --> 00:23:15,279
y and that gives us 3 at every value so

517
00:23:15,279 --> 00:23:18,700
it doesn't really separate the points we

518
00:23:18,700 --> 00:23:21,549
can look at x squared and that gives us

519
00:23:21,549 --> 00:23:24,460
different values for every point but we

520
00:23:24,460 --> 00:23:27,940
get 0 & 9 for the red values and 1 & 4

521
00:23:27,940 --> 00:23:29,679
for the green ones so this one also

522
00:23:29,679 --> 00:23:32,620
don't doesn't separate them but now we

523
00:23:32,620 --> 00:23:35,110
look at the product x times y and that

524
00:23:35,110 --> 00:23:38,350
gives us 0 for the red values and 2 for

525
00:23:38,350 --> 00:23:40,389
the green ones so that one seems to do

526
00:23:40,389 --> 00:23:43,750
the job right it's a function that can

527
00:23:43,750 --> 00:23:47,259
tell them apart so that's the equation

528
00:23:47,259 --> 00:23:50,350
we're going to use you can see their

529
00:23:50,350 --> 00:23:54,429
products here and now for the red points

530
00:23:54,429 --> 00:23:58,509
X comma Y we have that the product X y

531
00:23:58,509 --> 00:24:01,750
equals 0 and for the green points we

532
00:24:01,750 --> 00:24:04,980
have that the product X y equals 2 and

533
00:24:04,980 --> 00:24:09,879
what separates a 0 and a 2 well a 1 so

534
00:24:09,879 --> 00:24:12,970
the equation x y equals 1 will separate

535
00:24:12,970 --> 00:24:13,920
them

536
00:24:13,920 --> 00:24:17,010
and what is XY equals one it's the same

537
00:24:17,010 --> 00:24:20,490
as y equals one over X and the graph for

538
00:24:20,490 --> 00:24:23,070
y was 1 over X is precisely this

539
00:24:23,070 --> 00:24:26,190
hyperbola over here that is the curve we

540
00:24:26,190 --> 00:24:31,740
want it so that is the kernel trick now

541
00:24:31,740 --> 00:24:34,590
we can also see it in 3d here we have

542
00:24:34,590 --> 00:24:42,000
the point 0 3 1 2 2 1 and 3 0 and we're

543
00:24:42,000 --> 00:24:45,270
going to consider them in 3 space so

544
00:24:45,270 --> 00:24:46,590
we're going to take the map that takes

545
00:24:46,590 --> 00:24:51,420
the point X comma Y 2 X comma Y comma X

546
00:24:51,420 --> 00:24:57,240
times y so where does 0 3 go 0 3 goes to

547
00:24:57,240 --> 00:25:01,200
0 comma 3 comma 0 since the product of 0

548
00:25:01,200 --> 00:25:05,730
& 3 is 0 1 2 goes to 1 comma 2 comma 2

549
00:25:05,730 --> 00:25:08,430
so it goes all the way up since the

550
00:25:08,430 --> 00:25:11,730
third coordinate is the height the point

551
00:25:11,730 --> 00:25:14,900
2 1 also goes to 2 comma 1 comma 2 and

552
00:25:14,900 --> 00:25:18,750
the point 3 0 goes to 3 comma 0 comma 0

553
00:25:18,750 --> 00:25:21,960
so there we go we can split them using a

554
00:25:21,960 --> 00:25:25,020
plane so you can think of a support

555
00:25:25,020 --> 00:25:26,940
vector machine a kernel method as a

556
00:25:26,940 --> 00:25:29,640
surgeon who is a slightly confused

557
00:25:29,640 --> 00:25:31,110
trying to split some apples and oranges

558
00:25:31,110 --> 00:25:33,090
all of a sudden she comes up with a

559
00:25:33,090 --> 00:25:35,580
great idea the idea consists of moving

560
00:25:35,580 --> 00:25:38,990
the apples up and the oranges down and

561
00:25:38,990 --> 00:25:41,490
then successfully cutting a line through

562
00:25:41,490 --> 00:25:46,380
between them ok so let's move the next

563
00:25:46,380 --> 00:25:48,360
example let's say we have a chain of

564
00:25:48,360 --> 00:25:51,720
pizza parlors and we want to put 3 of

565
00:25:51,720 --> 00:25:54,930
them in this city so we make a study and

566
00:25:54,930 --> 00:25:56,760
realize that the people who eat piece of

567
00:25:56,760 --> 00:26:01,050
the most live in these locations and so

568
00:26:01,050 --> 00:26:03,000
we need to know where are the optimal

569
00:26:03,000 --> 00:26:08,880
places to put our 3 pizza parlors well

570
00:26:08,880 --> 00:26:10,320
it seems like the houses are nicely

571
00:26:10,320 --> 00:26:12,720
split into three groups the red the blue

572
00:26:12,720 --> 00:26:14,550
and the yellow so it makes sense to put

573
00:26:14,550 --> 00:26:15,900
one pizza parlor in each one of the

574
00:26:15,900 --> 00:26:18,450
three clusters but we're teaching a

575
00:26:18,450 --> 00:26:20,520
computer how to do this a computer can

576
00:26:20,520 --> 00:26:22,500
just eyeball the three clusters we need

577
00:26:22,500 --> 00:26:24,990
an algorithm so here's one algorithm

578
00:26:24,990 --> 00:26:26,480
that'll work

579
00:26:26,480 --> 00:26:28,040
let's start by choosing three random

580
00:26:28,040 --> 00:26:30,980
locations for the pizza parlors so

581
00:26:30,980 --> 00:26:33,050
they're here where the stars are located

582
00:26:33,050 --> 00:26:37,460
red blue and yellow now it makes sense

583
00:26:37,460 --> 00:26:41,030
to say each house should go to the pizza

584
00:26:41,030 --> 00:26:44,090
parlor that is closest to it in that

585
00:26:44,090 --> 00:26:47,270
case we can look at the map like this

586
00:26:47,270 --> 00:26:49,790
where the yellow houses go to the yellow

587
00:26:49,790 --> 00:26:52,280
pizza parlor the blue houses go to the

588
00:26:52,280 --> 00:26:55,070
blue pizza parlor and the red houses go

589
00:26:55,070 --> 00:26:59,090
to the red pizza parlor but now look at

590
00:26:59,090 --> 00:27:01,070
where the yellow houses are located you

591
00:27:01,070 --> 00:27:03,560
would make a lot of sense to move the

592
00:27:03,560 --> 00:27:05,870
yellow pizza parlor to the center of

593
00:27:05,870 --> 00:27:08,870
these houses same thing with the blue

594
00:27:08,870 --> 00:27:11,330
houses and the red houses so let's do

595
00:27:11,330 --> 00:27:13,700
that let's move every pizza parlor to

596
00:27:13,700 --> 00:27:15,650
the center of the houses that it serves

597
00:27:15,650 --> 00:27:23,720
as follows but now look at these blue

598
00:27:23,720 --> 00:27:25,940
points there are a lot closer to the

599
00:27:25,940 --> 00:27:27,800
yellow pizza parlor than to the blue one

600
00:27:27,800 --> 00:27:29,840
so we might as well color them yellow

601
00:27:29,840 --> 00:27:32,990
and look at these red points they're

602
00:27:32,990 --> 00:27:35,330
closer to the blue bits of color then to

603
00:27:35,330 --> 00:27:39,140
the red so let's color them blue and now

604
00:27:39,140 --> 00:27:41,540
let's do the step again that send each

605
00:27:41,540 --> 00:27:43,220
pizza parlor to the center of this

606
00:27:43,220 --> 00:27:48,110
houses that is serving in this way but

607
00:27:48,110 --> 00:27:50,600
then again look at this red house is

608
00:27:50,600 --> 00:27:52,280
there so much closer to the blue pizza

609
00:27:52,280 --> 00:27:55,880
parlor so let's turn them blue and then

610
00:27:55,880 --> 00:27:57,560
again let's move every pizza parlor to

611
00:27:57,560 --> 00:28:00,130
the center of the house as it serves and

612
00:28:00,130 --> 00:28:02,900
now we've reached an optimal solution so

613
00:28:02,900 --> 00:28:04,870
starting with random points and

614
00:28:04,870 --> 00:28:07,730
iterating this process helped us reach

615
00:28:07,730 --> 00:28:11,980
the best locations for the pizza parlors

616
00:28:11,980 --> 00:28:14,630
this algorithm is called k-means

617
00:28:14,630 --> 00:28:18,830
clustering but now let's just say we

618
00:28:18,830 --> 00:28:20,360
don't want to specify the number of

619
00:28:20,360 --> 00:28:23,090
clusters to begin with it's just a

620
00:28:23,090 --> 00:28:26,060
different way to group the houses so say

621
00:28:26,060 --> 00:28:28,070
they're arranged like this it would make

622
00:28:28,070 --> 00:28:31,490
sense to say the following if two houses

623
00:28:31,490 --> 00:28:34,610
are close they should be served by the

624
00:28:34,610 --> 00:28:37,550
same pizza parlor so if we go by this

625
00:28:37,550 --> 00:28:40,270
rule let's try to group the house

626
00:28:40,270 --> 00:28:42,289
let's look at which houses are the

627
00:28:42,289 --> 00:28:44,960
closest to each other it's these two

628
00:28:44,960 --> 00:28:45,760
over here

629
00:28:45,760 --> 00:28:49,820
so we grouped them now what are the next

630
00:28:49,820 --> 00:28:52,490
two closest houses it's these two over

631
00:28:52,490 --> 00:28:53,140
here

632
00:28:53,140 --> 00:28:57,500
so we grouped them the next two closest

633
00:28:57,500 --> 00:28:59,900
houses are these two so again we grouped

634
00:28:59,900 --> 00:29:02,929
them the next two closest outside is two

635
00:29:02,929 --> 00:29:07,130
so we unite the groups now the next two

636
00:29:07,130 --> 00:29:10,100
house right here so we grouped them the

637
00:29:10,100 --> 00:29:12,080
next two clusters are here so we join

638
00:29:12,080 --> 00:29:14,659
the groups the next two closest houses

639
00:29:14,659 --> 00:29:16,460
are here but now let's just say that's

640
00:29:16,460 --> 00:29:20,000
too big so all we need to do is specify

641
00:29:20,000 --> 00:29:22,190
a distance and say this distance is too

642
00:29:22,190 --> 00:29:24,820
far when you reach this distance stop

643
00:29:24,820 --> 00:29:29,090
clustering the houses and now we get our

644
00:29:29,090 --> 00:29:32,330
clusters this algorithm is called here

645
00:29:32,330 --> 00:29:36,830
article clustering so congratulations

646
00:29:36,830 --> 00:29:39,320
in this video we've learned many of the

647
00:29:39,320 --> 00:29:41,750
main algorithms of machine learning we

648
00:29:41,750 --> 00:29:43,760
learn to find you house prices using

649
00:29:43,760 --> 00:29:46,100
linear regression we learn to detect

650
00:29:46,100 --> 00:29:48,950
spam email using naive Bayes we learn to

651
00:29:48,950 --> 00:29:52,309
recommend apps using decision trees we

652
00:29:52,309 --> 00:29:53,419
learn to create a model for an

653
00:29:53,419 --> 00:29:55,220
admissions office using logistic

654
00:29:55,220 --> 00:29:57,950
regression we learn how to improve them

655
00:29:57,950 --> 00:30:00,799
using neural networks and we learn how

656
00:30:00,799 --> 00:30:02,390
to improve it even more using support

657
00:30:02,390 --> 00:30:05,330
vector machines and finally we learn how

658
00:30:05,330 --> 00:30:07,100
to locate pizza parlors around the city

659
00:30:07,100 --> 00:30:11,179
using clustering algorithms so many

660
00:30:11,179 --> 00:30:12,860
questions may arise in your head such as

661
00:30:12,860 --> 00:30:15,679
are there more algorithms the answer is

662
00:30:15,679 --> 00:30:19,669
yes which ones to use that's not easy

663
00:30:19,669 --> 00:30:21,650
given a data set how do we know which

664
00:30:21,650 --> 00:30:25,159
algorithm to pick how to compare them

665
00:30:25,159 --> 00:30:28,100
and evaluate them into algorithms how do

666
00:30:28,100 --> 00:30:29,090
you know which one is better than

667
00:30:29,090 --> 00:30:31,789
another one data set given the running

668
00:30:31,789 --> 00:30:36,049
time their accuracy etc are there

669
00:30:36,049 --> 00:30:38,929
examples other projects are the real up

670
00:30:38,929 --> 00:30:40,700
that data that I can get my hands dirty

671
00:30:40,700 --> 00:30:42,950
with them the answer to all these

672
00:30:42,950 --> 00:30:45,559
questions are more or in the Udacity

673
00:30:45,559 --> 00:30:48,679
machine learning nanodegree so if this

674
00:30:48,679 --> 00:30:50,299
interests you you should take a look at

675
00:30:50,299 --> 00:00:00,000
it thank you

