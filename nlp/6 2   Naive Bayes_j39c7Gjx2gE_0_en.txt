the naivebayes algorithm is one of the

most important algorithms for text

classification the intuition of the

naive Bayes algorithm is really quite

simple it's based on Bayes rule which

we'll see in a second and it relies on a

very simple representation of the

document called the bag of words

representation let's see the intuition

of the bag of words representation

imagine I have some document it says I

love this movie it's sweet but with

satirical humor and so on and our job is

to is to build this function gamma which

takes the document and returns a class

the class could be positive or the class

could be negative in the case of of

sentiment analysis which is it positive

or negative in order to solve this task

one thing we might do is look at

individual words in the document like

love or satirical or great we might look

at all the words and in some kinds of

text classification we're gonna look at

all the words we're going to look at

every single word and in other cases

we'll look at just some subset if we

were to look at a subset we might

imagine that the document looks

something like this it just looks like

it has the word love in the word

satirical the word great and all the

other words have disappeared whether we

use a subset of words or all the words

in the document the bag of words

representation loses all the information

about the order of the words in the

document and all we represent about the

document is the set of words that

occurred and their accounts so for

example for the previous document we

might represent the document as just a

vector of words great love recommend

laugh happy and for each one account

great occurred twice love occurred twice

recommend occurred once and again we can

keep all of the words in the document

and will often do that or we can keep

just some of the words in the document

if we have an idea that some of the

words are particularly indicative cues

so the idea of the bag of words

representation is that we're gonna

represent our document just by a list of

words and there counts and throw away

everything else about the document

which order the words occurred in what

font they were in anything else and our

function will our function gamma our

classifier will take that representation

and assign us a class positive or

negative and the supplies I've shown it

to you for the two class problem of

sentiment analysis positive or negative

sentiment but this applies for all sorts

of document classification tasks so I

might have some document I need to

classify into a different computer

science topic because I'm building an

online library of computer science

papers or I'm giving advice on computer

science topics so I have some text some

some document here with words like

parser or language or label or

translation and I want to know which

aspect of computer science it should go

in so I can file my paper automatically

and a good text classifier should

automatically figure out that that's a

that's a natural language processing

paper so that's the intuition of the

naive Bayes classifier
