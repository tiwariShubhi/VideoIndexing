every natural language processing tool

has to be evaluated and language models

have to be evaluated as well what does

it mean for to our language model to be

a good language model in general we say

a good language model is one that is

better at finding the good sentences and

predict and liking them more than the

bad sentences or more specifically we

want to assign a higher probability to

Rio or perhaps frequently observed

sentences then ungrammatical or

impossible or at least rarely observed

sentences so that's the goal of our

evaluating a language model now we train

the parameters of a language model on a

training set and we test the models

performance on data that we haven't seen

so we have some training data and some

unseen data this unseen data is called a

test set and we want it to be something

that's not the same as our training set

totally unused we've never looked at it

before and that will be a fair

evaluation of our model and then we'll

need an evaluation metric that tells you

how well does your model do on this

unseen test set so what are these

evaluation models the best evaluation

best way of comparing any two models to

language models a and B is to put each

model in a task so we're gonna build our

spelling corrector or speech recognizer

or empty system whatever our application

is that uses language models will put

our language model in there and now

we'll run our task and we'll get some

accuracy for the system running with

model a the system running with model B

perhaps that's how many misspelled words

are corrected properly if we're doing

spelling correction or how many words

are translated correctly if we're doing

translation and now we just compare the

accuracy of the two models whichever

model has a higher accuracy is the

better language model so this is called

extrinsic evaluation we're using

something external to the Engram model

itself and looking at our performance on

that external task the problem with this

kind of extrinsic evaluation is also

called invivo

evaluation is that it's time consuming

in many cases this can take days or

weeks for a modern machine translation

system or modern

recognition system running evaluations

can often be extremely slow so instead

what we sometimes use is an intrinsic

evaluation something that's about

intrinsically about language models

themselves and not about any particular

application and the most common

intrinsic evaluation is called

perplexity now perplexity happens to be

a bad approximation to an extreme

extrinsic evaluation unless it turns out

that the test data looks a lot like the

training data and so generally

perplexity is useful only in pilot

experiments but it does help to think

about the problem and it's a useful tool

as long as we also use extrinsic

evaluation as well so let's think about

the intuition of perplexity and like

many ideas in language modeling this

dates back to Claude Shannon so so

Shannon proposed among many other things

a game about word prediction how well

can we predict the next word so for

example we've seen sentences like I

always order pizza with cheese and and

our job is to predict the next word

so from this first sentence we might say

well a good language model might guess

that we are likely to have mushrooms and

likely to have pepperoni and may be less

likely to have any anchovies because

anchovies are somewhat less popular than

mushrooms and very unlikely to put fried

rice on our pizza and extremely unlikely

let's say to have and and other people I

guess do say and and after after the

word and and so the how well the model

predicts these the actual words that

occur is is the into is is how good the

model is so a model honest on a sentence

like the 33rd president of the US we

know the next word is very likely to be

JFK or John or Kennedy or some word like

that so this is a pretty predictable

case here we have I saw anything could

come next so in some cases we're going

to do that be much better predicting the

next word in some cases very much worse

but a good language model on average

should do better than a bad language

model now it turns out that you know

grams are very bad at this game and if

you think for a second you'll realize

why so in summary a

better model of text a better language

model is one that assigns a higher

probability assigns a higher probability

to whatever word actually occurs if you

can guess right

the next word you are a good language

model so the best language model is one

that best predicts an unseen test set or

assigns on average the highest

probability of a sentence to all the

sentences that it sees if I've seen this

if I see this test set and I assign you

give me a new test set and I assign a

probability to each of those sentences

the better language model is the one

that says all I knew that sentence was

coming and assigns it a very high

probability now the perplexity this new

metric that we're going to be using is

the probability of the test set

normalized by the number of words so

we'll take let's say our test set is a

long sentence and in words long so we'll

take this n-word sentence will take its

probability and we'll take the one over

n that will take the nth the nth root so

and we'll take the inverse of it so it's

it's a way of normalizing for the length

of the probability so it's it's take

this long sentence take the probably the

whole sentence and normalize by the

number of words because obviously long

sentences the longer the sentence the

less probable it's going to be so we

want some normalizing factor so we can

compare test sets of different lengths

so that's the end through of 1 over the

perplexity of a string of words W is the

nth root of 1 over the probability of

the string of words so this parenthesis

should be here so and by the chain rule

that's the the probability of this

string of words 1 through n is the

probability overall I sorry I'm sorry

the product over all I of the

probability of each word given the

entire prefix beforehand and so we've

just by the chain rule replaced the

probability of a long sequence with the

product of the probabilities of each

word given its prefix and then for by

grams by our Markov approximation to the

chain rule we can say that the

probability we've replaced the

probability of a sequence of words with

the product of

bunch of diagrams so the perplexity of a

string of words is the nth root of the

product of n by Gram probabilities

multiplied together and inverted so it's

just a function of the probability of

the sentence so because of this

inversion minimizing perplexity is the

same as maximizing probability there's

another intuition for perplexity also

based on Shannon and and this example

comes from Josh Goodman and this int the

second intuition for perplexity relies

on the idea that perplexity is the

average related to the average branching

factor perplexity at any point in a in a

sentence is on average how many things

could occur next and we'll see later

this is related to the probability of

the upcoming thing is related to the

entropy of the upcoming things but

roughly speaking if I had 10 possible

words that could come next and they were

all equal probability my perplexity

would be 10 so for example if I'm

recognizing the 10 digits then the

perplexity of the task is 10 there's 10

possible things that could come next I

can't decide between them if I have to

reprimand a recognizer for a for a

switchboard phone service and I have to

recognize 30,000 names then the

perplexity of the names is 30,000 if

they're all equally likely but suppose a

system has to represent has to recognize

let's say again a phone a switchboard

phone operator automatic phone operator

has to recognize the word operator and

that occurs a quarter of the time the

word sales that occurs a quarter of the

time or the word technical support that

occurs a quarter of the time and then

with one over 120,000 times each another

30,000 names occur so now we have to

take the weighted average of all these

possibilities what could occur to

compute on average how likely is any one

word to occur and now the perplexity is

54 so the perplexity again is the

weighted equivalent branching factor so

let's examine this new kind of perplex

the wave Louisville and branching factor

and show that it's the same as this

inverted normalized probability metric

so let's take a sentence consisting of

random digits

what's the perplexity of this sentence

according to a model that assigns four

equal probability to each digit so we'll

see the perplexity of the sentence this

string of digits let's make it let's

make it since it doesn't matter how long

it is so we have a bunch of digits and

the probability of this bunch of digits

will call them digit one digit two

through digit n the perplexity by our

first metric is negative one is is the

probability of this sequence to the

negative 1 over N and since we've said

that each of these words has probability

1/10 1/10 and we're assuming that

unigram probability so that's the

probability of 1/10 times 1/10 times

1/10 times 1/10 and so on so that's the

product that's 1/10 to the N because

there's there were n words to the

negative 1 over N and as we can see over

here that's equal to the ends cancel we

get 1 10 to the minus 1 or we get 10 so

by thinking about perplexity as the

normalized probability of a long string

we can sort of see the intuition that

the average branching factor by

normalizing for the length we're sort of

asking how many things can occur in each

time weighted by their probability all

right so now perplexity in general the

lower the perplexity the better of the

model so for example here's here's where

a training set trained on 38 million

words tested on on 1.5 million words

from the newspaper The Wall Street

Journal and a unigram model has a

perplexity of 962 a bigram model has a

much lower much more accurate perplexity

of 170 and a trigram model has even a

lower perplexity

so perplexity since it's modeling

something like average branching factor

or average predictability the lower you

get the better you are predicting the

the actual data that occurs
