1
00:00:00,000 --> 00:00:00,790


2
00:00:00,790 --> 00:00:03,129
The following content is
provided under a Creative

3
00:00:03,129 --> 00:00:04,549
Commons license.

4
00:00:04,549 --> 00:00:06,759
Your support will help
MIT OpenCourseWare

5
00:00:06,759 --> 00:00:10,849
continue to offer high quality
educational resources for free.

6
00:00:10,849 --> 00:00:13,390
To make a donation or to
view additional materials

7
00:00:13,390 --> 00:00:17,320
from hundreds of MIT courses
visit MIT OpenCourseWare

8
00:00:17,320 --> 00:00:18,570
at ocw.mit.edu.

9
00:00:18,570 --> 00:00:29,769


10
00:00:29,769 --> 00:00:32,170
JOHN GUTTAG: We ended
the last lecture

11
00:00:32,170 --> 00:00:35,200
looking at greedy algorithms.

12
00:00:35,200 --> 00:00:38,370
Today I want to discuss the
pros and cons of greedy.

13
00:00:38,369 --> 00:00:40,239
Oh, I should mention--

14
00:00:40,240 --> 00:00:44,310
in response to popular demand,
I have put the PowerPoint up,

15
00:00:44,310 --> 00:00:48,920
so if you download the ZIP
file, you'll find the questions,

16
00:00:48,920 --> 00:00:52,600
including question 1, the
first question, plus the code,

17
00:00:52,600 --> 00:00:56,090
plus the PowerPoint.

18
00:00:56,090 --> 00:00:59,300
We actually do read Piazza,
and sometimes, at least,

19
00:00:59,299 --> 00:01:00,379
pay attention.

20
00:01:00,380 --> 00:01:03,710
We should pay
attention all the time.

21
00:01:03,710 --> 00:01:08,150
So what are the pros
and cons of greedy?

22
00:01:08,150 --> 00:01:11,160
The pro-- and it's
a big pro-- is

23
00:01:11,159 --> 00:01:14,789
that it's really easy to
implement, as you could see.

24
00:01:14,790 --> 00:01:18,280
Also enormously important--
it's really fast.

25
00:01:18,280 --> 00:01:20,099
We looked at the
complexity last time--

26
00:01:20,099 --> 00:01:23,729
it was m log n-- quite quick.

27
00:01:23,730 --> 00:01:27,090
The downside-- and this can
be either a big problem or not

28
00:01:27,090 --> 00:01:28,500
a big problem--

29
00:01:28,500 --> 00:01:30,840
is that it doesn't
actually solve

30
00:01:30,840 --> 00:01:34,439
the problem, in the sense
that we've asked ourselves

31
00:01:34,439 --> 00:01:36,459
to optimize something.

32
00:01:36,459 --> 00:01:40,929
And we get a solution that
may or may not be optimal.

33
00:01:40,930 --> 00:01:43,900
Worse-- we don't even
know, in this case,

34
00:01:43,900 --> 00:01:46,540
how close to optimal it is.

35
00:01:46,540 --> 00:01:50,830
Maybe it's almost optimal, but
maybe it's really far away.

36
00:01:50,829 --> 00:01:54,920
And that's a big problem
with many greedy algorithms.

37
00:01:54,920 --> 00:01:58,659
There are some very
sophisticated greedy algorithms

38
00:01:58,659 --> 00:02:02,200
we won't be looking at that
give you a bound on how good

39
00:02:02,200 --> 00:02:07,010
the approximation is, but
most of them don't do that.

40
00:02:07,010 --> 00:02:10,550
Last time we looked
at an alternative

41
00:02:10,550 --> 00:02:13,310
to a greedy algorithm
that was guaranteed

42
00:02:13,310 --> 00:02:14,539
to find the right solution.

43
00:02:14,539 --> 00:02:16,819
It was a brute force algorithm.

44
00:02:16,819 --> 00:02:19,039
The basic idea is simple--

45
00:02:19,039 --> 00:02:23,039
that you enumerate all
possible combinations of items,

46
00:02:23,039 --> 00:02:25,679
remove the combination
whose total units exceed

47
00:02:25,680 --> 00:02:28,920
the allowable weight, and
then choose the winner

48
00:02:28,919 --> 00:02:32,399
from those that are remaining.

49
00:02:32,400 --> 00:02:34,360
Now let's talk about
how to implement it.

50
00:02:34,360 --> 00:02:36,630
And the way I want to
implement it is using something

51
00:02:36,629 --> 00:02:39,359
called a search tree.

52
00:02:39,360 --> 00:02:42,310
There are lots of different
ways to implement it.

53
00:02:42,310 --> 00:02:44,180
In the second half
of today's lecture,

54
00:02:44,180 --> 00:02:45,950
you'll see why I
happen to choose

55
00:02:45,949 --> 00:02:48,780
this particular approach.

56
00:02:48,780 --> 00:02:52,009
So what is a search tree?

57
00:02:52,009 --> 00:02:56,810
A tree is, basically,
a kind of graph.

58
00:02:56,810 --> 00:03:00,000
And we'll hear much more
about graphs next week.

59
00:03:00,000 --> 00:03:04,449
But this is a simple form
where you have a root

60
00:03:04,449 --> 00:03:06,519
and then children of the root.

61
00:03:06,520 --> 00:03:09,310
In this particular
form, research C,

62
00:03:09,310 --> 00:03:10,930
you have two children.

63
00:03:10,930 --> 00:03:12,250
So we start with the root.

64
00:03:12,250 --> 00:03:15,219


65
00:03:15,219 --> 00:03:17,680
And then we look at
our list of elements

66
00:03:17,680 --> 00:03:21,430
to be considered
that we might take,

67
00:03:21,430 --> 00:03:24,700
and we look at the first
element in that list.

68
00:03:24,699 --> 00:03:28,659
And then we draw a
left branch, which

69
00:03:28,659 --> 00:03:32,590
shows the consequence of
choosing to take that element,

70
00:03:32,590 --> 00:03:36,250
and a right branch, which
shows the consequences of not

71
00:03:36,250 --> 00:03:37,210
taking that element.

72
00:03:37,210 --> 00:03:39,980


73
00:03:39,979 --> 00:03:43,250
And then we consider
the second element,

74
00:03:43,250 --> 00:03:49,389
and so on and so forth, until we
get to the bottom of the tree.

75
00:03:49,389 --> 00:03:52,559
So by convention, the left
element will mean we took it,

76
00:03:52,560 --> 00:03:54,670
the right direction will
mean we didn't take it.

77
00:03:54,669 --> 00:03:59,000


78
00:03:59,000 --> 00:04:02,930
And then we apply it recursively
to the non-leaf children.

79
00:04:02,930 --> 00:04:04,520
The leaf means we
get to the end,

80
00:04:04,520 --> 00:04:07,400
we've considered the last
element to be considered.

81
00:04:07,400 --> 00:04:10,129
Nothing else to think about.

82
00:04:10,129 --> 00:04:11,659
When we get to the
code, we'll see

83
00:04:11,659 --> 00:04:15,139
that, in addition to the
description being recursive,

84
00:04:15,139 --> 00:04:19,000
it's convenient to write
the code that way, too.

85
00:04:19,000 --> 00:04:21,250
And then finally,
we'll choose the node

86
00:04:21,250 --> 00:04:24,560
that has the highest value
that meets our constraints.

87
00:04:24,560 --> 00:04:26,949
So let's look at an example.

88
00:04:26,949 --> 00:04:29,560
My example is I have
my backpack that

89
00:04:29,560 --> 00:04:33,920
can hold a certain number
of calories if you will.

90
00:04:33,920 --> 00:04:37,360
And I'm choosing between, to
keep it small, a beer, a pizza,

91
00:04:37,360 --> 00:04:39,580
and a burger--

92
00:04:39,579 --> 00:04:43,319
three essential food groups.

93
00:04:43,319 --> 00:04:47,829
The first thing I explore on
the left is take the beer,

94
00:04:47,829 --> 00:04:50,349
and then I have the
pizza and the burger

95
00:04:50,350 --> 00:04:53,160
to continue to consider.

96
00:04:53,160 --> 00:04:56,520
I then say, all right,
let's take the pizza.

97
00:04:56,519 --> 00:04:58,169
Now I have just the burger.

98
00:04:58,170 --> 00:05:00,509
Now I taste the burger.

99
00:05:00,509 --> 00:05:04,500
This traversal of this
generation of the tree

100
00:05:04,500 --> 00:05:07,980
is called left-most depth-most.

101
00:05:07,980 --> 00:05:11,900
So I go all the way down
to the bottom of the tree.

102
00:05:11,899 --> 00:05:14,679
I then back up a
level and say, all

103
00:05:14,680 --> 00:05:17,740
right, I'm now at the bottom.

104
00:05:17,740 --> 00:05:24,129
Let's go back and
see what happens

105
00:05:24,129 --> 00:05:29,209
if I make the other choice
at the one level up the tree.

106
00:05:29,209 --> 00:05:31,599
So I went up and
said, well, now let's

107
00:05:31,600 --> 00:05:37,000
see what happens if I
make a different decision,

108
00:05:37,000 --> 00:05:40,519
as in we didn't take the burger.

109
00:05:40,519 --> 00:05:41,779
And then I work my way--

110
00:05:41,779 --> 00:05:43,849
this is called backtracking--

111
00:05:43,850 --> 00:05:45,470
up another level.

112
00:05:45,470 --> 00:05:49,500
I now say, suppose, I didn't
take the piece of pizza.

113
00:05:49,500 --> 00:05:52,250
Now I have the beer
only and only the burger

114
00:05:52,250 --> 00:05:58,110
to think about, so
on and so forth,

115
00:05:58,110 --> 00:06:00,629
until I've generated
the whole tree.

116
00:06:00,629 --> 00:06:04,050
You'll notice it will always be
the case that the leftmost leaf

117
00:06:04,050 --> 00:06:08,800
of this tree has got all
the possible items in it,

118
00:06:08,800 --> 00:06:12,079
and the rightmost leaf none.

119
00:06:12,079 --> 00:06:14,959
And then I just check
which of these leaves

120
00:06:14,959 --> 00:06:19,180
meets the constraint
and what are the values.

121
00:06:19,180 --> 00:06:24,430
And if I compute the value
and the calories in each one,

122
00:06:24,430 --> 00:06:28,120
and if our constraint
was 750 calories,

123
00:06:28,120 --> 00:06:30,504
then I get to choose
the winner, which is--

124
00:06:30,504 --> 00:06:33,355


125
00:06:33,355 --> 00:06:34,980
I guess, it's the
pizza and the burger.

126
00:06:34,980 --> 00:06:35,710
Is that right?

127
00:06:35,709 --> 00:06:38,439


128
00:06:38,439 --> 00:06:45,810
The most value under 750.

129
00:06:45,810 --> 00:06:49,180
That's the way I go through.

130
00:06:49,180 --> 00:06:52,709
It's quite a
straightforward algorithm.

131
00:06:52,709 --> 00:06:56,349
And I don't know why we draw our
trees with the root at the top

132
00:06:56,350 --> 00:06:58,290
and the leaves at the bottom.

133
00:06:58,290 --> 00:07:00,960
My only conjecture is
computer scientists

134
00:07:00,959 --> 00:07:02,354
don't spend enough
time outdoors.

135
00:07:02,355 --> 00:07:06,210


136
00:07:06,209 --> 00:07:09,870
Now let's think of the
computational complexity

137
00:07:09,870 --> 00:07:13,019
of this process.

138
00:07:13,019 --> 00:07:15,959
The time is going to be based
on the total number of nodes

139
00:07:15,959 --> 00:07:18,099
we generate.

140
00:07:18,100 --> 00:07:21,550
So if we know the number of
nodes that are in the tree,

141
00:07:21,550 --> 00:07:24,160
we then know the complexity
of the algorithm,

142
00:07:24,160 --> 00:07:27,330
the asymptotic complexity.

143
00:07:27,329 --> 00:07:31,459
Well, how many levels
do we have in the tree?

144
00:07:31,459 --> 00:07:33,919
Just the number of items, right?

145
00:07:33,920 --> 00:07:35,660
Because at each
level of the tree

146
00:07:35,660 --> 00:07:39,040
we're deciding to take
or not to take an item.

147
00:07:39,040 --> 00:07:43,210
And so we can only do that for
the number of items we have.

148
00:07:43,209 --> 00:07:46,839
So if we go back, for example,
and we look at the tree--

149
00:07:46,839 --> 00:07:50,419
not that tree, that tree--

150
00:07:50,420 --> 00:07:52,590
and we count the
number of levels,

151
00:07:52,589 --> 00:07:56,599
it's going to be based upon
the total number of items.

152
00:07:56,600 --> 00:07:59,150
We know that because if you
look at, say, the leftmost node

153
00:07:59,149 --> 00:08:04,159
at the bottom, we've made
three separate decisions.

154
00:08:04,160 --> 00:08:08,660
So counting the
root, it's n plus 1.

155
00:08:08,660 --> 00:08:10,939
But we don't care
about plus 1 when we're

156
00:08:10,939 --> 00:08:14,889
doing asymptotic complexity.

157
00:08:14,889 --> 00:08:19,310
So that tells us how many
levels we have in the tree.

158
00:08:19,310 --> 00:08:23,030
The next question we
need to ask is, how many

159
00:08:23,029 --> 00:08:26,169
nodes are there at each level?

160
00:08:26,170 --> 00:08:30,580
And you can look at this
and see-- the deeper we go,

161
00:08:30,579 --> 00:08:34,590
the more nodes we
have at each level.

162
00:08:34,590 --> 00:08:39,340
In fact, if we come
here, we can see

163
00:08:39,340 --> 00:08:41,970
that the number of
nodes at level i--

164
00:08:41,970 --> 00:08:46,649
depth i of the
tree-- is 2 to the i.

165
00:08:46,649 --> 00:08:48,840
That makes sense if you
remember last time we

166
00:08:48,840 --> 00:08:50,970
looked at binary numbers.

167
00:08:50,970 --> 00:08:53,550
We're saying we're representing
our choices as either 0

168
00:08:53,549 --> 00:08:55,559
or 1 for what we take.

169
00:08:55,559 --> 00:08:58,229
If we have n items
to choose from,

170
00:08:58,230 --> 00:09:00,240
then the number of
possible choices

171
00:09:00,240 --> 00:09:03,350
is 2 to the n, the
size of the powerset.

172
00:09:03,350 --> 00:09:05,865
So that will tell us the
number of nodes at each level.

173
00:09:05,865 --> 00:09:09,549


174
00:09:09,549 --> 00:09:13,469
So if there are n items, the
number of nodes in the tree

175
00:09:13,470 --> 00:09:18,509
is going to be the sum
from 0 to n of 2 to the i

176
00:09:18,509 --> 00:09:21,450
because we have
that many levels.

177
00:09:21,450 --> 00:09:23,850
And if you've studied
a little math,

178
00:09:23,850 --> 00:09:28,399
you know that's exactly
2 to the n plus 1.

179
00:09:28,399 --> 00:09:30,980
Or if you do what I do,
you look it up in Wikipedia

180
00:09:30,980 --> 00:09:34,659
and you know it's
2 to the n plus 1.

181
00:09:34,659 --> 00:09:37,209
Now, there's an
obvious optimization.

182
00:09:37,210 --> 00:09:41,320
We don't need to
explore the whole tree.

183
00:09:41,320 --> 00:09:45,760
If we get to a point where
the backpack is overstuffed,

184
00:09:45,759 --> 00:09:48,639
there's no point in saying,
should we take this next item?

185
00:09:48,639 --> 00:09:50,919
Because we know we can't.

186
00:09:50,919 --> 00:09:53,319
I generated a bunch
of leaves that

187
00:09:53,320 --> 00:09:57,820
were useless because
the weight was too high.

188
00:09:57,820 --> 00:10:01,660
So you could always
abort early and say, oh,

189
00:10:01,659 --> 00:10:05,319
no point in generating the
rest of this part of the tree

190
00:10:05,320 --> 00:10:09,320
because we know everything
in it will be too heavy.

191
00:10:09,320 --> 00:10:13,460
Adding something cannot
reduce the weight.

192
00:10:13,460 --> 00:10:14,780
It's a nice optimization.

193
00:10:14,779 --> 00:10:17,819
It's one you'll see we
actually do in the code.

194
00:10:17,820 --> 00:10:20,750
But it really doesn't
change the complexity.

195
00:10:20,750 --> 00:10:24,259
It's not going to change
the worst-cost complexity.

196
00:10:24,259 --> 00:10:28,830


197
00:10:28,830 --> 00:10:32,389
Exponential, as we saw this,
I think, in Eric's lecture,

198
00:10:32,389 --> 00:10:33,750
is a big number.

199
00:10:33,750 --> 00:10:36,149
You don't usually
like 2 to the n.

200
00:10:36,149 --> 00:10:39,299
Does this mean that brute
force is never useful?

201
00:10:39,299 --> 00:10:40,620
Well, let's give it a try.

202
00:10:40,620 --> 00:10:43,674


203
00:10:43,674 --> 00:10:44,674
We'll look at some code.

204
00:10:44,674 --> 00:10:48,439


205
00:10:48,440 --> 00:10:49,770
Here is the implementation.

206
00:10:49,769 --> 00:10:57,850


207
00:10:57,850 --> 00:11:02,399
So it's maxVal,
toConsider, and avail.

208
00:11:02,399 --> 00:11:08,789
And then we say, if toConsider
is empty or avail is 0--

209
00:11:08,789 --> 00:11:11,699
avail is an index, we're going
to go through the list using

210
00:11:11,700 --> 00:11:14,580
that to tell us
whether or not we still

211
00:11:14,580 --> 00:11:17,170
have an element to consider--

212
00:11:17,169 --> 00:11:22,610
then the result will be the
tuple 0 and the empty tuple.

213
00:11:22,610 --> 00:11:25,279


214
00:11:25,279 --> 00:11:26,419
We couldn't take anything.

215
00:11:26,419 --> 00:11:29,529
This is the base
of our recursion.

216
00:11:29,529 --> 00:11:32,509
Either there's nothing
left to consider or there's

217
00:11:32,509 --> 00:11:34,250
no available weight--

218
00:11:34,250 --> 00:11:35,629
the Val, as the
amount of weight,

219
00:11:35,629 --> 00:11:39,409
is 0 or toConsider is empty.

220
00:11:39,409 --> 00:11:42,829
Well, if either
of those are true,

221
00:11:42,830 --> 00:11:45,850
then we ask whether
to consider * 0,

222
00:11:45,850 --> 00:11:48,460
the first element to look at.

223
00:11:48,460 --> 00:11:51,670
Is that cost greater
than availability?

224
00:11:51,669 --> 00:11:54,740


225
00:11:54,740 --> 00:11:58,960
If it is, we don't need to
explore the left branch.

226
00:11:58,960 --> 00:12:01,269
because it means we can't
afford to put that thing

227
00:12:01,269 --> 00:12:03,490
in the backpack, the knapsack.

228
00:12:03,490 --> 00:12:05,350
There's just no room for it.

229
00:12:05,350 --> 00:12:08,529
So we'll explore the
right branch only.

230
00:12:08,529 --> 00:12:13,389
The result will be whatever the
maximum value is of toConsider

231
00:12:13,389 --> 00:12:17,529
of the remainder of the list--
the list with the first element

232
00:12:17,529 --> 00:12:18,899
sliced off--

233
00:12:18,899 --> 00:12:22,069
and availability unchanged.

234
00:12:22,070 --> 00:12:24,480
So it's a recursive
implementation, saying,

235
00:12:24,480 --> 00:12:27,930
now we only have to consider
the right branch of the tree

236
00:12:27,929 --> 00:12:29,909
because we knew we
couldn't take this element.

237
00:12:29,909 --> 00:12:32,490
It just weighs too
much, or costs too much,

238
00:12:32,490 --> 00:12:36,000
or was too fattening,
in my case.

239
00:12:36,000 --> 00:12:41,210
Otherwise, we now have to
consider both branches.

240
00:12:41,210 --> 00:12:46,000
So we'll set next item to
toConsider of 0, the first one,

241
00:12:46,000 --> 00:12:47,269
and explore the left branch.

242
00:12:47,269 --> 00:12:51,039


243
00:12:51,039 --> 00:12:53,980
On this branch, there
are two possibilities

244
00:12:53,980 --> 00:13:01,279
to think about, which I'm
calling withVal and withToTake.

245
00:13:01,279 --> 00:13:05,769
So I'm going to call maxVal
of toConsider of everything

246
00:13:05,769 --> 00:13:12,309
except the current element and
pass in an available weight

247
00:13:12,309 --> 00:13:15,699
of avail minus whatever--

248
00:13:15,700 --> 00:13:20,009
well, let me widen this so
we can see the whole code.

249
00:13:20,009 --> 00:13:23,985


250
00:13:23,985 --> 00:13:28,039
This is not going to let me
widen this window any more.

251
00:13:28,039 --> 00:13:28,799
Shame on it.

252
00:13:28,799 --> 00:13:30,591
Let me see if I can
get rid of the console.

253
00:13:30,591 --> 00:13:37,060


254
00:13:37,059 --> 00:13:38,769
Well, we'll have
to do this instead.

255
00:13:38,769 --> 00:13:45,189


256
00:13:45,190 --> 00:13:48,690
So we're going to call
maxVal with everything

257
00:13:48,690 --> 00:13:51,300
except the current
element and give it

258
00:13:51,299 --> 00:13:58,199
avail minus the cost of that
next item of toConsider sub 0.

259
00:13:58,200 --> 00:14:01,050
Because we know that the
availability, available weight

260
00:14:01,049 --> 00:14:03,129
has to have that cost
subtracted from it.

261
00:14:03,129 --> 00:14:09,159


262
00:14:09,159 --> 00:14:18,409
And then we'll add to withVal
next item dot getValue.

263
00:14:18,409 --> 00:14:22,199
So that's a value
if we do take it.

264
00:14:22,200 --> 00:14:23,950
Then we'll explore the
right branch-- what

265
00:14:23,950 --> 00:14:25,270
happens if we don't take it?

266
00:14:25,269 --> 00:14:27,938


267
00:14:27,938 --> 00:14:29,605
And then we'll choose
the better branch.

268
00:14:29,605 --> 00:14:33,670


269
00:14:33,669 --> 00:14:36,909
So it's a pretty simple
recursive algorithm.

270
00:14:36,909 --> 00:14:40,179
We just go all the
way to the bottom

271
00:14:40,179 --> 00:14:42,250
and make the right
choice at the bottom,

272
00:14:42,250 --> 00:14:46,690
and then percolate back up, like
so many recursive algorithms.

273
00:14:46,690 --> 00:14:52,680


274
00:14:52,679 --> 00:14:54,569
We have a simple
program to test it.

275
00:14:54,570 --> 00:15:02,414


276
00:15:02,413 --> 00:15:04,580
I better start a console
now if I'm going to run it.

277
00:15:04,580 --> 00:15:12,190


278
00:15:12,190 --> 00:15:14,870
And we'll testGreedys on foods.

279
00:15:14,870 --> 00:15:18,789
Well, we'll testGreedys
and then we'll testMaxVal.

280
00:15:18,789 --> 00:15:20,709
So I'm building
the same thing we

281
00:15:20,710 --> 00:15:23,920
did in Monday's
lecture, the same menu.

282
00:15:23,919 --> 00:15:25,539
And I'll run the
same testGreedys

283
00:15:25,539 --> 00:15:27,459
we looked at last time.

284
00:15:27,460 --> 00:15:31,030
And we'll see whether or not
we get something better when

285
00:15:31,029 --> 00:15:32,769
we run the truly optimal one.

286
00:15:32,769 --> 00:15:41,259


287
00:15:41,259 --> 00:15:43,240
Well, indeed we do.

288
00:15:43,240 --> 00:15:45,639
You remember that last
time and, fortunately,

289
00:15:45,639 --> 00:15:52,149
this time too, the best
we did was a value of 318.

290
00:15:52,149 --> 00:15:56,470
But now we see we can
actually get to 353 if we use

291
00:15:56,470 --> 00:16:00,600
the truly optimal algorithm.

292
00:16:00,600 --> 00:16:05,110
So we see it ran pretty
quickly and actually

293
00:16:05,110 --> 00:16:10,419
gave us a better answer than we
got from the greedy algorithm.

294
00:16:10,419 --> 00:16:12,759
And it's often the case.

295
00:16:12,759 --> 00:16:14,679
If I have time at the
end, I'll show you

296
00:16:14,679 --> 00:16:16,359
an optimization
program you might

297
00:16:16,360 --> 00:16:21,220
want to run that works
perfectly fine to use

298
00:16:21,220 --> 00:16:24,310
this kind of brute
force algorithm on.

299
00:16:24,309 --> 00:16:28,229
Let's go back to the PowerPoint.

300
00:16:28,230 --> 00:16:31,560
So I'm just going through
the code again we just ran.

301
00:16:31,559 --> 00:16:35,219
This was the header we saw--

302
00:16:35,220 --> 00:16:37,700
toConsider, as the
items that correspond

303
00:16:37,700 --> 00:16:42,200
to nodes higher up the
tree, and avail, as I said,

304
00:16:42,200 --> 00:16:44,619
the amount of space.

305
00:16:44,619 --> 00:16:46,410
And again, here's what
the body of the code

306
00:16:46,409 --> 00:16:49,034
loooked like, I took
out the comments.

307
00:16:49,034 --> 00:16:51,363


308
00:16:51,364 --> 00:16:53,530
One of the things you might
think about in your head

309
00:16:53,529 --> 00:16:57,189
when you look at this code is
putting the comments back in.

310
00:16:57,190 --> 00:16:59,410
I always find that for
me a really good way

311
00:16:59,409 --> 00:17:04,059
to understand code that I didn't
write is to try and comment it.

312
00:17:04,059 --> 00:17:06,578
And that helps me sort of
force myself to think about

313
00:17:06,578 --> 00:17:09,068
what is it really doing.

314
00:17:09,068 --> 00:17:12,098
So you'll have both versions--
you'll have the PowerPoint

315
00:17:12,098 --> 00:17:15,009
version without the
comments and the actual code

316
00:17:15,009 --> 00:17:16,900
with the comments.

317
00:17:16,900 --> 00:17:18,579
You can think about
looking at this

318
00:17:18,578 --> 00:17:20,710
and then looking
at the real code

319
00:17:20,710 --> 00:17:23,465
and making sure that
you're understanding jibes.

320
00:17:23,464 --> 00:17:28,000


321
00:17:28,000 --> 00:17:30,529
I should point out that
this doesn't actually

322
00:17:30,529 --> 00:17:33,509
build the search tree.

323
00:17:33,509 --> 00:17:42,660
We've got this local variable
result, starting here,

324
00:17:42,660 --> 00:17:48,050
that records the best
solution found so far.

325
00:17:48,049 --> 00:17:51,210
So it's not the picture I drew
where I generate all the nodes

326
00:17:51,210 --> 00:17:53,090
and then I inspect them.

327
00:17:53,089 --> 00:17:54,199
I just keep track--

328
00:17:54,200 --> 00:17:57,890
as I generate a node, I
say, how good is this?

329
00:17:57,890 --> 00:17:59,970
Is it better than the
best I've found so far?

330
00:17:59,970 --> 00:18:03,180
If so, it becomes the new best.

331
00:18:03,180 --> 00:18:07,000
And I can do that because
every node I generate

332
00:18:07,000 --> 00:18:12,609
is, in some sense, a legal
solution to the problem.

333
00:18:12,609 --> 00:18:17,199
Probably rarely is it the
final optimal solution

334
00:18:17,200 --> 00:18:19,029
but it's at least
a legal solution.

335
00:18:19,029 --> 00:18:20,529
And so if it's
better than something

336
00:18:20,529 --> 00:18:25,829
we saw before, we can
make it the new best.

337
00:18:25,829 --> 00:18:26,919
This is very common.

338
00:18:26,920 --> 00:18:29,310
And this is, in fact, what
most people do with it

339
00:18:29,309 --> 00:18:31,349
when they use a search tree--

340
00:18:31,349 --> 00:18:33,899
they don't actually
build the tree

341
00:18:33,900 --> 00:18:36,660
in the pictorial way
we've looked at it

342
00:18:36,660 --> 00:18:39,932
but play some trick like
this of just keeping

343
00:18:39,932 --> 00:18:40,890
track of their results.

344
00:18:40,890 --> 00:18:44,610


345
00:18:44,609 --> 00:18:45,824
Any questions about this?

346
00:18:45,825 --> 00:18:50,289


347
00:18:50,289 --> 00:18:52,210
All right.

348
00:18:52,210 --> 00:18:57,110
We did just try it on
example from lecture 1.

349
00:18:57,109 --> 00:18:59,000
And we saw that it worked great.

350
00:18:59,000 --> 00:19:00,980
It gave us a better answer.

351
00:19:00,980 --> 00:19:03,319
It finished quickly.

352
00:19:03,319 --> 00:19:06,889
But we should not take too
much solace from the fact

353
00:19:06,890 --> 00:19:10,160
that it finished quickly
because 2 to the eighth

354
00:19:10,160 --> 00:19:11,750
is actually a
pretty tiny number.

355
00:19:11,750 --> 00:19:16,160


356
00:19:16,160 --> 00:19:19,759
Almost any algorithm is fine
when I'm working on something

357
00:19:19,759 --> 00:19:21,259
this small.

358
00:19:21,259 --> 00:19:24,140
Let's look now at what happens
if we have a bigger menu.

359
00:19:24,140 --> 00:19:28,870


360
00:19:28,869 --> 00:19:33,129
Here is some code
to do a bigger menu.

361
00:19:33,130 --> 00:19:37,440
Since, as you will discover
if you haven't already,

362
00:19:37,440 --> 00:19:39,910
I'm a pretty lazy
person, I didn't

363
00:19:39,910 --> 00:19:43,570
want to write out a menu with
a 100 items or even 50 items.

364
00:19:43,569 --> 00:19:46,689
So I wrote some code
to generate the menus.

365
00:19:46,690 --> 00:19:50,350
And I used randomness
to do that.

366
00:19:50,349 --> 00:19:52,809
This is a Python
library we'll be

367
00:19:52,809 --> 00:19:57,950
using a lot for the
rest of the semester.

368
00:19:57,950 --> 00:20:04,250
It's used any time you want
to generate things at random

369
00:20:04,250 --> 00:20:05,750
and do many other things.

370
00:20:05,750 --> 00:20:07,430
We'll come back to it a lot.

371
00:20:07,430 --> 00:20:10,940
Here we're just going to
use a very small part of it.

372
00:20:10,940 --> 00:20:14,210


373
00:20:14,210 --> 00:20:19,471
To build a large menu
of some numItems--

374
00:20:19,471 --> 00:20:21,180
and we're going to
give the maximum value

375
00:20:21,180 --> 00:20:25,220
and the maximum
cost for each item.

376
00:20:25,220 --> 00:20:30,420
We'll assume the minimum
is, in this case, 1.

377
00:20:30,420 --> 00:20:32,009
Items will start empty.

378
00:20:32,009 --> 00:20:35,629
And then for i in
range number of items,

379
00:20:35,630 --> 00:20:41,690
I'm going to call this function
random dot randint that

380
00:20:41,690 --> 00:20:46,779
takes a range of integers from
1 to, actually in this case,

381
00:20:46,779 --> 00:20:52,789
maxVal minus 1, or 1 to
maxVal, actually, in this case.

382
00:20:52,789 --> 00:20:55,819
And it just chooses
one of them at random.

383
00:20:55,819 --> 00:20:59,049
So when you run this, you don't
know what it's going to get.

384
00:20:59,049 --> 00:21:03,039
Random dot randint might
return 1, it might return 23,

385
00:21:03,039 --> 00:21:04,778
it might return 54.

386
00:21:04,778 --> 00:21:06,819
The only thing you know
is it will be an integer.

387
00:21:06,819 --> 00:21:09,639


388
00:21:09,640 --> 00:21:13,980
And then I'm going to build
menus ranging from 5 items

389
00:21:13,980 --> 00:21:14,920
to 60 items--

390
00:21:14,920 --> 00:21:19,759


391
00:21:19,759 --> 00:21:29,720
buildLargeMenu, the number
of items, with maxVal of 90

392
00:21:29,720 --> 00:21:35,250
and a maxCost of 250,
pleasure and calories.

393
00:21:35,250 --> 00:21:39,329
And then I'm going to test
maxVal on each of these menus.

394
00:21:39,329 --> 00:21:43,049


395
00:21:43,049 --> 00:21:46,589
So building menus of
various sizes at random

396
00:21:46,589 --> 00:21:52,220
and then just trying to find the
optimal value for each of them.

397
00:21:52,220 --> 00:21:53,240
Let's look at the code.

398
00:21:53,240 --> 00:21:56,609


399
00:21:56,609 --> 00:22:03,599
Let's comment this out, we
don't need to run that again.

400
00:22:03,599 --> 00:22:10,432


401
00:22:10,432 --> 00:22:13,430
So we'll build a
large menu and then

402
00:22:13,430 --> 00:22:16,009
we'll try it for a bunch of
items and see what we get.

403
00:22:16,009 --> 00:22:29,440


404
00:22:29,440 --> 00:22:30,990
So it's going along.

405
00:22:30,990 --> 00:22:34,720
Trying the menu up to
30 went pretty quickly.

406
00:22:34,720 --> 00:22:38,009
So even 2 to the 30
didn't take too long.

407
00:22:38,009 --> 00:22:41,529
But you might notice it's kind
of bogging down, we got 35.

408
00:22:41,529 --> 00:22:46,250


409
00:22:46,250 --> 00:22:48,119
I guess, I could ask
the question now--

410
00:22:48,119 --> 00:22:51,289
it was one of the questions
I was going to ask as a poll

411
00:22:51,289 --> 00:22:53,659
but maybe I won't bother--

412
00:22:53,660 --> 00:22:55,592
how much patience do we have?

413
00:22:55,592 --> 00:22:57,800
When do you think we'll run
out of patience and quit?

414
00:22:57,799 --> 00:23:03,859


415
00:23:03,859 --> 00:23:05,689
If you're out of
patience, raise your hand.

416
00:23:05,690 --> 00:23:08,640


417
00:23:08,640 --> 00:23:11,600
Well, some of you are way
more patient than I am.

418
00:23:11,599 --> 00:23:12,849
So we're going to quit anyway.

419
00:23:12,849 --> 00:23:18,740


420
00:23:18,740 --> 00:23:20,240
We were trying to do 40.

421
00:23:20,240 --> 00:23:22,819
It might have finished 40, 45.

422
00:23:22,819 --> 00:23:26,480
I've never waited long
enough to get to 45.

423
00:23:26,480 --> 00:23:27,740
It just is too long.

424
00:23:27,740 --> 00:23:33,099


425
00:23:33,099 --> 00:23:35,509
That raises the
question, is it hopeless?

426
00:23:35,509 --> 00:23:41,500


427
00:23:41,500 --> 00:23:43,750
And in theory, yes.

428
00:23:43,750 --> 00:23:46,839
As I mentioned last time, it
is an inherently exponential

429
00:23:46,839 --> 00:23:48,459
problem.

430
00:23:48,460 --> 00:23:50,590
The answer is-- in practice, no.

431
00:23:50,589 --> 00:23:54,919
Because there's something
called dynamic programming,

432
00:23:54,920 --> 00:23:59,200
which was invented by a
fellow at the RAND Corporation

433
00:23:59,200 --> 00:24:02,230
called Richard Bellman,
a rather remarkable

434
00:24:02,230 --> 00:24:05,500
mathematician/computer
scientist.

435
00:24:05,500 --> 00:24:07,720
He wrote a whole book
on it, but I'm not sure

436
00:24:07,720 --> 00:24:09,640
why because it's not
that complicated.

437
00:24:09,640 --> 00:24:14,140


438
00:24:14,140 --> 00:24:17,020
When we talk about
dynamic programming,

439
00:24:17,019 --> 00:24:20,859
it's a kind of a funny
story, at least to me.

440
00:24:20,859 --> 00:24:23,549
I learned it and I
didn't know anything

441
00:24:23,549 --> 00:24:24,549
about the history of it.

442
00:24:24,549 --> 00:24:28,180
And I've had all sorts
of theories about why it

443
00:24:28,180 --> 00:24:30,670
was called dynamic programming.

444
00:24:30,670 --> 00:24:35,259
You know how it is, how people
try and fit a theory to data.

445
00:24:35,259 --> 00:24:37,000
And then I read a
history book about it,

446
00:24:37,000 --> 00:24:39,369
and this was Bellman's
own description

447
00:24:39,369 --> 00:24:43,889
of why he called it
dynamic programming.

448
00:24:43,890 --> 00:24:45,630
And it turned out,
as you can see,

449
00:24:45,630 --> 00:24:48,960
he basically chose a word
because it was the description

450
00:24:48,960 --> 00:24:51,430
that didn't mean anything.

451
00:24:51,430 --> 00:24:55,330
Because he was doing
mathematics, and at the time

452
00:24:55,329 --> 00:24:58,179
he was being funded by a part
of the Defense Department

453
00:24:58,180 --> 00:25:00,789
that didn't approve
of mathematics.

454
00:25:00,789 --> 00:25:04,059
And he wanted to
conceal that fact.

455
00:25:04,059 --> 00:25:08,409
And indeed at the time, the
head of Defense Appropriations

456
00:25:08,410 --> 00:25:12,239
in the US Congress didn't
much like mathematics.

457
00:25:12,239 --> 00:25:13,779
And he was afraid
that he didn't want

458
00:25:13,779 --> 00:25:17,529
to have to go and testify and
tell people he was doing math.

459
00:25:17,529 --> 00:25:19,569
So he just invented
something that no one

460
00:25:19,569 --> 00:25:21,399
would know what it meant.

461
00:25:21,400 --> 00:25:24,400
And years of students
spent time later trying

462
00:25:24,400 --> 00:25:27,620
to figure out what
it actually did mean.

463
00:25:27,619 --> 00:25:30,279
Anyway, what's the basic idea?

464
00:25:30,279 --> 00:25:34,869
To understand it I want
to temporarily abandon

465
00:25:34,869 --> 00:25:39,250
the knapsack problem and look
at a much simpler problem--

466
00:25:39,250 --> 00:25:40,224
Fibonacci numbers.

467
00:25:40,224 --> 00:25:42,879


468
00:25:42,880 --> 00:25:46,630
You've seen this already, with
cute little bunnies, I think,

469
00:25:46,630 --> 00:25:49,600
when you saw it.

470
00:25:49,599 --> 00:25:51,980
N equals 0, n
equals 1-- return 1.

471
00:25:51,980 --> 00:25:57,220
Otherwise, fib of n minus
1 plus fib of n minus 2.

472
00:25:57,220 --> 00:25:59,559
And as I think you saw
when you first saw it,

473
00:25:59,559 --> 00:26:03,970
it takes a long time to run.

474
00:26:03,970 --> 00:26:08,029
Fib of 120, for example,
is a very big number.

475
00:26:08,029 --> 00:26:12,410
It's shocking how
quickly Fibonacci grows.

476
00:26:12,410 --> 00:26:20,890
So let's think about
implementing it.

477
00:26:20,890 --> 00:26:22,459
If we run Fibonacci--

478
00:26:22,459 --> 00:26:23,750
well, maybe we'll just do that.

479
00:26:23,750 --> 00:26:37,029


480
00:26:37,029 --> 00:26:39,463
So here is fib of n,
let's just try running it.

481
00:26:39,463 --> 00:26:41,129
And again, we'll test
people's patience.

482
00:26:41,130 --> 00:26:54,140


483
00:26:54,140 --> 00:26:55,970
We'll see how long
we're letting it run.

484
00:26:55,970 --> 00:26:59,240
I'm going to try for
i in the range of 121.

485
00:26:59,240 --> 00:27:02,432
We'll print fib of i.

486
00:27:02,432 --> 00:27:09,839


487
00:27:09,839 --> 00:27:11,204
Comes clumping along.

488
00:27:11,204 --> 00:27:14,169


489
00:27:14,170 --> 00:27:16,970
It slows down pretty quickly.

490
00:27:16,970 --> 00:27:18,910
And if you look at it,
it's kind of surprising

491
00:27:18,910 --> 00:27:21,190
it's this slow because these
numbers aren't that big.

492
00:27:21,190 --> 00:27:24,090


493
00:27:24,089 --> 00:27:25,799
These are not enormous numbers.

494
00:27:25,799 --> 00:27:28,319
Fib of 35 is not a huge number.

495
00:27:28,319 --> 00:27:32,119
Yet it took a long
time to compute.

496
00:27:32,119 --> 00:27:34,279
So you have the numbers
growing pretty quickly

497
00:27:34,279 --> 00:27:38,149
but the computation, actually,
seems to be growing faster

498
00:27:38,150 --> 00:27:40,540
than the results.

499
00:27:40,539 --> 00:27:41,159
We're at 37.

500
00:27:41,160 --> 00:27:44,380


501
00:27:44,380 --> 00:27:48,250
It's going to gets slower and
slower, even though our numbers

502
00:27:48,250 --> 00:27:51,650
are not that big.

503
00:27:51,650 --> 00:27:53,870
The question is,
what's going on?

504
00:27:53,869 --> 00:27:57,439
Why is it taking so
long for Fibonacci

505
00:27:57,440 --> 00:28:00,789
to compute these results?

506
00:28:00,789 --> 00:28:13,579
Well, let's call it and
look at the question.

507
00:28:13,579 --> 00:28:18,559
And to do that I want to
look at the call tree.

508
00:28:18,559 --> 00:28:23,359
This is for Fibonacci
of 6, which is only 13,

509
00:28:23,359 --> 00:28:25,629
which, I think, most
of us would agree

510
00:28:25,630 --> 00:28:27,980
was not a very big number.

511
00:28:27,980 --> 00:28:30,200
And let's look
what's going on here.

512
00:28:30,200 --> 00:28:33,509


513
00:28:33,509 --> 00:28:35,750
If you look at this,
what in some sense

514
00:28:35,750 --> 00:28:39,410
seems really stupid about it?

515
00:28:39,410 --> 00:28:44,120
What is it doing that a
rational person would not want

516
00:28:44,119 --> 00:28:45,349
to do if they could avoid it?

517
00:28:45,349 --> 00:28:52,740


518
00:28:52,740 --> 00:28:55,319
It's bad enough to
do something once.

519
00:28:55,319 --> 00:28:57,779
But to do the same thing
over and over again

520
00:28:57,779 --> 00:29:00,990
is really wasteful.

521
00:29:00,990 --> 00:29:04,019
And if we look at this,
we'll see, for example,

522
00:29:04,019 --> 00:29:07,440
that fib 4 is being
computed here,

523
00:29:07,440 --> 00:29:11,350
and fib 4 is being
computed here.

524
00:29:11,349 --> 00:29:16,014
Fib 3 is being considered
here, and here, and here.

525
00:29:16,015 --> 00:29:19,190


526
00:29:19,190 --> 00:29:21,980
And do you think we'll get
a different answer for fib 3

527
00:29:21,980 --> 00:29:24,480
in one place when we get
it in the other place?

528
00:29:24,480 --> 00:29:27,230
You sure hope not.

529
00:29:27,230 --> 00:29:33,160
So you think, well, what
should we do about this?

530
00:29:33,160 --> 00:29:36,690
How would we go about avoiding
doing the same work over

531
00:29:36,690 --> 00:29:38,539
and over again?

532
00:29:38,539 --> 00:29:40,159
And there's kind of
an obvious answer,

533
00:29:40,160 --> 00:29:43,600
and that answer is at the
heart of dynamic programming.

534
00:29:43,599 --> 00:29:46,759
What's the answer?

535
00:29:46,759 --> 00:29:50,039
AUDIENCE: [INAUDIBLE]

536
00:29:50,039 --> 00:29:51,466
JOHN GUTTAG: Exactly.

537
00:29:51,467 --> 00:29:53,550
And I'm really happy that
someone in the front row

538
00:29:53,549 --> 00:29:57,990
answered the question because
I can throw it that far.

539
00:29:57,990 --> 00:30:03,660
You store the answer and then
look it up when you need it.

540
00:30:03,660 --> 00:30:06,580
Because we know that we can
look things up very quickly.

541
00:30:06,579 --> 00:30:09,099


542
00:30:09,099 --> 00:30:12,949
Dictionary, despite what
Eric said in his lecture,

543
00:30:12,950 --> 00:30:17,509
almost all the time
works in constant time

544
00:30:17,509 --> 00:30:20,960
if you make it big enough,
and it usually is in Python.

545
00:30:20,960 --> 00:30:25,279
We'll see later in the
term how to do that trick.

546
00:30:25,279 --> 00:30:30,519
So you store it and then you'd
never have to compute it again.

547
00:30:30,519 --> 00:30:34,900
And that's the basic trick
behind dynamic programming.

548
00:30:34,900 --> 00:30:41,940
And it's something
called memoization,

549
00:30:41,940 --> 00:30:44,890
as in you create a memo and
you store it in the memo.

550
00:30:44,890 --> 00:30:48,400


551
00:30:48,400 --> 00:30:50,620
So we see this here.

552
00:30:50,619 --> 00:30:56,149
Notice that what we're doing
is trading time for space.

553
00:30:56,150 --> 00:31:05,300
It takes some space to store
the old results, but negligible

554
00:31:05,299 --> 00:31:08,750
related to the time we save.

555
00:31:08,750 --> 00:31:10,130
So here's the trick.

556
00:31:10,130 --> 00:31:13,530
We're going to create a table
to record what we've done.

557
00:31:13,529 --> 00:31:16,379
And then before
computing fib of x,

558
00:31:16,380 --> 00:31:20,370
we'll check if the value
has already been computed.

559
00:31:20,369 --> 00:31:22,919
If so, we just look
it up and return it.

560
00:31:22,920 --> 00:31:25,000
Otherwise, we'll compute it--

561
00:31:25,000 --> 00:31:27,000
it's the first time-- and
store it in the table.

562
00:31:27,000 --> 00:31:31,559


563
00:31:31,559 --> 00:31:36,190
Here is a fast implementation
of Fibonacci that does that.

564
00:31:36,190 --> 00:31:38,980
It looks like the
old one, except it's

565
00:31:38,980 --> 00:31:41,410
got an extra argument--

566
00:31:41,410 --> 00:31:45,350
memo-- which is a dictionary.

567
00:31:45,349 --> 00:31:47,959
The first time we call it,
the memo will be empty.

568
00:31:47,960 --> 00:31:52,319


569
00:31:52,319 --> 00:31:57,240
It tries to return
the value in the memo.

570
00:31:57,240 --> 00:32:01,079
If it's not there, an exception
will get raised, we know that.

571
00:32:01,079 --> 00:32:05,179
And it will branch to
here, compute the result,

572
00:32:05,180 --> 00:32:11,190
and then store it in
the memo and return it.

573
00:32:11,190 --> 00:32:13,259
It's the same old
recursive thing

574
00:32:13,259 --> 00:32:16,920
we did before but with the memo.

575
00:32:16,920 --> 00:32:20,190
Notice, by the way, that
I'm using exceptions

576
00:32:20,190 --> 00:32:22,350
not as an error
handling mechanism,

577
00:32:22,349 --> 00:32:26,269
really, but just as
a flow of control.

578
00:32:26,269 --> 00:32:29,509
To me, this is cleaner than
writing code that says,

579
00:32:29,509 --> 00:32:34,440
if this is in the keys, then
do this, otherwise, do that.

580
00:32:34,440 --> 00:32:37,440
It's slightly fewer lines of
code, and for me, at least,

581
00:32:37,440 --> 00:32:41,049
easier to read to use try-except
for this sort of thing.

582
00:32:41,049 --> 00:32:44,690


583
00:32:44,690 --> 00:32:48,930
Let's see what happens
if we run this one.

584
00:32:48,930 --> 00:33:02,810
Get rid of the slow fib
and we'll run fastFib.

585
00:33:02,809 --> 00:33:17,779


586
00:33:17,779 --> 00:33:20,240
Wow.

587
00:33:20,240 --> 00:33:25,960
We're already done with fib 120.

588
00:33:25,960 --> 00:33:28,980
Pretty amazing, considering last
time we got stuck around 40.

589
00:33:28,980 --> 00:33:31,890


590
00:33:31,890 --> 00:33:35,700
It really works, this
memoization trick.

591
00:33:35,700 --> 00:33:37,440
An enormous difference.

592
00:33:37,440 --> 00:33:47,940


593
00:33:47,940 --> 00:33:49,559
When can you use it?

594
00:33:49,559 --> 00:33:53,009
It's not that memorization
is a magic bullet that

595
00:33:53,009 --> 00:33:54,480
will solve all problems.

596
00:33:54,480 --> 00:33:58,710


597
00:33:58,710 --> 00:34:01,799
The problems it can solve,
it can help with, really,

598
00:34:01,799 --> 00:34:02,970
is the right thing.

599
00:34:02,970 --> 00:34:06,779
And by the way, as we'll see, it
finds an optimal solution, not

600
00:34:06,779 --> 00:34:10,019
an approximation.

601
00:34:10,019 --> 00:34:13,920
Problems have two things
called optimal substructure,

602
00:34:13,920 --> 00:34:16,619
overlapping subproblems.

603
00:34:16,619 --> 00:34:19,349
What are these mean?

604
00:34:19,349 --> 00:34:21,449
We have optimal
substructure when

605
00:34:21,449 --> 00:34:23,550
a globally optimal
solution can be

606
00:34:23,550 --> 00:34:31,650
found by combining optimal
solutions to local subproblems.

607
00:34:31,650 --> 00:34:35,130
So for example, when
x is greater than 1

608
00:34:35,130 --> 00:34:42,900
we can solve fib x by solving
fib x minus 1 and fib x minus 2

609
00:34:42,900 --> 00:34:47,079
and adding those
two things together.

610
00:34:47,079 --> 00:34:50,130
So there is optimal
substructure--

611
00:34:50,130 --> 00:34:53,650
you solve these two smaller
problems independently

612
00:34:53,650 --> 00:34:58,059
of each other and then combine
the solutions in a fast way.

613
00:34:58,059 --> 00:35:03,750


614
00:35:03,750 --> 00:35:09,489
You also have to have something
called overlapping subproblems.

615
00:35:09,489 --> 00:35:11,839
This is why the memo worked.

616
00:35:11,840 --> 00:35:14,570
Finding an optimal
solution has to involve

617
00:35:14,570 --> 00:35:19,200
solving the same
problem multiple times.

618
00:35:19,199 --> 00:35:21,089
Even if you have
optimal substructure,

619
00:35:21,090 --> 00:35:24,570
if you don't see the same
problem more than once--

620
00:35:24,570 --> 00:35:25,760
creating a memo.

621
00:35:25,760 --> 00:35:28,950
Well, it'll work, you can
still create the memo.

622
00:35:28,949 --> 00:35:30,789
You'll just never
find anything in it

623
00:35:30,789 --> 00:35:32,730
when you look things
up because you're

624
00:35:32,730 --> 00:35:34,275
solving each problem once.

625
00:35:34,275 --> 00:35:36,809


626
00:35:36,809 --> 00:35:41,090
So you have to be solving the
same problem multiple times

627
00:35:41,090 --> 00:35:45,090
and you have to be able to
solve it by combining solutions

628
00:35:45,090 --> 00:35:45,975
to smaller problems.

629
00:35:45,974 --> 00:35:48,940


630
00:35:48,940 --> 00:35:51,780
Now, we've seen things with
optimal substructure before.

631
00:35:51,780 --> 00:35:54,920


632
00:35:54,920 --> 00:35:58,250
In some sense, merge
sort worked that way--

633
00:35:58,250 --> 00:36:00,769
we were combining
separate problems.

634
00:36:00,769 --> 00:36:03,259
Did merge sort have
overlapping subproblems?

635
00:36:03,260 --> 00:36:05,930


636
00:36:05,929 --> 00:36:09,980
No, because-- well,
I guess, it might

637
00:36:09,980 --> 00:36:13,550
have if the list had the same
element many, many times.

638
00:36:13,550 --> 00:36:17,450
But we would expect, mostly not.

639
00:36:17,449 --> 00:36:19,939
Because each time we're
solving a different problem,

640
00:36:19,940 --> 00:36:21,860
because we have different
lists that we're now

641
00:36:21,860 --> 00:36:24,320
sorting and merging.

642
00:36:24,320 --> 00:36:27,559
So it has half of it
but not the other.

643
00:36:27,559 --> 00:36:31,519
Dynamic programming will
not help us for sorting,

644
00:36:31,519 --> 00:36:34,619
cannot be used to
improve merge sort.

645
00:36:34,619 --> 00:36:37,769
Oh, well, nothing
is a silver bullet.

646
00:36:37,769 --> 00:36:40,509


647
00:36:40,510 --> 00:36:43,980
What about the knapsack problem?

648
00:36:43,980 --> 00:36:46,840
Does it have these
two properties?

649
00:36:46,840 --> 00:36:50,640


650
00:36:50,639 --> 00:36:55,210
We can look at it in
terms of these pictures.

651
00:36:55,210 --> 00:36:58,990
And it's pretty clear that it
does have optimal substructure

652
00:36:58,989 --> 00:37:02,319
because we're taking the left
branch and the right branch

653
00:37:02,320 --> 00:37:03,400
and choosing the winner.

654
00:37:03,400 --> 00:37:06,210


655
00:37:06,210 --> 00:37:10,490
But what about
overlapping subproblems?

656
00:37:10,489 --> 00:37:13,479
Are we ever solving, in this
case, the same problem--

657
00:37:13,480 --> 00:37:16,329


658
00:37:16,329 --> 00:37:17,119
add two nodes?

659
00:37:17,119 --> 00:37:21,480


660
00:37:21,480 --> 00:37:23,909
Well, do any of these
nodes look identical?

661
00:37:23,909 --> 00:37:28,429


662
00:37:28,429 --> 00:37:30,859
In this case, no.

663
00:37:30,860 --> 00:37:34,250
We could write a dynamic
programming solution

664
00:37:34,250 --> 00:37:35,579
to the knapsack problem--

665
00:37:35,579 --> 00:37:40,170
and we will-- and run
it on this example,

666
00:37:40,170 --> 00:37:42,059
and we'd get the right answer.

667
00:37:42,059 --> 00:37:45,130
We would get zero speedup.

668
00:37:45,130 --> 00:37:46,960
Because at each
node, if you can see,

669
00:37:46,960 --> 00:37:49,360
the problems are different.

670
00:37:49,360 --> 00:37:53,309
We have different things in the
knapsack or different things

671
00:37:53,309 --> 00:37:54,630
to consider.

672
00:37:54,630 --> 00:37:57,215
Never do we have the same
contents and the same things

673
00:37:57,215 --> 00:37:57,840
left to decide.

674
00:37:57,840 --> 00:38:01,769


675
00:38:01,769 --> 00:38:04,800
So "maybe" was not a bad
answer if that was the answer

676
00:38:04,800 --> 00:38:05,940
you gave to this question.

677
00:38:05,940 --> 00:38:08,550


678
00:38:08,550 --> 00:38:11,950
But let's look at
a different menu.

679
00:38:11,949 --> 00:38:15,009
This menu happens to
have two beers in it.

680
00:38:15,010 --> 00:38:19,110


681
00:38:19,110 --> 00:38:22,680
Now, if we look at
what happens, do

682
00:38:22,679 --> 00:38:25,819
we see two nodes that are
solving the same problem?

683
00:38:25,820 --> 00:38:31,789


684
00:38:31,789 --> 00:38:34,639
The answer is what?

685
00:38:34,639 --> 00:38:35,509
Yes or no?

686
00:38:35,510 --> 00:38:43,200


687
00:38:43,199 --> 00:38:45,480
I haven't drawn the
whole tree here.

688
00:38:45,480 --> 00:38:49,440
Well, you'll notice
the answer is yes.

689
00:38:49,440 --> 00:38:56,829
This node and this node are
solving the same problem.

690
00:38:56,829 --> 00:38:58,059
Why is it?

691
00:38:58,059 --> 00:39:02,130
Well, in this node,
we took this beer

692
00:39:02,130 --> 00:39:05,269
and still had this
one to consider.

693
00:39:05,269 --> 00:39:10,250
But in this node,
we took that beer

694
00:39:10,250 --> 00:39:12,920
but it doesn't matter
which beer we took.

695
00:39:12,920 --> 00:39:17,750
We still have a beer in
the knapsack and a burger

696
00:39:17,750 --> 00:39:20,659
and a slice to consider.

697
00:39:20,659 --> 00:39:24,069
So we got there different ways,
by choosing different beers,

698
00:39:24,070 --> 00:39:27,769
but we're in the same place.

699
00:39:27,769 --> 00:39:30,880
So in fact, we
actually, in this case,

700
00:39:30,880 --> 00:39:37,480
do have the same problem
to solve more than once.

701
00:39:37,480 --> 00:39:42,940
Now, here I had two
things that were the same.

702
00:39:42,940 --> 00:39:45,309
That's not really necessary.

703
00:39:45,309 --> 00:39:49,429
Here's another
very small example.

704
00:39:49,429 --> 00:39:56,329
And the point I want to
make here is shown by this.

705
00:39:56,329 --> 00:39:59,389
So here I have again
drawn a search tree.

706
00:39:59,389 --> 00:40:02,599
And I'm showing you this
because, in fact, it's exactly

707
00:40:02,599 --> 00:40:07,429
this tree that will be producing
in our dynamic programming

708
00:40:07,429 --> 00:40:10,039
solution to the
knapsack problem.

709
00:40:10,039 --> 00:40:16,219
Each node in the tree starts
with what you've taken--

710
00:40:16,219 --> 00:40:18,500
initially, nothing,
the empty set.

711
00:40:18,500 --> 00:40:22,429
What's left, the total value,
and the remaining calories.

712
00:40:22,429 --> 00:40:24,710
There's some redundancy
here, by the way.

713
00:40:24,710 --> 00:40:27,409
If I know what I've taken, I
could already always compute

714
00:40:27,409 --> 00:40:31,309
the value and what's left.

715
00:40:31,309 --> 00:40:33,865
But this is just so
it's easier to see.

716
00:40:33,865 --> 00:40:35,739
And I've numbered the
nodes here in the order

717
00:40:35,739 --> 00:40:37,129
in which they're get generated.

718
00:40:37,130 --> 00:40:40,240


719
00:40:40,239 --> 00:40:44,649
Now, the thing that
I want you to notice

720
00:40:44,650 --> 00:40:49,420
is, when we ask whether we're
solving the same problem,

721
00:40:49,420 --> 00:40:56,059
we don't actually
care what we've taken.

722
00:40:56,059 --> 00:41:00,739
We don't even care
about the value.

723
00:41:00,739 --> 00:41:08,679
All we care is, how much room
we have left in the knapsack

724
00:41:08,679 --> 00:41:11,514
and which items we
have left to consider.

725
00:41:11,514 --> 00:41:14,279


726
00:41:14,280 --> 00:41:20,490
Because what I take next or
what I take remaining really

727
00:41:20,489 --> 00:41:23,219
has nothing to do with how
much value I already have

728
00:41:23,219 --> 00:41:27,419
because I'm trying to maximize
the value that's left,

729
00:41:27,420 --> 00:41:30,599
independent of
previous things done.

730
00:41:30,599 --> 00:41:36,210
Similarly, I don't care why
I have a 100 calories left.

731
00:41:36,210 --> 00:41:39,490
Whether I used it up on beers
or a burger, doesn't matter.

732
00:41:39,489 --> 00:41:44,569
All that matters is that
I just have 100 left.

733
00:41:44,570 --> 00:41:49,910
So we see in a large complicated
problem it could easily

734
00:41:49,909 --> 00:41:53,389
be a situation where different
choices of what to take

735
00:41:53,389 --> 00:41:57,619
and what to not take would
leave you in a situation

736
00:41:57,619 --> 00:41:59,835
where you have the same
number of remaining calories.

737
00:41:59,835 --> 00:42:02,670


738
00:42:02,670 --> 00:42:05,700
And therefore you are solving a
problem you've already solved.

739
00:42:05,699 --> 00:42:12,219


740
00:42:12,219 --> 00:42:15,489
At each node, we're just
given the remaining weight,

741
00:42:15,489 --> 00:42:19,539
maximize the value by choosing
among the remaining items.

742
00:42:19,539 --> 00:42:20,710
That's all that matters.

743
00:42:20,710 --> 00:42:23,309


744
00:42:23,309 --> 00:42:26,779
And so indeed, you will have
overlapping subproblems.

745
00:42:26,780 --> 00:42:29,320


746
00:42:29,320 --> 00:42:33,690
As we see in this tree, for
the example we just saw,

747
00:42:33,690 --> 00:42:36,240
the box is around a place
where we're actually

748
00:42:36,239 --> 00:42:39,899
solving the same problem,
even though we've

749
00:42:39,900 --> 00:42:44,579
made different decisions about
what to take, A versus B.

750
00:42:44,579 --> 00:42:46,889
And in fact, we have
different amounts of value

751
00:42:46,889 --> 00:42:48,059
in the knapsack--

752
00:42:48,059 --> 00:42:49,650
6 versus 7.

753
00:42:49,650 --> 00:42:53,769
What matters is we still
have C and D to consider

754
00:42:53,769 --> 00:42:56,259
and we have two units left.

755
00:42:56,260 --> 00:43:03,930


756
00:43:03,929 --> 00:43:06,629
It's a small and easy step.

757
00:43:06,630 --> 00:43:08,430
I'm not going to walk
you through the code

758
00:43:08,429 --> 00:43:10,859
because it's kind
of boring to do so.

759
00:43:10,860 --> 00:43:16,610
How do you modify the maxVal we
looked at before to use a memo?

760
00:43:16,610 --> 00:43:19,789
First, you have to add the third
argument, which is initially

761
00:43:19,789 --> 00:43:23,610
going to be set to
the empty dictionary.

762
00:43:23,610 --> 00:43:26,840
The key of the memo
will be a tuple--

763
00:43:26,840 --> 00:43:32,660
the items left to be considered
and the available weight.

764
00:43:32,659 --> 00:43:37,369
Because the items left to
be considered are in a list,

765
00:43:37,369 --> 00:43:41,420
we can represent the items
left to be considered

766
00:43:41,420 --> 00:43:45,550
by how long the list is.

767
00:43:45,550 --> 00:43:47,710
Because we'll start at
the front item and just

768
00:43:47,710 --> 00:43:48,760
work our way to the end.

769
00:43:48,760 --> 00:43:52,460


770
00:43:52,460 --> 00:43:55,039
And then the function
works, essentially,

771
00:43:55,039 --> 00:43:57,699
exactly the same
way fastFib worked.

772
00:43:57,699 --> 00:44:03,795


773
00:44:03,795 --> 00:44:06,169
I'm not going to run it for
you because we're running out

774
00:44:06,170 --> 00:44:08,755
of time.

775
00:44:08,755 --> 00:44:10,130
You might want to
run it yourself

776
00:44:10,130 --> 00:44:14,119
because it is kind of fun to
see how really fast it is.

777
00:44:14,119 --> 00:44:19,569
But more interestingly,
we can look at this table.

778
00:44:19,570 --> 00:44:22,809
This column is what we would
get with the original recursive

779
00:44:22,809 --> 00:44:26,320
implementation where
we didn't use a memo.

780
00:44:26,320 --> 00:44:30,730
And it was therefore 2
to the length of items.

781
00:44:30,730 --> 00:44:34,990
And as you can see,
it gets really big

782
00:44:34,989 --> 00:44:37,389
or, as we say at the end, huge.

783
00:44:37,389 --> 00:44:40,769


784
00:44:40,769 --> 00:44:43,949
But the number of
calls grows incredibly

785
00:44:43,949 --> 00:44:49,199
slowly for the dynamic
programming solution.

786
00:44:49,199 --> 00:44:53,359
In the beginning
it's worth Oh, well.

787
00:44:53,360 --> 00:44:58,670
But by the time we get to
the last number I wrote,

788
00:44:58,670 --> 00:45:03,289
we're looking at 43,000
versus some really big number

789
00:45:03,289 --> 00:45:06,210
I don't know how to pronounce--

790
00:45:06,210 --> 00:45:09,409
18 somethings.

791
00:45:09,409 --> 00:45:14,119
Incredible improvement
in performance.

792
00:45:14,119 --> 00:45:17,659
And then at the
end, it's a number

793
00:45:17,659 --> 00:45:21,079
we couldn't fit on the
slide, even in tiny font.

794
00:45:21,079 --> 00:45:25,460
And yet, only 703,000 calls.

795
00:45:25,460 --> 00:45:27,380
How can this be?

796
00:45:27,380 --> 00:45:30,769
We know the problem is
inherently exponential.

797
00:45:30,769 --> 00:45:34,050
Have we overturned the
laws of the universe?

798
00:45:34,050 --> 00:45:38,860
Is dynamic programming a
miracle in the liturgical sense?

799
00:45:38,860 --> 00:45:40,849
No.

800
00:45:40,849 --> 00:45:43,519
But the thing I want
you to carry away

801
00:45:43,519 --> 00:45:50,190
is that computational complexity
can be a very subtle notion.

802
00:45:50,190 --> 00:45:52,470
The running time
of fastMaxVal is

803
00:45:52,469 --> 00:45:55,619
governed by the number
of distinct pairs

804
00:45:55,619 --> 00:46:00,690
that we might be able to
use as keys in the memo--

805
00:46:00,690 --> 00:46:03,480
toConsider and available.

806
00:46:03,480 --> 00:46:08,429
The number of possible values
of toConsider is small.

807
00:46:08,429 --> 00:46:10,869
It's bounded by the
length of the items.

808
00:46:10,869 --> 00:46:16,329
If I have a 100 items,
it's 0, 1, 2, up to a 100.

809
00:46:16,329 --> 00:46:19,299
The possible values
of available weight

810
00:46:19,300 --> 00:46:22,340
is harder to characterize.

811
00:46:22,340 --> 00:46:26,030
But it's bounded by the number
of distinct sums of weights

812
00:46:26,030 --> 00:46:28,530
you can get.

813
00:46:28,530 --> 00:46:33,590
If I start with
750 calories left,

814
00:46:33,590 --> 00:46:35,100
what are the possibilities?

815
00:46:35,099 --> 00:46:40,329
Well, in fact, in this case,
maybe we can take only 750

816
00:46:40,329 --> 00:46:42,619
because we're using with units.

817
00:46:42,619 --> 00:46:43,519
So it's small.

818
00:46:43,519 --> 00:46:45,940
But it's actually smaller
than that because it

819
00:46:45,940 --> 00:46:48,760
has to do with the
combinations of ways

820
00:46:48,760 --> 00:46:52,040
I can add up the units I have.

821
00:46:52,039 --> 00:46:53,509
I know this is complicated.

822
00:46:53,510 --> 00:46:56,560
It's not worth my going through
the details in the lectures.

823
00:46:56,559 --> 00:47:01,610
It's covered in considerable
detail in the assigned reading.

824
00:47:01,610 --> 00:47:03,860
Quickly summarizing
lectures 1 and 2,

825
00:47:03,860 --> 00:47:06,320
here's what I want
you to take away.

826
00:47:06,320 --> 00:47:08,330
Many problems of
practical importance

827
00:47:08,329 --> 00:47:12,081
can be formulated as
optimization problems.

828
00:47:12,081 --> 00:47:16,339
Greedy algorithms often provide
an adequate though often not

829
00:47:16,340 --> 00:47:18,750
optimal solution.

830
00:47:18,750 --> 00:47:21,869
Even though finding
an optimal solution

831
00:47:21,869 --> 00:47:24,630
is, in theory,
exponentially hard,

832
00:47:24,630 --> 00:47:29,760
dynamic programming really
often yields great results.

833
00:47:29,760 --> 00:47:33,110
It always gives you a correct
result and it's sometimes,

834
00:47:33,110 --> 00:47:37,890
in fact, most of the times
gives it to you very quickly.

835
00:47:37,889 --> 00:47:39,659
Finally, in the
PowerPoint, you'll

836
00:47:39,659 --> 00:47:42,869
find an interesting
optimization problem

837
00:47:42,869 --> 00:47:46,000
having to do with whether or
not you should roll over problem

838
00:47:46,000 --> 00:47:48,920
that grades into a quiz.

839
00:47:48,920 --> 00:47:51,900
And it's simply a question
of solving this optimization

840
00:47:51,900 --> 00:47:53,450
problem.

841
00:47:53,449 --> 00:48:03,823


