WEBVTT

1
00:00:02.252 --> 00:00:05.592
The Hadoop Ecosystem: So Much free Stuff!

2
00:00:20.275 --> 00:00:24.046
How did the big data
open-source movement begin?

3
00:00:24.046 --> 00:00:28.492
In 2004 Google published
a paper about their

4
00:00:28.492 --> 00:00:33.811
in-house processing framework
they called MapReduce.

5
00:00:33.811 --> 00:00:37.699
The next year,
Yahoo released an open-source

6
00:00:37.699 --> 00:00:42.369
implementation based on this
framework called Hadoop.

7
00:00:42.369 --> 00:00:45.379
In the following years,
other frameworks and

8
00:00:45.379 --> 00:00:49.650
tools were released to the community
as open-source projects.

9
00:00:49.650 --> 00:00:53.764
These frameworks provided new
capabilities missing in Hadoop,

10
00:00:53.764 --> 00:00:56.990
such as SQL like querying or
high level scripting.

11
00:00:59.240 --> 00:01:03.220
Today, there are over 100
open-source projects for

12
00:01:03.220 --> 00:01:06.880
big data and
this number continues to grow.

13
00:01:08.160 --> 00:01:11.181
Many rely on Hadoop, but
some are independent.

14
00:01:13.711 --> 00:01:18.420
With so many frameworks and tools
available, how do we learn what they do?

15
00:01:19.600 --> 00:01:26.590
We can organize them with a layer diagram
to understand their capabilities.

16
00:01:26.590 --> 00:01:30.830
Sometimes we also used the term
stack instead of a layer diagram.

17
00:01:32.560 --> 00:01:37.400
In a layer diagram,
a component uses the functionality or

18
00:01:37.400 --> 00:01:41.958
capabilities of the components
in the layer below it.

19
00:01:41.958 --> 00:01:47.470
Usually components at the same
layer do not communicate.

20
00:01:47.470 --> 00:01:54.669
And a component never assumes a specific
tool or component is above it.

21
00:01:54.669 --> 00:02:00.901
In this example,
component A is in the bottom layer,

22
00:02:00.901 --> 00:02:04.370
which components B and C use.

23
00:02:06.170 --> 00:02:09.390
Component D uses B, but not C.

24
00:02:11.240 --> 00:02:13.790
And D does not directly use A.

25
00:02:17.060 --> 00:02:21.630
Let's look at one set of tools in
the Hadoop ecosystem as a layer diagram.

26
00:02:23.920 --> 00:02:30.795
This layer diagram is organized
vertically based on the interface.

27
00:02:30.795 --> 00:02:35.054
Low level interfaces, so storage and
scheduling, on the bottom.

28
00:02:35.054 --> 00:02:39.315
And high level languages and
interactivity at the top.

29
00:02:41.915 --> 00:02:47.315
The Hadoop distributed file system,
or HDFS, is the foundation for

30
00:02:47.315 --> 00:02:53.570
many big data frameworks, since it
provides scaleable and reliable storage.

31
00:02:54.740 --> 00:03:00.380
As the size of your data increases,
you can add commodity hardware

32
00:03:00.380 --> 00:03:05.660
to HDFS to increase storage capacity so

33
00:03:05.660 --> 00:03:09.250
it enables scaling out of your resources.

34
00:03:11.460 --> 00:03:15.388
Hadoop YARN provides
flexible scheduling and

35
00:03:15.388 --> 00:03:19.220
resource management over the HDFS storage.

36
00:03:20.910 --> 00:03:25.988
YARN is used at Yahoo to schedule
jobs across 40,000 servers.

37
00:03:28.370 --> 00:03:33.430
MapReduce is a programming model
that simplifies parallel computing.

38
00:03:34.720 --> 00:03:39.300
Instead of dealing with the complexities
of synchronization and scheduling, you

39
00:03:39.300 --> 00:03:45.920
only need to give MapReduce two functions,
map and reduce, as you heard before.

40
00:03:48.020 --> 00:03:50.080
This programming model is so

41
00:03:50.080 --> 00:03:55.740
powerful that Google previously
used it for indexing websites.

42
00:03:59.450 --> 00:04:05.009
MapReduce only assume a limited
model to express data.

43
00:04:05.009 --> 00:04:10.094
Hive and Pig are two additional
programming models on

44
00:04:10.094 --> 00:04:15.292
top of MapReduce to augment
data modeling of MapReduce

45
00:04:15.292 --> 00:04:21.398
with relational algebra and
data flow modeling respectively.

46
00:04:21.398 --> 00:04:25.718
Hive was created at
Facebook to issue SQL-like

47
00:04:25.718 --> 00:04:30.038
queries using MapReduce
on their data in HDFS.

48
00:04:30.038 --> 00:04:37.951
Pig was created at Yahoo to model data
flow based programs using MapReduce.

49
00:04:37.951 --> 00:04:41.431
Thanks to YARN stability
to manage resources,

50
00:04:41.431 --> 00:04:45.959
not just for MapReduce but
other programming models as well.

51
00:04:45.959 --> 00:04:50.787
Giraph was built for
processing large-scale graphs efficiently.

52
00:04:50.787 --> 00:04:57.904
For example, Facebook uses Giraph to
analyze the social graphs of its users.

53
00:04:57.904 --> 00:05:03.196
Similarly, Storm, Spark,
and Flink were built for

54
00:05:03.196 --> 00:05:07.899
real time and
in memory processing of big data on

55
00:05:07.899 --> 00:05:12.381
top of the YARN resource scheduler and
HDFS.

56
00:05:12.381 --> 00:05:17.986
In-memory processing is a powerful way of
running big data applications even faster,

57
00:05:17.986 --> 00:05:21.787
achieving 100x's better performance for
some tasks.

58
00:05:24.446 --> 00:05:28.405
Sometimes, your data or
processing tasks are not easily or

59
00:05:28.405 --> 00:05:33.330
efficiently represented using the file and
directory model of storage.

60
00:05:34.620 --> 00:05:39.810
Examples of this include collections
of key-values or large sparse tables.

61
00:05:41.990 --> 00:05:49.381
NoSQL projects such as Cassandra,
MongoDB, and HBase handle these cases.

62
00:05:49.381 --> 00:05:54.180
Cassandra was created at Facebook,
but Facebook also used HBase for

63
00:05:54.180 --> 00:05:56.010
its messaging platform.

64
00:05:58.320 --> 00:06:03.560
Finally, running all of these tools
requires a centralized management system

65
00:06:03.560 --> 00:06:08.490
for synchronization, configuration and
to ensure high availability.

66
00:06:09.860 --> 00:06:13.210
Zookeeper performs these duties.

67
00:06:13.210 --> 00:06:17.700
It was created by Yahoo to wrangle
services named after animals.

68
00:06:20.060 --> 00:06:22.990
A major benefit of the Hadoop ecosystem

69
00:06:22.990 --> 00:06:25.340
is that all these tools
are open-source projects.

70
00:06:26.450 --> 00:06:28.920
You can download and use them for free.

71
00:06:30.220 --> 00:06:34.934
Each project has a community of users and
developers that

72
00:06:34.934 --> 00:06:39.756
answer questions, fix bugs and
implement new features.

73
00:06:39.756 --> 00:06:44.370
You can mix and match to get only
the tools you need to achieve your goals.

74
00:06:46.010 --> 00:06:50.330
Alternatively, there are several
pre-built stacks of these tools

75
00:06:50.330 --> 00:06:54.670
offered by companies such as Cloudera,
MAPR and Hortonworks.

76
00:06:56.090 --> 00:07:00.850
These companies provide the core
software stacks for free and

77
00:07:00.850 --> 00:07:03.740
offer commercial support for
production environments.

78
00:07:05.800 --> 00:07:09.110
As a summary, the Hadoop ecosystem

79
00:07:09.110 --> 00:07:13.672
consists of a growing number
of open-source tools.

80
00:07:13.672 --> 00:07:17.502
Providing opportunities to
pick the right tool for

81
00:07:17.502 --> 00:07:21.788
the right tasks for
better performance and lower costs.

82
00:07:21.788 --> 00:07:25.284
We will reveal some of these
tools in further detail and

83
00:07:25.284 --> 00:07:29.620
provide an analysis of when to use
which in the next set of lectures.