WEBVTT

1
00:00:02.450 --> 00:00:06.090
So we have seen how to compute
degree histograms of a graph.

2
00:00:07.760 --> 00:00:11.100
While degree histograms are useful
to characterize a graph,

3
00:00:11.100 --> 00:00:13.110
it is usually a means to an end.

4
00:00:14.130 --> 00:00:18.400
It's a known practice in statistics to
compute a mathematical expression for

5
00:00:18.400 --> 00:00:22.390
a statistical distribution
Using histograms.

6
00:00:23.910 --> 00:00:28.600
For graphs, we often look for a function
to describe the degree distribution.

7
00:00:29.620 --> 00:00:33.510
But this is expressed as
a distribution of the probability

8
00:00:33.510 --> 00:00:38.090
that a random vertex will
have exactly k neighbors.

9
00:00:38.090 --> 00:00:40.669
Now, this problem has been
investigated by many.

10
00:00:41.780 --> 00:00:45.300
One popular, well known model,
is a Power Law.

11
00:00:46.770 --> 00:00:52.910
A graph follows a Power Law if,
the best probability is given by k,

12
00:00:52.910 --> 00:00:55.380
erased to a negative
exponent called alpha.

13
00:00:56.890 --> 00:01:01.660
The value of alpha, for many practical
networks, is between two and three.

14
00:01:03.240 --> 00:01:04.310
More recently,

15
00:01:04.310 --> 00:01:07.750
people have suggested other distributions
that look like the power law graph.

16
00:01:08.880 --> 00:01:12.611
One of them is a log-normal graph.

17
00:01:12.611 --> 00:01:16.148
Here, the logarithm of k has
a Gaussian distribution.

18
00:01:16.148 --> 00:01:20.630
So this log-normal distribution
seems to have the better fit to

19
00:01:20.630 --> 00:01:23.120
natural graphs that are observed.

20
00:01:25.200 --> 00:01:27.280
So, why are power law graphs important?

21
00:01:28.930 --> 00:01:31.290
Interestingly, many very,

22
00:01:31.290 --> 00:01:34.810
very different real life graphs in
the world seem to follow the power law.

23
00:01:36.030 --> 00:01:41.860
If a graph does follow the power law, it
would have one large connected component

24
00:01:41.860 --> 00:01:49.030
with a very high proportion of notes
connected to it In a power law graph,

25
00:01:50.060 --> 00:01:54.036
most nodes have a low degree and
some nodes will be disconnected.

26
00:01:54.036 --> 00:01:59.260
The low degree nodes belong to
a very dense sub graphs and

27
00:01:59.260 --> 00:02:01.600
those sub graphs are connected
to each other through hubs.

28
00:02:03.150 --> 00:02:06.700
In the center of the graph
has a high density,

29
00:02:06.700 --> 00:02:09.690
power law graphs can be
difficult to compute with.

30
00:02:09.690 --> 00:02:13.907
For example, the shortest path
algorithm operating in the dense part

31
00:02:13.907 --> 00:02:18.695
will possibly be very inefficient, not
because of the size of the network, but

32
00:02:18.695 --> 00:02:22.928
because there are too many paths to
explore inside the denser pieces.

33
00:02:27.090 --> 00:02:31.574
The more interesting reason why
people study power-law graphs

34
00:02:31.574 --> 00:02:35.570
is because power-law graphs
are supposed to be robust.

35
00:02:36.840 --> 00:02:42.329
So in nature, all biological networks
show power-law graphs because

36
00:02:42.329 --> 00:02:47.552
It gives you a high rate of redundancy
against failure and attacks.