WEBVTT

1
00:00:00.550 --> 00:00:03.512
Now that we revealed all three layers,

2
00:00:03.512 --> 00:00:08.556
we are ready to come back to
the Integration and Processing layer.

3
00:00:08.556 --> 00:00:12.652
Just a simple Google search for
Big Data Processing Pipelines

4
00:00:12.652 --> 00:00:17.378
will bring a vast number of pipelines
with large number of technologies

5
00:00:17.378 --> 00:00:22.041
that support scalable data cleaning,
preparation, and analysis.

6
00:00:24.091 --> 00:00:28.286
How do we make sense of it all to
make sure we use the right tools for

7
00:00:28.286 --> 00:00:29.540
our application?

8
00:00:30.660 --> 00:00:35.490
We will continue our lecture to review
a set of evaluation criteria for

9
00:00:35.490 --> 00:00:40.750
these systems and some of the big data
processing systems based on this criteria.

10
00:00:42.250 --> 00:00:47.850
Depending on the resources we have access
to and characteristics of our application,

11
00:00:47.850 --> 00:00:51.130
we apply several
considerations to evaluate and

12
00:00:51.130 --> 00:00:52.920
pick a software stack for big data.

13
00:00:54.010 --> 00:00:59.410
Of these, first one we consider
is the Execution Model,

14
00:00:59.410 --> 00:01:04.450
and the expressivity of it to support for
various transformations of batch or

15
00:01:04.450 --> 00:01:07.430
streaming data, or
sometimes interactive computing.

16
00:01:08.920 --> 00:01:12.550
Semantics of streaming,
including exactly once or

17
00:01:12.550 --> 00:01:17.620
at least one processing for each event, or
being able to keep the state of the data,

18
00:01:17.620 --> 00:01:21.680
is an important concern for
this execution model.

19
00:01:21.680 --> 00:01:26.110
Latency is another important criteria,
depending on the application.

20
00:01:27.210 --> 00:01:30.760
Having a low latency system
is very important for

21
00:01:30.760 --> 00:01:34.345
applications like online gaming and
hazards management.

22
00:01:34.345 --> 00:01:38.340
Whereas most applications
are less time critical,

23
00:01:38.340 --> 00:01:43.800
like search engine indexing, and would
be fine with a batch processing ability.

24
00:01:44.820 --> 00:01:49.760
Scalability for both small and
large datasets and different

25
00:01:49.760 --> 00:01:54.070
analytical methods and algorithms,
is also an important evaluation criteria.

26
00:01:55.290 --> 00:01:59.430
As well as support for
different programming language

27
00:01:59.430 --> 00:02:03.470
of the libraries used by the analytical
tools that we have access to.

28
00:02:04.700 --> 00:02:09.030
Finally, while all big data
tools provide fault tolerance,

29
00:02:09.030 --> 00:02:14.390
the mechanics of how the fault tolerance is
handled is an important issue to consider.

30
00:02:15.790 --> 00:02:18.900
Let's review five of
the big data processing

31
00:02:18.900 --> 00:02:23.390
engines supported by the Apache Foundation
using this evaluation criteria.

32
00:02:25.300 --> 00:02:30.230
The MapReduce implementation of
Hadoop provides a batch execution

33
00:02:30.230 --> 00:02:35.230
model where the data from HDFS gets
loaded into mappers before processing.

34
00:02:36.440 --> 00:02:39.380
There is no in-memory processing support,

35
00:02:39.380 --> 00:02:44.490
meaning the mappers write the data on
files before the reducers can read it,

36
00:02:44.490 --> 00:02:48.250
resulting in a high-latency and
less scalable execution.

37
00:02:49.960 --> 00:02:53.690
This also hinders
the performance of iterative and

38
00:02:53.690 --> 00:02:58.827
interactive applications that require many
steps of transformations using MapReduce.

39
00:03:01.150 --> 00:03:04.835
Although the only native
programming interface for

40
00:03:04.835 --> 00:03:09.870
MapReduce is in Java, other programming
languages like Python provide modules or

41
00:03:09.870 --> 00:03:14.370
libraries for Hadoop MapReduce
programming, however with less efficiency.

42
00:03:16.180 --> 00:03:20.730
Data replication is the primary
method of fault tolerance,

43
00:03:20.730 --> 00:03:26.270
which in turn affects the scalability and
execution speed further.

44
00:03:26.270 --> 00:03:29.560
Spark was built to support iterative and

45
00:03:29.560 --> 00:03:34.730
interactive big data processing
pipelines efficiently using an in-memory

46
00:03:34.730 --> 00:03:39.800
structure called Resilient Distributed
Datasets, or shortly, RDDs.

47
00:03:41.040 --> 00:03:45.860
In addition to map and reduce operations,
it provides support for

48
00:03:45.860 --> 00:03:49.890
a range of transformation
operations like join and filter.

49
00:03:49.890 --> 00:03:55.711
Any pipeline of transformations can
be applied to these RDD's in-memory,

50
00:03:55.711 --> 00:04:00.829
making Spark's performance very high for
iterative processing.

51
00:04:02.538 --> 00:04:07.480
The RDD extraction is also designed
to handle fault tolerance with

52
00:04:07.480 --> 00:04:09.230
less impact on performance.

53
00:04:10.886 --> 00:04:13.170
In addition to HDFS,

54
00:04:13.170 --> 00:04:18.200
Spark can read data from many storage
platforms and it provides support for

55
00:04:18.200 --> 00:04:24.155
streaming data applications using
a technique called micro-batching.

56
00:04:24.155 --> 00:04:30.250
Its latency can be on the order of
seconds depending on the batch size,

57
00:04:30.250 --> 00:04:34.030
which is relatively slower compared
to native streaming platforms.

58
00:04:35.600 --> 00:04:40.320
Spark has support for a number of
programming languages, including Scala and

59
00:04:40.320 --> 00:04:44.260
Python as the most popular ones,
as well as built-in libraries for

60
00:04:44.260 --> 00:04:46.500
graph processing and machine learning.

61
00:04:47.530 --> 00:04:51.415
Although Flink has very
similar transformations and

62
00:04:51.415 --> 00:04:55.890
in-memory data extractions with Spark,
it provides direct support for

63
00:04:55.890 --> 00:04:59.517
streaming data,
making it a lower-latency framework.

64
00:05:00.620 --> 00:05:04.720
It provides connection interfaces to
streaming data ingestion engines like

65
00:05:04.720 --> 00:05:06.020
Kafka and Flume.

66
00:05:07.460 --> 00:05:11.340
Flink supports application
programming interfaces in Java and

67
00:05:11.340 --> 00:05:12.966
Scala just like Spark.

68
00:05:12.966 --> 00:05:17.760
Starting with it's original
version called Stratosphere,

69
00:05:17.760 --> 00:05:23.010
Flink had it's own execution engine
called Nephele, and had an ability

70
00:05:23.010 --> 00:05:27.670
to run both on Hadoop and also separately
in its own execution environment.

71
00:05:29.060 --> 00:05:33.110
In addition to map and reduce,
Flink provides abstractions for

72
00:05:33.110 --> 00:05:37.055
other data parallel database
patterns like join and group by.

73
00:05:39.210 --> 00:05:44.010
One of the biggest advantage of using
Flink comes from it's optimizer

74
00:05:44.010 --> 00:05:47.460
to pick and apply the best pattern and
execution strategy.

75
00:05:48.490 --> 00:05:52.080
There has been experiments comparing
fault tolerance features of Flink

76
00:05:52.080 --> 00:05:56.720
to those of Sparks, which conclude
that Sparks slightly better for Spark.

77
00:05:57.840 --> 00:06:03.080
The Beam system, from Google,
is a relatively new system for

78
00:06:03.080 --> 00:06:06.890
batch and stream processing with
a data flow programming model.

79
00:06:08.080 --> 00:06:13.090
It initially used Google's own Cloud data
flow as an execution environment, but

80
00:06:13.090 --> 00:06:17.228
Spark and Flink backends for
it have been implemented recently.

81
00:06:17.228 --> 00:06:22.370
It's a low-latency environment with
high reviews on fault tolerance.

82
00:06:23.460 --> 00:06:28.456
It currently provides application
programming interfaces in Java and

83
00:06:28.456 --> 00:06:31.295
Scala, and a Python SDK is in the works.

84
00:06:31.295 --> 00:06:34.532
SDK means software development kit.

85
00:06:34.532 --> 00:06:40.690
Beam provides a very strong streaming and
windowing framework for streaming data.

86
00:06:40.690 --> 00:06:45.417
And it is highly scalable and reliable,
allowing it to make trade-off

87
00:06:45.417 --> 00:06:49.690
decisions between accuracy,
speed, and cost of processing.

88
00:06:51.710 --> 00:06:53.730
Storm has been designed for

89
00:06:53.730 --> 00:06:58.960
stream processing in real
time with very low-latency.

90
00:06:58.960 --> 00:07:03.930
It defined input stream interface
abstractions called spouts, and

91
00:07:03.930 --> 00:07:06.080
computation abstractions called bolts.

92
00:07:07.420 --> 00:07:11.700
Spouts and bolts can be pipelined
together using a data flow approach.

93
00:07:11.700 --> 00:07:15.430
That data gets queued until
the computation acknowledges

94
00:07:15.430 --> 00:07:16.190
the receipt of it.

95
00:07:18.310 --> 00:07:21.080
A master node tracks running jobs and

96
00:07:21.080 --> 00:07:24.860
ensures all data is processed
by the computations on workers.

97
00:07:26.430 --> 00:07:31.952
Nathan Mars, the lead developer for
Storm, built the Lambda Architecture

98
00:07:31.952 --> 00:07:37.744
using Storm for stream processing and
Hadoop MapReduce for batch processing.

99
00:07:40.660 --> 00:07:45.740
The Lambda Architecture
originally used Storm for

100
00:07:45.740 --> 00:07:50.229
speed layer and Hadoop and
HBase for batch and

101
00:07:50.229 --> 00:07:54.490
serving layers, as seen in this diagram.

102
00:07:55.840 --> 00:08:00.760
However, it was later used as a more
general framework that can combine

103
00:08:00.760 --> 00:08:06.990
the results of stream and batch processing
executed in multiple big data systems.

104
00:08:06.990 --> 00:08:12.700
This diagram shows a generalized Lambda
Architecture containing some of the tools

105
00:08:12.700 --> 00:08:19.930
we discussed earlier, including using
Spark for both batch and speed layers.

106
00:08:21.540 --> 00:08:25.530
In this course, we picked Spark
as a big data integration and

107
00:08:25.530 --> 00:08:30.600
processing environment since it supports
most of our evaluation criteria.

108
00:08:30.600 --> 00:08:35.862
And this hybrid data processing
architecture using built-in data querying,

109
00:08:35.862 --> 00:08:38.619
streaming, and analytical libraries.

110
00:08:38.619 --> 00:08:43.586
We will continue our discussion with
Spark and hands-on exercises in Spark.