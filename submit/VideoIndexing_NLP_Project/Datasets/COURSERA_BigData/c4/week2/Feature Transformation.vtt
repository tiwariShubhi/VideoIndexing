WEBVTT

1
00:00:01.850 --> 00:00:04.330
Let's now discuss what
feature transformation is.

2
00:00:05.640 --> 00:00:09.340
After this video you will be able
to articulate the purpose of

3
00:00:09.340 --> 00:00:14.170
feature transformation, list three
feature transformation operations, and

4
00:00:14.170 --> 00:00:16.180
discuss when scaling is important.

5
00:00:17.670 --> 00:00:19.390
In addition to feature selection,

6
00:00:19.390 --> 00:00:23.690
data pre-processing can also
include feature transformation.

7
00:00:23.690 --> 00:00:26.730
Feature transformation involves
mapping a set of values for

8
00:00:26.730 --> 00:00:30.860
the feature to a new set of values to
make the representation of the data more

9
00:00:30.860 --> 00:00:34.800
suitable or easier to process for
the downstream analysis.

10
00:00:36.760 --> 00:00:40.010
A common feature transformation
operation is scaling.

11
00:00:40.010 --> 00:00:42.200
This involves changing
the range of values for

12
00:00:42.200 --> 00:00:46.570
a feature of features to
another specified range.

13
00:00:46.570 --> 00:00:49.840
This is done to avoid allowing
features with large values to

14
00:00:49.840 --> 00:00:51.280
dominate the analysis results.

15
00:00:52.300 --> 00:00:56.030
For example, if your dataset has
both width and height as features,

16
00:00:56.030 --> 00:00:59.910
the magnitude of the weight values,
which are in pounds, will be much

17
00:00:59.910 --> 00:01:03.910
larger than the magnitude of the height
values which are in feet and inches.

18
00:01:03.910 --> 00:01:06.950
So scaling both features
to a common value range

19
00:01:06.950 --> 00:01:09.910
will make the contributions from
both weight and height equal.

20
00:01:11.350 --> 00:01:16.230
One way to perform scaling is to map all
values of a feature to a specific range

21
00:01:16.230 --> 00:01:18.690
such as between zero and one.

22
00:01:18.690 --> 00:01:21.342
For example,
let's say you have a feature for

23
00:01:21.342 --> 00:01:24.750
income that ranges from 30,000 to 100,000.

24
00:01:24.750 --> 00:01:29.420
And you have another feature for years
of employment that ranges from 0 to 50.

25
00:01:29.420 --> 00:01:32.500
These features have very different scales.

26
00:01:32.500 --> 00:01:35.840
If you want both features to have equal
weighting when you compare the data

27
00:01:35.840 --> 00:01:41.170
samples, then you can scale the range
of both features to be between 0 and 1.

28
00:01:41.170 --> 00:01:44.870
That way the income feature which is
on much largest scale than the years

29
00:01:44.870 --> 00:01:48.940
of employment feature will not
dominate the compares result.

30
00:01:48.940 --> 00:01:53.350
Alternatively, scaling can be perform
by transforming the features such that

31
00:01:53.350 --> 00:01:57.420
the results have zero mean,
and unit standard deviation.

32
00:01:57.420 --> 00:02:00.730
The steps to perform the scaling
is to first calculate the mean and

33
00:02:00.730 --> 00:02:03.930
standard deviation values for
the feature to be scaled.

34
00:02:03.930 --> 00:02:06.560
Then for each value, for this feature,

35
00:02:06.560 --> 00:02:11.510
subtract the mean value from that value,
and divide by the standard deviation.

36
00:02:11.510 --> 00:02:15.290
The transformed feature will end
up with a mean value of zero, and

37
00:02:15.290 --> 00:02:16.680
standard deviation of one.

38
00:02:17.720 --> 00:02:20.420
This effectively removes
the units of the features and

39
00:02:20.420 --> 00:02:25.370
converts each future value to number
of standard deviations from the mean.

40
00:02:26.540 --> 00:02:30.720
This scaling method is used when
the min and max values are known.

41
00:02:30.720 --> 00:02:34.760
This is also useful when there are
outliers which will skew the calculation

42
00:02:34.760 --> 00:02:38.380
for the range as the max value is
determined by the furthest outlier.

43
00:02:39.400 --> 00:02:43.980
This scaling operation is often
referred to as zero-normalization or

44
00:02:43.980 --> 00:02:45.030
as standardization.

45
00:02:46.390 --> 00:02:49.110
Filtering is another feature
transformation operation.

46
00:02:50.250 --> 00:02:55.450
This is commonly applied to time series
data, such as speech or audio signals.

47
00:02:55.450 --> 00:02:58.520
A low pass filter can be
used to filter out noise.

48
00:02:58.520 --> 00:03:02.910
Which usually manifests as the high
frequency component in the signal.

49
00:03:02.910 --> 00:03:07.090
A low pass filter removes components
above a certain frequency

50
00:03:07.090 --> 00:03:09.410
allowing the rest to
pass through unaltered.

51
00:03:10.750 --> 00:03:14.310
Filtering can also be used
to remove noise in images.

52
00:03:14.310 --> 00:03:19.530
Noise in an image is random variation
in intensity or color in the pixels.

53
00:03:19.530 --> 00:03:23.590
For example, a noise can cause
an image to appear grainy.

54
00:03:23.590 --> 00:03:28.180
A mean or median filter can be used to
replace the pixel value with the mean or

55
00:03:28.180 --> 00:03:30.240
median value of its neighboring pixels.

56
00:03:31.270 --> 00:03:33.730
This has the effect of
smoothing out the image,

57
00:03:33.730 --> 00:03:36.390
removing the noise that causes
the graininess in the image.

58
00:03:37.830 --> 00:03:41.911
Aggregation combines values for
a feature in order to summarize data or

59
00:03:41.911 --> 00:03:43.210
reduce variability.

60
00:03:44.340 --> 00:03:48.850
Aggregation combines values for a feature
in order to summarize the data or

61
00:03:48.850 --> 00:03:50.970
to reduce variability.

62
00:03:50.970 --> 00:03:55.660
Aggregation is done by summing or
averaging data values at a higher level.

63
00:03:55.660 --> 00:03:59.720
For example, hourly values can be
aggregated to the daily level.

64
00:03:59.720 --> 00:04:04.255
Or values within a city region can
be aggregated to a state level.

65
00:04:04.255 --> 00:04:07.010
These plots show
the results of aggregation.

66
00:04:07.010 --> 00:04:11.060
The left plot shows the wind
speed values in miles per hour

67
00:04:11.060 --> 00:04:14.730
averaged every 10 minutes
over a period of seven days.

68
00:04:14.730 --> 00:04:19.110
Notice that there's a lot of variability,
that is the values fluctuate a lot.

69
00:04:20.130 --> 00:04:23.730
The right plot shows wind speed
values averaged every hour so

70
00:04:23.730 --> 00:04:26.920
every 60 minutes instead
of every 10 minutes.

71
00:04:26.920 --> 00:04:31.340
Notice that the line is much smoother
here because the values are aggregated at

72
00:04:31.340 --> 00:04:32.750
a higher time scale level.

73
00:04:33.750 --> 00:04:36.900
So aggregation can have
the effect of removing noise

74
00:04:36.900 --> 00:04:40.160
to provide a clear representation
of the structure of your data.

75
00:04:41.240 --> 00:04:44.260
Another example is tracking stock prices.

76
00:04:44.260 --> 00:04:47.620
Hourly deviations of a stock
may be difficult to track but,

77
00:04:47.620 --> 00:04:52.900
aggregated daily changes may better reveal
any upward or downward trend of the stock.

78
00:04:54.280 --> 00:04:58.330
In summary, feature transformation
involves mapping the set of values for

79
00:04:58.330 --> 00:05:02.600
a feature to a new set of values to
make the representation of the data

80
00:05:02.600 --> 00:05:06.180
more suitable for the downstream analysis.

81
00:05:06.180 --> 00:05:10.090
Feature transformation should be used with
cautions since they change the nature of

82
00:05:10.090 --> 00:05:16.030
the data and unintentionally remove some
important characteristics of the data.

83
00:05:16.030 --> 00:05:19.757
So it's important to look at the effects
of the transformation you're applying

84
00:05:19.757 --> 00:05:22.897
to your data to make certain that
it has the intended consequences.