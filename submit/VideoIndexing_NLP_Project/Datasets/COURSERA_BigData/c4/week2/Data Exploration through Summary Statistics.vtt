WEBVTT

1
00:00:00.950 --> 00:00:04.820
Let's look at how we can use summary
statistics to explore data in more detail.

2
00:00:06.320 --> 00:00:11.740
After this video you will be able to
define what a summary statistic is,

3
00:00:11.740 --> 00:00:14.610
list three common summary statistics and

4
00:00:14.610 --> 00:00:17.930
explain how summary statistics
are useful in exploring data.

5
00:00:19.830 --> 00:00:24.096
Summary statistics are quantities
that describe a set of data values.

6
00:00:24.096 --> 00:00:29.750
Summary statistics provide a simple and
quick way to summarize a dataset.

7
00:00:29.750 --> 00:00:33.270
We will discuss three main
categories of summary statistics.

8
00:00:33.270 --> 00:00:38.650
Measures of location or centrality,
measures of spread, and measures of shape.

9
00:00:40.680 --> 00:00:44.970
Measures of location are summary
statistics that describe the central or

10
00:00:44.970 --> 00:00:47.670
typical value in your dataset.

11
00:00:47.670 --> 00:00:51.700
These statistics give a sense of
the middle or center of the dataset.

12
00:00:52.730 --> 00:00:56.870
Examples of these are mean,
median and mode.

13
00:00:56.870 --> 00:01:00.720
The mean is just the average
of the values in a dataset.

14
00:01:00.720 --> 00:01:05.198
The median is the value in the middle if
you sorted the values in your dataset.

15
00:01:05.198 --> 00:01:10.300
In a sorted list, half of the values
will be less than the median and

16
00:01:10.300 --> 00:01:11.930
half will be greater than the median.

17
00:01:13.200 --> 00:01:15.700
If the number of data values is even,

18
00:01:15.700 --> 00:01:18.609
then the median is the mean
of the two middle values.

19
00:01:19.620 --> 00:01:23.550
The mode is a value that is repeated
more often than any other value.

20
00:01:25.660 --> 00:01:29.290
In this example we have
a dataset with ten values.

21
00:01:29.290 --> 00:01:30.667
For this dataset,

22
00:01:30.667 --> 00:01:36.010
the mean is 51.1 which is the number
of all the values divided by 10.

23
00:01:36.010 --> 00:01:43.380
The median is 46, if you sort these
numbers, the middle numbers are 42 and 50.

24
00:01:43.380 --> 00:01:47.151
The average of these two numbers is 46.

25
00:01:47.151 --> 00:01:51.054
There are two modes for
the this dataset, 42 and 78,

26
00:01:51.054 --> 00:01:55.705
since each occurs twice,
more than any other value in the dataset.

27
00:01:57.480 --> 00:02:02.187
Measures of spread describe how
dispersed or varied your dataset is.

28
00:02:02.187 --> 00:02:06.764
Common measures of spread are minimum,
maximum, range,

29
00:02:06.764 --> 00:02:10.450
standard deviation and variance.

30
00:02:10.450 --> 00:02:13.440
Minimum and
maximum are of course the smallest and

31
00:02:13.440 --> 00:02:16.740
largest values in your
dataset respectively.

32
00:02:16.740 --> 00:02:21.070
The range is simply the difference
between the maximum and minimum and

33
00:02:21.070 --> 00:02:24.020
tells you how spread out your data is.

34
00:02:24.020 --> 00:02:27.785
Standard deviation describes the amount
of variation in your dataset.

35
00:02:28.920 --> 00:02:32.620
A low standard deviation value means
that the samples in your dataset

36
00:02:32.620 --> 00:02:34.630
tend to be close to the mean.

37
00:02:34.630 --> 00:02:39.050
And a high standard deviation value means
that the data samples are spread out.

38
00:02:39.050 --> 00:02:42.480
Variance is closely related
to standard deviation.

39
00:02:42.480 --> 00:02:46.530
In fact the variance is the square
of the standard deviation.

40
00:02:46.530 --> 00:02:51.900
So it also indicates how spread out
the data samples are from the mean.

41
00:02:51.900 --> 00:02:56.780
For the same dataset, the range is 66
which is a difference between the largest

42
00:02:56.780 --> 00:03:00.964
number which is 87 and
the smallest number which is 21.

43
00:03:00.964 --> 00:03:04.620
The variance is 548.767,

44
00:03:04.620 --> 00:03:09.770
you can calculate this using
a calculator or a spreadsheet.

45
00:03:09.770 --> 00:03:15.030
And the standard deviation is 23.426
which is the square root of the variance.

46
00:03:16.680 --> 00:03:21.470
Measures of shape describe the shape
of the distribution of a set of values.

47
00:03:21.470 --> 00:03:24.740
Common members of shape are skewness and
kurtosis.

48
00:03:25.790 --> 00:03:30.150
Skewness indicates whether the data
values are asymmetrically distributed.

49
00:03:31.150 --> 00:03:35.020
A skewness value of around zero
indicates that the data distribution

50
00:03:35.020 --> 00:03:38.760
is approximately normal, as shown in
the middle figure in the top diagram.

51
00:03:39.830 --> 00:03:44.280
A negative skewness value indicates that
the distribution is skewed to the left,

52
00:03:44.280 --> 00:03:47.590
as indicated in the left
figure in the top diagram.

53
00:03:47.590 --> 00:03:50.200
A positive skewness
value on the other hand

54
00:03:50.200 --> 00:03:53.230
indicates that the data distribution
is skewed to the right.

55
00:03:54.340 --> 00:03:58.430
Kurtosis measures the tailedness
of the data distribution or

56
00:03:58.430 --> 00:04:02.170
how heavy or
fat the tails of the distribution are.

57
00:04:02.170 --> 00:04:07.040
A high kurtosis value describes a
distribution with longer and fatter tails

58
00:04:07.040 --> 00:04:12.075
and a higher and sharper central peak,
indicating the presence of outliers.

59
00:04:12.075 --> 00:04:14.692
A low kurtosis value on the other hand,

60
00:04:14.692 --> 00:04:19.376
describes a distribution with shorter and
lighter tails and lower and

61
00:04:19.376 --> 00:04:23.280
broader central peak,
suggesting the lack of outliers.

62
00:04:25.140 --> 00:04:31.740
In our age example, the skewness is about
0.3 indicating a slight positive skew.

63
00:04:31.740 --> 00:04:37.210
And the kurtosis is -1.2 indicating
a distribution with a low and

64
00:04:37.210 --> 00:04:39.940
broad central peak and
shorter and lighter tails.

65
00:04:41.080 --> 00:04:46.210
Measures of dependence determine if any
relationship exists between variables.

66
00:04:46.210 --> 00:04:49.560
Pairwise correlation is a commonly
used measure of dependence.

67
00:04:50.850 --> 00:04:55.480
This is a table that shows pairwise
correlation for a set of variables.

68
00:04:55.480 --> 00:04:58.430
Note that correlation applies
only to numerical variables.

69
00:04:59.470 --> 00:05:04.517
Correlations is between zero and one,
with zero indicating no correlation,

70
00:05:04.517 --> 00:05:07.430
and one indicating a one
to one correlation.

71
00:05:07.430 --> 00:05:10.268
So a correlation of
0.89 is very strong and

72
00:05:10.268 --> 00:05:15.240
this is expected since a person's height
and weight should be very correlated.

73
00:05:16.780 --> 00:05:21.480
The summary statistics we just covered
are useful for numerical variables.

74
00:05:21.480 --> 00:05:25.900
For categorical variables, we want to look
at statistics that describe the number of

75
00:05:25.900 --> 00:05:29.290
categories and
the frequency of each category.

76
00:05:29.290 --> 00:05:31.400
This is done using a contingency table.

77
00:05:32.940 --> 00:05:35.860
Here's an example that shows
a distribution of people's pets and

78
00:05:35.860 --> 00:05:37.140
their colors.

79
00:05:37.140 --> 00:05:42.150
We can see the most common pet is
a dog and least common's a fish.

80
00:05:42.150 --> 00:05:45.948
Similarly, black is the most common
color and orange the least common.

81
00:05:45.948 --> 00:05:51.240
The contingency table also shows
the distribution between the categories.

82
00:05:51.240 --> 00:05:56.750
For example, only fish are orange
while most of the brown pets are dogs.

83
00:05:56.750 --> 00:05:59.810
In addition to looking at
the traditional summary statistics for

84
00:05:59.810 --> 00:06:05.100
numerical variables, and
category count for categorical variables.

85
00:06:05.100 --> 00:06:06.370
For machine learning problems,

86
00:06:06.370 --> 00:06:10.450
we also want to examine some additional
statistics to quickly validate the data.

87
00:06:11.760 --> 00:06:15.050
One of the first things to
check is the number of rows and

88
00:06:15.050 --> 00:06:17.660
the number of columns in your dataset.

89
00:06:17.660 --> 00:06:21.080
Does the number of rows match
the expected number of samples?

90
00:06:21.080 --> 00:06:25.110
Does the number of columns match
the expected number of variables?

91
00:06:25.110 --> 00:06:27.000
These should be very quick and
easy checks.

92
00:06:28.490 --> 00:06:32.770
Another easy data validation check is
to look at the values in the first and

93
00:06:32.770 --> 00:06:36.170
last few samples in your dataset
to see if they're reasonable.

94
00:06:37.500 --> 00:06:41.780
For example, do the temperature values
looks to be in the right units of measure.

95
00:06:43.180 --> 00:06:45.514
Do the values for rainfall look correct or

96
00:06:45.514 --> 00:06:48.053
are there some values
that look out of place?

97
00:06:48.053 --> 00:06:51.447
Are the data types for
your variables correct, for example,

98
00:06:51.447 --> 00:06:55.130
is the date field captured as dates or
timestamp.

99
00:06:55.130 --> 00:06:57.926
Or is it capture as a string or
numerical value?

100
00:06:57.926 --> 00:07:01.770
These will have consequences in how
these fields should be processed.

101
00:07:03.210 --> 00:07:06.490
Another important step is to check for
missing values.

102
00:07:06.490 --> 00:07:10.280
You need to determine the number
of samples with missing values.

103
00:07:10.280 --> 00:07:13.060
You also need to determine
if there are any variables

104
00:07:13.060 --> 00:07:14.964
with a high percentage of missing values.

105
00:07:16.155 --> 00:07:19.585
Handling missing values is a very
important step in data preparation

106
00:07:19.585 --> 00:07:21.260
which we will cover in the next module.

107
00:07:21.260 --> 00:07:25.875
Having this information will be very
helpful in determining how missing values

108
00:07:25.875 --> 00:07:27.915
should be handled in data preparation.

109
00:07:29.270 --> 00:07:33.190
We covered several types of summary
statistics useful for exploring data and

110
00:07:33.190 --> 00:07:34.590
machine learning.

111
00:07:34.590 --> 00:07:39.020
The statistics provide useful information
about your dataset and should be

112
00:07:39.020 --> 00:07:42.480
thoroughly examine if you want to get
a better understanding of your data.