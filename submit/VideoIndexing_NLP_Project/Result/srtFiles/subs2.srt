
1
00:00:01.270 --> 00:00:06.840
Let's look at a 2nd example where big data
can have a big impact on saving lives.

2
00:00:06.840 --> 00:00:10.428
I mean,
literally saving lives one life at a time.

3
00:00:10.428 --> 00:00:14.508
I collaborated with a number of
world-class researchers in San Diego, and

4
00:00:14.508 --> 00:00:18.911
an industrial group who are dedicated to
improving human health through research

5
00:00:18.911 --> 00:00:20.970
and practice of precision medicine.

6
00:00:22.400 --> 00:00:24.250
What is precision medicine?

7
00:00:24.250 --> 00:00:28.950
It is an emerging area of medicine
targeted toward an individual person.

8
00:00:28.950 --> 00:00:33.910
Analysing her genetics, her environment,
her daily activities so

9
00:00:33.910 --> 00:00:37.880
that one can detect or
predict a health problem early,

10
00:00:37.880 --> 00:00:42.570
help prevent disease and
in case of illness provide the right drug

11
00:00:42.570 --> 00:00:46.690
at the right dose that is
suitable just for her.

12
00:00:46.690 --> 00:00:51.587
Very recently the White House and
the National Institute of Health here

13
00:00:51.587 --> 00:00:56.401
in the U.S. have declared it to be
a top priority area for research and

14
00:00:56.401 --> 00:00:58.779
development for the next decade.

15
00:00:58.779 --> 00:01:01.689
The expected learning
outcome of this video is for

16
00:01:01.689 --> 00:01:04.668
you to give example of sensor,
organizational and

17
00:01:04.668 --> 00:01:07.870
people-generated data used
in precision medicine.

18
00:01:09.050 --> 00:01:13.650
And, explain why the integration of
different kinds of data is critical

19
00:01:13.650 --> 00:01:14.940
in advancing healthcare.

20
00:01:16.150 --> 00:01:20.000
For any technology to
succeed in real life we need

21
00:01:20.000 --> 00:01:24.940
not only a certain level of maturity of
the technology itself, but a number of

22
00:01:24.940 --> 00:01:30.050
enabling factors including social
economic environment, market demands,

23
00:01:30.050 --> 00:01:34.860
consumer readiness, cost effectiveness,
all of which must work together.

24
00:01:36.430 --> 00:01:39.790
Why is big data for
precision medicine important now?

25
00:01:39.790 --> 00:01:40.290
Let's see.

26
00:01:41.480 --> 00:01:44.900
An important aspect of precision
medicine is to utilize

27
00:01:44.900 --> 00:01:49.570
an individual's genetic profile for
his or her own diagnoses and treatment.

28
00:01:50.910 --> 00:01:52.630
Analyzing the human genome,

29
00:01:52.630 --> 00:01:56.670
which holds the key to human health
is rapidly becoming more affordable.

30
00:01:57.950 --> 00:02:01.110
Today's cost to sequence a genome is less

31
00:02:01.110 --> 00:02:03.760
than 10% of what it
cost just back in 2008.

32
00:02:03.760 --> 00:02:09.070
But, human genomic data is big.

33
00:02:09.070 --> 00:02:10.390
How big?

34
00:02:10.390 --> 00:02:14.660
In a perfect world, just the three
billion letters of your genome

35
00:02:14.660 --> 00:02:17.220
would require about 700
megabytes to store.

36
00:02:18.300 --> 00:02:23.280
In the real world, meaning the kind of
data generated from genome sequencing

37
00:02:23.280 --> 00:02:27.540
machines, we need 200GB to store a genome.

38
00:02:28.620 --> 00:02:32.700
And it takes now about
a day to sequence a genome.

39
00:02:32.700 --> 00:02:37.520
We are finally beginning to create more
electronic records that can be stored and

40
00:02:37.520 --> 00:02:39.130
manipulated in digital media.

41
00:02:40.270 --> 00:02:45.180
Most doctors offices and hospitals now
use electronic health record systems

42
00:02:45.180 --> 00:02:49.130
which contain all details of
a patient's visit and lab test.

43
00:02:50.410 --> 00:02:51.290
How big is this data?

44
00:02:52.710 --> 00:02:57.710
As a quick example The Samaritan Medical
Center Watertown New York at 294 that

45
00:02:57.710 --> 00:03:03.690
Community Hospital reported
120 terabytes as of 2013.

46
00:03:03.690 --> 00:03:07.490
The data value more than double
in just the last two years.

47
00:03:08.860 --> 00:03:13.860
So clearly just in a past two years
dramatic changes have prepared the health

48
00:03:13.860 --> 00:03:18.920
care industry to produce and analyze
larger mounts of complex patient data.

49
00:03:20.170 --> 00:03:25.570
To summarize what we have seen so far
the key components of these changes are:

50
00:03:25.570 --> 00:03:31.460
Reduced cost of data generation and
analysis, increased availability of cheap

51
00:03:31.460 --> 00:03:37.430
large data storage, and they increased
digitization of previously paper records.

52
00:03:38.430 --> 00:03:43.560
But we need one more capability to advance
toward the promised land of individualized

53
00:03:43.560 --> 00:03:44.410
health care practices.

54
00:03:45.950 --> 00:03:50.420
We need to combine various types of
data produce by different groups in

55
00:03:50.420 --> 00:03:51.130
a meaningful way.

56
00:03:52.580 --> 00:03:56.150
Let's look at this issue from
the same point of view as Ilka did.

57
00:03:56.150 --> 00:03:59.760
With her discussion of how big data
can help with wildfire analytics.

58
00:04:01.040 --> 00:04:04.980
The key is the integration of
multiple types of data sources.

59
00:04:04.980 --> 00:04:09.130
Data from sensors,
organizations and people.

60
00:04:09.130 --> 00:04:12.200
In the next few slides,
we look at each of these, and

61
00:04:12.200 --> 00:04:17.820
then I'll share a story about some of the
new and really exciting ways people data

62
00:04:17.820 --> 00:04:22.660
especially has the potential to
change healthcare big data landscape.

63
00:04:24.240 --> 00:04:25.320
Let's start with sensor data.

64
00:04:26.600 --> 00:04:31.000
Sure, digital hospital equipment
have been producing sensor data for

65
00:04:31.000 --> 00:04:35.720
years, but it was unlikely that
the data was ever stored or

66
00:04:35.720 --> 00:04:39.790
shared, let alone
analyzed retrospectively.

67
00:04:39.790 --> 00:04:41.025
These were intended for

68
00:04:41.025 --> 00:04:45.880
real-time use, to inform healthcare
professionals, and then got discarded.

69
00:04:47.110 --> 00:04:50.320
Now we have many more sensors and
deployment.

70
00:04:50.320 --> 00:04:52.850
And many more places
that are capturing and

71
00:04:52.850 --> 00:04:55.970
explicitly gathering information
to be stored and analyzed.

72
00:04:57.190 --> 00:04:59.970
Let's just take a new kind of data

73
00:04:59.970 --> 00:05:02.720
that's increasingly becoming
common in our daily lives.

74
00:05:04.960 --> 00:05:06.600
Fitness devices are everywhere now

75
00:05:07.770 --> 00:05:11.320
their sales have skyrocketed
in the last few years.

76
00:05:11.320 --> 00:05:16.360
They are in wristbands, watches, shoes and
vests, directly communicating with your

77
00:05:16.360 --> 00:05:21.160
personal mobile device, tracking several
activity variables like blood pressure,

78
00:05:21.160 --> 00:05:26.080
different types of activities,
blood glucose levels, etc at every moment.

79
00:05:26.080 --> 00:05:28.850
Their goal is to improve wellness.

80
00:05:28.850 --> 00:05:32.080
By having you monitor
your daily status and

81
00:05:32.080 --> 00:05:35.410
hopefully improve your
lifestyle to stay healthy.

82
00:05:35.410 --> 00:05:40.080
But the data they generate can be
very useful medical information

83
00:05:40.080 --> 00:05:44.100
because this data is about what
happens in your normal life and

84
00:05:44.100 --> 00:05:45.700
not just when you go to the doctor.

85
00:05:47.450 --> 00:05:49.660
How much data do they generate?

86
00:05:49.660 --> 00:05:53.890
The device called FitBit can
produce several gigabytes a day.

87
00:05:53.890 --> 00:05:58.900
Could this data be used to save healthcare
costs, effect a healthier lifestyle?

88
00:05:58.900 --> 00:05:59.660
That's a question mark.

89
00:06:01.090 --> 00:06:05.660
It's safe to guess that this data
alone wouldn't drive the dream of

90
00:06:05.660 --> 00:06:07.350
precision medicine.

91
00:06:07.350 --> 00:06:11.290
But what if we consider integrating
it with other sources of data

92
00:06:11.290 --> 00:06:14.060
like electronic health records or
a genomic profile?

93
00:06:15.150 --> 00:06:17.310
This remains an open question.

94
00:06:18.320 --> 00:06:22.460
This is an open arena for research that
my colleagues at scripts are doing.

95
00:06:22.460 --> 00:06:27.090
It's also a potentially significant area
for product and business development.

96
00:06:27.090 --> 00:06:30.480
Let's look at some examples of health
related data being generated by

97
00:06:30.480 --> 00:06:31.120
organizations.

98
00:06:32.630 --> 00:06:35.380
Many public databases
including those curated and

99
00:06:35.380 --> 00:06:39.690
managed by NCBI, the National Center for
Biotechnology Information,

100
00:06:39.690 --> 00:06:43.180
had been created to capture the basic
scientific data and knowledge for

101
00:06:43.180 --> 00:06:48.090
humans and other model organisms at
the different building blocks of life.

102
00:06:48.090 --> 00:06:53.220
These databases carry both experimental
and computed data that are necessary to

103
00:06:53.220 --> 00:06:56.193
observations for
unconquered diseases like cancer.

104
00:06:56.193 --> 00:07:00.730
In addition,
many have created knoweledge-bases

105
00:07:00.730 --> 00:07:04.500
like the Geneontology and
The Unified Medical Language System

106
00:07:04.500 --> 00:07:08.050
to assemble human knowledge in
a machine processable form.

107
00:07:08.050 --> 00:07:11.660
These are just a few examples of
organizational data sources and

108
00:07:11.660 --> 00:07:15.040
governmental data gathered by health
care systems around the world

109
00:07:15.040 --> 00:07:18.050
could also be used as a massive
source of information.

110
00:07:19.380 --> 00:07:22.210
But really some of
the most interesting and

111
00:07:22.210 --> 00:07:27.040
novel opportunities seem likely to come
from the area of people generated data.

112
00:07:28.410 --> 00:07:32.450
Mobile healths apps is an area
that is growing significantly.

113
00:07:32.450 --> 00:07:35.720
There are apps now to monitor heart rates,
blood pressure, and

114
00:07:35.720 --> 00:07:37.310
test oxygen saturation levels.

115
00:07:38.860 --> 00:07:42.630
Apps, we might say,
record data from sensors but

116
00:07:42.630 --> 00:07:45.040
are also obviously generated from people.

117
00:07:46.230 --> 00:07:50.160
But there is more people generated
data that's interesting beyond censure

118
00:07:51.530 --> 00:07:52.120
measurements.

119
00:07:52.120 --> 00:07:55.280
In 2015 the Webby People's Voice Award

120
00:07:55.280 --> 00:07:58.310
went to an app which supports
meditation and mindfulness.

121
00:07:59.410 --> 00:08:02.400
Rather than an electronic sensing device,

122
00:08:02.400 --> 00:08:07.259
a human would indicate how many
minutes per day they spent meditating.

123
00:08:07.259 --> 00:08:11.078
If they interact with the app
which reminds them to be mindful,

124
00:08:11.078 --> 00:08:15.630
then we have human generated behavior
that we couldn't get from a sensor.

125
00:08:16.840 --> 00:08:22.510
There are well over 100,000 health apps
today in either iTunes or Google Play.

126
00:08:22.510 --> 00:08:25.710
And by some estimates
the Mobile Health App market

127
00:08:25.710 --> 00:08:29.064
may be worth 27 billion dollars by 2017.

128
00:08:30.070 --> 00:08:35.500
So really we are just seen the beginning
of what data might be generated here

129
00:08:35.500 --> 00:08:41.490
from what's being called human sensors,
but to really understand where the power

130
00:08:41.490 --> 00:08:45.980
of people generated data might take us
in the era of big data for healthcare.

131
00:08:45.980 --> 00:08:48.360
Let's imagine how things stand now.

132
00:08:48.360 --> 00:08:51.660
In general,
a patient goes to see their doctor and

133
00:08:51.660 --> 00:08:55.960
maybe their doctor asks if they have had
any side effects from their medications.

134
00:08:57.060 --> 00:08:58.430
The accuracy and

135
00:08:58.430 --> 00:09:02.470
hence the quality of data patients provide
in this kind of setting is very low.

136
00:09:03.620 --> 00:09:05.170
Not that it's really the patients fault.

137
00:09:06.240 --> 00:09:09.930
It might have been days or
weeks ago that they experienced something.

138
00:09:09.930 --> 00:09:13.760
They may be unsure whether something
they experienced was actually a reaction

139
00:09:13.760 --> 00:09:15.380
to then report it.

140
00:09:15.380 --> 00:09:18.590
And there might be details about exactly
when they took a medication that

141
00:09:18.590 --> 00:09:20.790
are meaningful, but
they've forgotten it after the fact.

142
00:09:22.520 --> 00:09:28.120
Today, people are self reporting reactions
and experiences they are having.

143
00:09:28.120 --> 00:09:32.540
We're on Twitter, on blog sites,
online support groups,

144
00:09:32.540 --> 00:09:37.030
online data sharing services: these
are sources of data that we've

145
00:09:37.030 --> 00:09:41.660
never had before that can be used to
understand in a far more detailed and

146
00:09:41.660 --> 00:09:46.360
personal rate the impact of drug
integrations are responses to certain

147
00:09:47.640 --> 00:09:50.430
If applications were designed
to integrate doctor and

148
00:09:50.430 --> 00:09:55.040
hospital records with information
on when drugs were taken and

149
00:09:55.040 --> 00:10:00.000
then to further mine social media or
collect self reports from patients.

150
00:10:00.000 --> 00:10:03.230
Who knows what kinds of questions
we will be able to answer?

151
00:10:03.230 --> 00:10:05.008
Or new questions we may be able to ask?

1
00:00:01.690 --> 00:00:03.830
Where does big data come from?

2
00:00:03.830 --> 00:00:07.720
The first thing I would like to
say before talking about big data

3
00:00:07.720 --> 00:00:09.010
is that it is not new.

4
00:00:10.040 --> 00:00:14.600
Most of the big data sources existed
before, but the scale we use and

5
00:00:14.600 --> 00:00:17.020
apply them today has changed.

6
00:00:17.020 --> 00:00:21.590
Just look at this image of open
link data on the Internet.

7
00:00:21.590 --> 00:00:23.740
I thought this image was so cool.

8
00:00:23.740 --> 00:00:27.350
It shows not only there are so
many sources of data, but

9
00:00:27.350 --> 00:00:28.490
they're also connected.

10
00:00:29.690 --> 00:00:32.147
If you want to check it out yourself,

11
00:00:32.147 --> 00:00:35.408
we'll give you the link
at the end of this video.

12
00:00:35.408 --> 00:00:40.859
Big data is often boiled down to a few
varieties of data generated by machines,

13
00:00:40.859 --> 00:00:44.010
people, and organizations.

14
00:00:44.010 --> 00:00:49.057
With machine generated data we refer to
data generated from real time sensors in

15
00:00:49.057 --> 00:00:54.029
industrial machinery or vehicles that
logs that track user behavior online,

16
00:00:54.029 --> 00:00:55.687
environmental sensors or

17
00:00:55.687 --> 00:00:59.930
personal health trackers, and
many other sense data resources.

18
00:01:01.080 --> 00:01:05.560
The Large Hadron Collider
generates 40 terabytes of data

19
00:01:05.560 --> 00:01:08.560
every second during experiments.

20
00:01:08.560 --> 00:01:14.078
But human generated data, we refer to
the vast amount of social media data,

21
00:01:14.078 --> 00:01:18.420
status updates, tweets,
photos, and medias.

22
00:01:18.420 --> 00:01:23.943
With organizational generated data we
refer to more traditional types of data,

23
00:01:23.943 --> 00:01:27.598
including transaction
information in databases and

24
00:01:27.598 --> 00:01:31.026
structured data open
stored in data warehouses.

25
00:01:31.026 --> 00:01:35.437
Note that big data can be either
structured, semi-structured, or

26
00:01:35.437 --> 00:01:40.390
unstructured, which is a topic we will
talk about more later in this course.

27
00:01:41.530 --> 00:01:47.180
In most business use cases, any single
source of data on its own is not useful.

28
00:01:48.490 --> 00:01:53.880
Real value often comes from combining
these streams of big data sources

29
00:01:53.880 --> 00:01:58.210
with each other and
analyzing them to generate new insights,

30
00:01:58.210 --> 00:02:00.430
which then goes back into
being big data themselves.

31
00:02:01.890 --> 00:02:03.870
Once you have such insights,

32
00:02:03.870 --> 00:02:08.320
it then enables what we call data
enabled decisions and actions.

33
00:02:09.670 --> 00:02:13.858
Let's now look into these different
types of big data in more detail.

1
00:00:01.081 --> 00:00:04.312
Why is Big Data generated
by machines useful?

2
00:00:28.325 --> 00:00:31.997
Let's go back for
a second to our first example for

3
00:00:31.997 --> 00:00:34.715
machine generated big data planes.

4
00:00:35.790 --> 00:00:38.940
What is producing all
that data on the plane?

5
00:00:40.430 --> 00:00:43.180
If you look at some of
the sensors that contribute

6
00:00:43.180 --> 00:00:46.600
to the half terabyte of
data generated on a plane,

7
00:00:46.600 --> 00:00:52.040
we will find that some of it comes from
accelerometers that measure turbulence.

8
00:00:53.350 --> 00:00:58.393
There are also sensors built into
the engines for temperature, pressure,

9
00:00:58.393 --> 00:01:02.666
many other measurable factors
to detect engine malfunctions.

10
00:01:02.666 --> 00:01:07.487
Constant real-time analysis of all
the data collected provides help

11
00:01:07.487 --> 00:01:11.496
monitoring and
problem detection at 40,000 feet.

12
00:01:11.496 --> 00:01:15.622
That's approximately 12,000
meters above ground.

13
00:01:17.800 --> 00:01:22.210
We call this type of
analytical processing in-situ.

14
00:01:22.210 --> 00:01:27.940
Previously, in traditional relational
database management systems,

15
00:01:27.940 --> 00:01:32.160
data was often moved to
computational space for processing.

16
00:01:32.160 --> 00:01:37.000
In Big Data space In-Situ
means bringing the computation

17
00:01:37.000 --> 00:01:40.865
to where data is located or,
in this case, generated.

18
00:01:43.200 --> 00:01:47.936
A key feature of these types
of real-time notifications is

19
00:01:47.936 --> 00:01:51.090
that they enable real-time actions.

20
00:01:51.090 --> 00:01:55.756
However, using such a capability
would require you to approach your

21
00:01:55.756 --> 00:01:58.580
application and your work differently.

22
00:02:00.000 --> 00:02:05.090
If you are using an activity tracker, you
should probably come up with a strategy

23
00:02:05.090 --> 00:02:09.540
for how you will incorporate the usage of
these useful gadgets into your lifestyle.

24
00:02:10.780 --> 00:02:15.520
Just like that, if you're planning to
incorporate Big Data driven insights into

25
00:02:15.520 --> 00:02:21.610
your organization, you need to define
a new strategy, and a new way of working.

26
00:02:23.570 --> 00:02:29.184
Most Big Data centric businesses have
updated their culture to be more real-time

27
00:02:29.184 --> 00:02:34.160
action oriented, refining real-time
processes to handle anything from customer

28
00:02:34.160 --> 00:02:38.080
relations and fraud detection,
to system monitoring and control.

29
00:02:39.200 --> 00:02:44.150
In addition, such volumes of real-time
data and analytical operations that need

30
00:02:44.150 --> 00:02:49.880
to take place requires an increased
use of scalable computing systems,

31
00:02:49.880 --> 00:02:53.870
which need to be a part of the planning
for an organizational Big Data strategy.

32
00:02:55.700 --> 00:02:59.580
They see affects of such
changes also in SCADA system.

33
00:03:00.920 --> 00:03:04.630
SCADA stands for Supervisory Control and
Data Acquisition.

34
00:03:06.580 --> 00:03:11.710
SCADA is a type of industrial control
system for remote monitoring and

35
00:03:11.710 --> 00:03:17.190
control of industrial processes
that exists in the physical world,

36
00:03:17.190 --> 00:03:21.020
potentially including multiple sites,
many types of sensors.

37
00:03:23.080 --> 00:03:28.410
In addition to monitoring and control,
SCADA system can be used to define

38
00:03:28.410 --> 00:03:33.390
actions for reduced waste and improved
efficiency in industrial processes,

39
00:03:33.390 --> 00:03:39.100
including those of manufacturing and
power generation, public or

40
00:03:39.100 --> 00:03:43.820
private infrastructure processes,
including water treatment, oil, and

41
00:03:43.820 --> 00:03:49.040
gas pipelines, and
electrical power transmission, and

42
00:03:49.040 --> 00:03:54.300
facility processes including buildings,
airports, ships, and space stations.

43
00:03:55.550 --> 00:04:00.240
They can even be used in smart
building applications to monitor and

44
00:04:00.240 --> 00:04:05.910
control heating, ventilation,
air conditioning systems like HVAC,

45
00:04:05.910 --> 00:04:08.030
access, and energy consumption.

46
00:04:09.330 --> 00:04:14.040
Again, the management of these processes
once the trends, patterns, and

47
00:04:14.040 --> 00:04:20.460
anomalies are identified in real-time
needs to be decided in the Big Data case.

48
00:04:20.460 --> 00:04:26.960
As a summary, as the largest and fastest
type of Big Data, machine generated

49
00:04:26.960 --> 00:04:31.690
data can uniquely enable real-time
actions in many systems and processes.

50
00:04:32.740 --> 00:04:40.198
However, a culture shift is needed for
its computing and real-time action.

1
00:00:00.910 --> 00:00:02.630
Big data generated by machines.

2
00:00:03.680 --> 00:00:05.508
It's everywhere and there's a lot.

3
00:00:16.258 --> 00:00:19.120
Do big planes require big data?

4
00:00:19.120 --> 00:00:20.650
Absolutely!

5
00:00:20.650 --> 00:00:24.770
Did you know that a Boeing 787 produces

6
00:00:24.770 --> 00:00:27.450
half a terabyte of data
every time it flies?

7
00:00:28.640 --> 00:00:33.680
Really, almost every part of
the plane updates both the flight and

8
00:00:33.680 --> 00:00:35.990
the ground team about
its status constantly.

9
00:00:37.105 --> 00:00:38.530
Where's all this data coming from?

10
00:00:39.560 --> 00:00:43.360
This is an example of machine-generated
data coming from sensors.

11
00:00:44.730 --> 00:00:47.730
If you look at all sources of big data,

12
00:00:47.730 --> 00:00:51.470
machine data is the largest
source of big data.

13
00:00:51.470 --> 00:00:54.850
Additionally, it is very complex.

14
00:00:54.850 --> 00:01:00.960
In general, we call machines that provide
some type of sensing capability smart.

15
00:01:00.960 --> 00:01:04.760
Have you ever wondered why you
call your cell phone a smartphone?

16
00:01:05.890 --> 00:01:08.790
Because it gives you a way
to track many things,

17
00:01:08.790 --> 00:01:12.740
including your geolocation, and
connect you to other things.

18
00:01:13.930 --> 00:01:16.716
So what makes a smart device smart, smart?

19
00:01:16.716 --> 00:01:22.110
Generally speaking, There are three
main properties of smart devices

20
00:01:22.110 --> 00:01:27.200
based on what they do with sensors and
things they encapsulate.

21
00:01:27.200 --> 00:01:29.480
They can connect to other devices or

22
00:01:29.480 --> 00:01:35.490
networks, they can execute services and
collect data autonomously,

23
00:01:35.490 --> 00:01:40.230
that means on their own, they have
some knowledge of the environment.

24
00:01:41.550 --> 00:01:46.940
The widespread availability of the smart
devices and their interconnectivity

25
00:01:46.940 --> 00:01:53.080
led to a new term being coined,
The Internet of Things.

26
00:01:53.080 --> 00:01:58.450
Think of a world of smart devices at home,
in your car, in the office,

27
00:01:58.450 --> 00:02:04.110
city, remote rural areas,
the sky, even the ocean,

28
00:02:04.110 --> 00:02:07.340
all connected and all generating data.

29
00:02:08.360 --> 00:02:12.590
Let's look at an example of a device
that has some of these things in it.

30
00:02:14.350 --> 00:02:19.930
An activity tracker is a device or
application for monitoring and

31
00:02:19.930 --> 00:02:25.790
tracking fitness-related metrics
such as distance walked or run,

32
00:02:25.790 --> 00:02:32.670
calorie consumption, and in some cases,
heartbeat and quality of sleep.

33
00:02:32.670 --> 00:02:37.140
What if everyone in New York City
wore an activity tracker?

34
00:02:37.140 --> 00:02:40.350
What if everyone wore several?

35
00:02:40.350 --> 00:02:45.300
I personally have three activity
trackers that I use on a daily basis.

36
00:02:45.300 --> 00:02:50.200
One to track my sleep, another one
to track my physical activity, and

37
00:02:50.200 --> 00:02:54.250
a third, my smartphone,
that goes everywhere with me.

38
00:02:54.250 --> 00:03:00.030
So it is not that unusual to imagine that
this will be the case for many people.

39
00:03:00.030 --> 00:03:05.320
As you have already heard from in
a previous lecture on personalized data,

40
00:03:05.320 --> 00:03:08.760
such activity trackers
have enabled a new way

41
00:03:08.760 --> 00:03:12.210
of doing patient intervention
via personalized medicine.

42
00:03:13.670 --> 00:03:18.440
Similarly, the sensors in planes have
generated a new way of looking at

43
00:03:18.440 --> 00:03:21.370
fleet management and flight safety.

44
00:03:21.370 --> 00:03:26.055
As a summary,
machines collect data 24/7 via

45
00:03:26.055 --> 00:03:31.980
their built-in sensors,
both at personal and industrial scales.

46
00:03:31.980 --> 00:03:35.308
And thus, they are the largest
of all the big data sources.

1
00:00:01.300 --> 00:00:02.963
Organization-Generated Data.

2
00:00:02.963 --> 00:00:09.580
Benefits come from combining
with other data types.

3
00:00:09.580 --> 00:00:12.380
How are some organizations
benefiting from big data?

4
00:00:29.278 --> 00:00:31.844
Let's look at real world examples to
see the advantages these organizations

5
00:00:31.844 --> 00:00:32.800
are getting out of big data.

6
00:00:33.960 --> 00:00:36.120
One of these companies is UPS.

7
00:00:37.720 --> 00:00:41.650
UPS delivers 16 million shipments per day.

8
00:00:41.650 --> 00:00:46.360
They get around 40 million
tracking requests.

9
00:00:46.360 --> 00:00:46.900
That's huge.

10
00:00:48.270 --> 00:00:54.431
An estimate of how much data UPS has
on its operations is 16 petabytes.

11
00:00:55.880 --> 00:01:00.580
Can you guess how much money UPS can
save by reducing each driver's route

12
00:01:00.580 --> 00:01:01.620
by just one mile?

13
00:01:03.410 --> 00:01:09.113
If they can reduce distance traveled
by each truck by even one mile,

14
00:01:09.113 --> 00:01:13.830
UPS can save a whopping $50 million U.S.
per year.

15
00:01:15.490 --> 00:01:19.010
This is where big data steps in.

16
00:01:19.010 --> 00:01:22.610
Utilizing complex optimization
over large datasets

17
00:01:22.610 --> 00:01:27.250
can lead to route optimizations that were
previously not visible to the company.

18
00:01:29.110 --> 00:01:32.900
Big data, together with smart processing,

19
00:01:32.900 --> 00:01:36.720
enables UPS to manage thousands
of route optimizations.

20
00:01:37.900 --> 00:01:43.310
Let's travel from package
delivery to the retail domain.

21
00:01:43.310 --> 00:01:46.870
An organization from
the retail shopping domain

22
00:01:46.870 --> 00:01:49.760
that heavily utilizes big data is Walmart.

23
00:01:51.590 --> 00:01:58.220
Walmart is a big organization that gets
250 million customers in 10,000 stores.

24
00:02:00.820 --> 00:02:07.570
Did you know they collect 2.5
petabytes of data per hour?

25
00:02:09.280 --> 00:02:14.699
They collect data on Twitter tweets,
local events, local weather,

26
00:02:14.699 --> 00:02:19.640
in-store purchases, online clicks and

27
00:02:19.640 --> 00:02:23.530
many other sales, customer and
product related data.

28
00:02:25.070 --> 00:02:31.080
They use this data to find patterns
such as which products are frequently

29
00:02:31.080 --> 00:02:36.878
purchased together, and what is the best
new product to introduce in their stores,

30
00:02:36.878 --> 00:02:41.530
to predict demand at
the particular location,

31
00:02:43.670 --> 00:02:47.898
and to customize customer recommendations.

32
00:02:47.898 --> 00:02:50.430
Overall, by leveraging big data and

33
00:02:50.430 --> 00:02:55.390
analytics, Walmart has maintained
its position as a top retailer.

34
00:02:56.650 --> 00:03:02.130
UPS and Walmart examples were just two out
of a number of companies using big data.

35
00:03:03.380 --> 00:03:07.760
Big data is producing results for
companies in all sectors.

36
00:03:09.670 --> 00:03:14.370
Studies forecast spending on
big data technologies to go up

37
00:03:14.370 --> 00:03:16.630
drastically in the next five years.

38
00:03:18.320 --> 00:03:25.280
A study by Bane and Company
suggests that early adopters of big

39
00:03:25.280 --> 00:03:30.650
data analytics have gained a significant
lead over the rest of the corporate world.

40
00:03:32.620 --> 00:03:34.430
For graphics referenced here,

41
00:03:35.450 --> 00:03:40.700
we see that companies that use
analytics are twice as likely

42
00:03:40.700 --> 00:03:45.160
to be in the top quartile of financial
performance within their industries.

43
00:03:46.330 --> 00:03:51.368
Five times as likely to make decisions
much faster than market peers.

44
00:03:52.440 --> 00:03:56.180
Three times as likely to
execute decisions as intended.

45
00:03:56.180 --> 00:04:02.880
And twice as likely to use data very
frequently when making decisions.

46
00:04:04.040 --> 00:04:06.610
This points to the growth and
demand of people and

47
00:04:06.610 --> 00:04:12.450
technology centered around or
specializing in big data applications.

48
00:04:12.450 --> 00:04:17.870
As a summary, organizations are gaining
significant benefit from integrating

49
00:04:17.870 --> 00:04:22.920
big data practices into their culture and
breaking their silos.

50
00:04:22.920 --> 00:04:28.080
Some major benefits to organizations are
operational efficiency, improved marketing

51
00:04:28.080 --> 00:04:32.630
outcomes, higher profits, and
improved customer satisfaction.
