hello in this segment I'm going to

introduce the task of the information

retrieval in including in particular

what's now the dominant form web search

the task of information retrieval can be

may be defined as follows that our goal

is finding material which is usually

documents of an unstructured nature

usually text that satisfies an

information need that's what the person

is looking for information on from

within large collections usually stored

on computers so there's lots of mentions

there are prototypical cases and other

kinds of information retrieval do exist

so there are things like music

information retrieval where there are

sounds not text documents but

effectively what we're going to talk

about here is the case where all of

those usually clauses hold there are

many scenarios for information retrieval

the one that people think I'll first

these days is almost invariably web

search but there are many others so

searching your email searching the

contents of your laptop computer finding

stuff in some company's knowledgebase

doing legal information retrieval to

find relevant cases for legal context or

something like that it's always been the

case that a large percentage of human

knowledge and information is stored in

the form of human language documents and

yet there's also for a long time being

something of a paradox there so this is

just a kind of a not quite real graph to

give a flavor of things don't really

believe the numbers on the left hand

side are exactly what they mean but what

we're showing is that in the mid-1990s

it was already the case that if you

looked at the volume of data that there

was some data that was in structured

forms by that I mean things like

relational databases and spreadsheets

but there was already vastly more data

in companies organizations and around

people's homes

there was an unstructured form in the

form of human language text however

despite that in the mid-1990s structured

data management or retrieval was a

developed field and

already large database companies we're

in the field of unstructured data

management there was very little there

are a few teeny little companies that

did various kinds of corporate document

retrieval and things like that that

situation just completely changed around

the turn of the millennium so if we look

today the situation is like this so the

data volumes have gotten larger on both

sides but in particular they've gotten

larger on the unstructured side the mess

of outpouring of blogs tweets forums and

all those other places that now store

massive amounts of information but

there's also then being a turnaround on

the corporate side so now we have huge

companies that are addressing the

problems of unstructured information

retrieval such as the major web search

giant's so let's start and just say a

little bit about what a the base what is

the basic framework of doing information

retrieval so we start off by assuming

that we've got a collection of documents

over which we're going to do retrieval

and then at the moment we're going to

assume that's just a static collection

later on we'll deal with when documents

get added to and deleted from that

collection and how we can go out and

find them in something like a web search

scenario then our goal is to retrieve

documents that are relevant to the users

information need and helps the user to

complete a task let me go through that

once more a little bit more slowly with

this picture so at the start what we

have is that the user has some tasks

that they want to perform let's take a

concrete example suppose what I want to

do is get rid of the mice that are in my

garage and I'm the kind of person that

doesn't really want to kill them with

poison so that's why you use the tasks

that I want to achieve and so to achieve

that task I feel that I need more

information and so this is the

information made I want to know about

getting rid of mice without killing them

this information need is the thing with

respect to which we assess in

information

retrieval system but we can't just take

someone's information need and stick it

straight into a computer so what we have

to do to be able to stick it into a

computer is to translate the information

need into something that goes into the

search box and so that's what's happened

here we now have a query and so here's

my attempt at a query how trap mice

alive so that's taken this information

need and I've made an attempt to realize

it as a particular query and so then

it's that query that goes into the

search engine which leads which then

interrogate sauer document collection

and leads to some results coming back

and that may be the end of the day that

sometimes if I'm not satisfied without

my information retrieval session is

working I might take the evidence I got

from there and go back and come up with

a better query so I might decide that

alive is a bad word and put in something

like without killing and see if that

works any better okay um what can go

wrong here well there are a couple of

stages of interpretation here so first

of all there was my initial task and I

made some decisions as to what kind of

information need I had um it could be

that I got something wrong there so I

could have misconception so maybe in

getting rid of mice the most important

issue is not whether or not I kill them

but whether I do it humanely but we're

not going to deal with that issue so

much while we're more interested in in

here is the translation between the

information need and the query and there

are lots of ways in which that can go

wrong in this formulation of the query

so I might choose the wrong words to

express the query I might make use of

query search operators like inverted

commas which might have a good or a bad

effect on how the query actually works

and so those the choices of my query

formulation which aren't altering my

information

need whatsoever that's important when we

talk about how to evaluate information

retrieval systems that's a topic we'll

say more about later but let me first

give you the first rough sense of this

because we'll need it for everything

that we do so whenever we make a query

to an information retrieval system we're

going to get some documents back and we

want to know whether the results are

good and the very basic way at which

we're going to see whether they are good

is as follows

we're going to think of two measures

which are complementary one of which is

precision so precision is the fraction

of the retrieved documents of the system

that are relevant to the users

information needs

so that's whether when you look at the

results it seems like one document in

ten is relevant to the information needs

you have or whether seven documents in

ten are that's assessing whether the mix

of stuff you're getting back has a lot

of it air results in it the cross

complimentary mixture measure is the one

of them recall recall is measuring how

much of the good information that's in

the document collection is the system is

succeeding and finding for you at the

fraction of relevant Doc's in the

collection that are retrieved well give

more precise definitions and

measurements for information retrieval

later and the one thing I want to

express right now is that for these

measures to make sense they have to be

evaluated with respect to the users

information need for certain kinds of

queries such as the ones we'll look at

in the following segments there are

documents that get returned

deterministic in terms of what query is

submitted so if we were just going to

evaluate what gets returned with respect

to the users query then we'd necessarily

say that the precision is a hundred

percent but that's not what we do what

we do is think about the users

information need and that the precision

of the results is assessed relative to

that so in particular if we just look

back for a moment if there's being a

miss formulation of the query by the

user or just they didn't come up with a

very good

query that will be seen as lower

lowering the precision of the return

results okay this is only the very

beginning of our looking at information

retrieval but I hope you've already got

a sense of how we think of the task of

information retrieval and roughly how we

can see whether a search engine is doing

a good or a bad job on it
