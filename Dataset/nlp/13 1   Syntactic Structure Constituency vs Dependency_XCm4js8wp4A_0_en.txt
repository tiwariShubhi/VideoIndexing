okay in this section of the course we're

going to start talking about how to pass

text using statistical models but before

doing that let me just introduce two

views of syntactic structure that we'll

explore in our parsing models so the

first view is what's called constituency

parsing and the idea of constituency

parsing is that what we do is that we

organize words into nested constituents

let me give you a bit of example of that

so we had long ago this sentence bed

raises interest rates and so we had the

parts of speech that we've seen before

that this is a proper noun and this is a

verb and this is these are both nouns in

the sense that's the correct parse but

then above that what we wanted to say is

these nouns go together to form a noun

phrase and then the verb and the noun

phrase go together to form a verb phrase

and everything goes together to form a

sentence and so these things up here

these are our constituents and so the

claim is that the part of the sentence

is also sometimes shown with square

brackets interest rates is a constituent

that it's a unit of the sentence now how

do we know what a constituent is well

that's a complex issue but here are some

of the ideas that we use so one big idea

is by looking at the words that stay

together and go together when phrases

move around because of various syntactic

constructions so in this example here

we've got these two and three words to

the children and about drugs and well

something that you'll notice is we can

actually swap them around into the

opposite order and that's fine John

talked about drugs to the children or

you could do other things with them so

for example maybe you could take this

one in front it

in certain discourse contexts you could

say to the children John talked about

drugs and so this is all evidence that

each of these groups of words is a

constituent on the other hand if you

randomly reorder the words of a sentence

normally you get something that just

doesn't work at all so here what I've

tried to do is take the word drugs from

the end here and thought maybe I can

just take it and stick it after tort but

that doesn't work at all so you can't

say John taught and this is down here

John talked drugs to the children about

and there are a lot of other tests and

other tests is this idea of phrasal

expansion and substitution so for the

phrase on the box you can make it a

bigger unit like right on top of the box

and you can make it a smaller unit like

there and in general you can apply these

substitutions in any place where the

phrase on the box can appear there are

lots of other syntactic tests tests that

people use for constituency really if

you want to learn a lot about this you

should take a linguistics course and

then you'll see this all in more detail

but I hope that's enough to give a rough

idea those were simple sentences this is

the kind of thing that happens when

you've got big real sentences so this

sentence is analyst said mr. strode AK

wants to resume a more influential role

in running the company and so the idea

of constituency structure or phrase

structure is that we have these units

again that are constituents so here's a

constituent a more influential role

here's another constituent which just is

the names distract and then here are

some different constituents down the

bottom so running the company is a

constituent but also this bigger in

running the company is also a

constituent so constituents nest

together and these are the kind of parse

trees that NLP people actually spend

their time dealing with and we'll talk

more about these but note just one

attribute of them is as well as actual

pronounced words they're postulating

these unpronounce units in them as well

called empty elements

so the straightforward way to model

phrase structure or constituency

structures just as a context-free

grammar which we assume you've seen

somewhere in computer science that is

just the idea that you've got these

rules that says a rewrites as BCD and if

you apply these and let's say we have B

goes to EF if you apply these you get

phrase structure rules where this is BCD

and then this goes through EF and that

gives you a constituency structure but

this these kind of rules you can write

for arbitrary symbols but if you

actually look at what happens in natural

languages there's always a lot more

structure and this is the idea that gets

called x-bar theory and what that says

is that in natural languages

by-and-large phrases are headed by

particular kinds of words which then

take modifies and dependence around them

so informally we call things a verb

phrase precisely because they have a

verb in the middle of them and we call

things a noun phrase precisely because

they have a noun that is the central

element of them so a noun phrase

something like the man in the corner

centrally has the noun man and then has

other modifiers sitting around it and so

although according to a context-free

grammar these are just arbitrary symbols

in practice we give them names that

reflect this hitted structure of phrase

structure and the same is true of other

categories as well like adjective

phrases and adverb phrases so they are a

large part of our category inventory we

do have other kinds of phrases so we

have sentences and various kinds of

invert and questioning sentences which

basically correspond to a subject noun

phrase and a verb phrase and then they

can appear in bigger complement clauses

these S bar and s bar Q which also have

something like a

at introducing the sentence and various

other miscellaneous stuff happens as

well again you can learn a lot more

about their mental linguistic syntax

class but this idea of headed phrase

structure is the connection between

phrase structure and the other big

approach to syntactic structure that I

want to show you and that's dependency

structure so in dependency structure the

idea is we directly show for the words

of a sentence which other words depend

on that is modify or our arguments of

them let's look at that with this

example the boy put put the tortoise on

the rug so the head of this whole

sentence is putting that that's a

central word of the sentence and that's

sometimes represented by having a

dependency arc coming in from the edge

pointing the whole the head of the whole

sentence ok so then put has two

arguments itself so it puts arguments

the boy I'll so it's it's got three

arguments itself the tortoise and on the

rack where where things are put so who

put what and then where okay and so then

at that point we then sort of say well

boy does it have any modifiers or

arguments its modifier is that tortoise

does it have any modifiers or arguments

it's modifiers da and then on as a

preposition takes a compliment so it's

argument is its complement the rug

whether the rug is the head and the

modifier rug is a DA and so this set of

arrows I've now drawn here is a

dependency analysis of this sentence and

this form of dependency analysis is the

other major syntactic representation

we'll use okay so I hope that's been

enough to give you some idea of the

representations we use for syntactic

structure and how the two main

representations connect to each other
