1
00:00:10,558 --> 00:00:21,329
Welcome to this course on A I, as we mentioned
let me first start, today with the syllabus

2
00:00:21,329 --> 00:00:25,549
that we are going to cover, and within the
little bit of this in the last class, towards

3
00:00:25,550 --> 00:00:29,300
the
end, and I am just repeating this for continuity.

4
00:00:29,300 --> 00:00:36,420
So, will spend, the first few weeks, not
two or three lectures, on the first part of

5
00:00:36,420 --> 00:00:43,429
the course, which is the history and philosophy
of A I. And we as we will see, goes back quite

6
00:00:43,429 --> 00:00:49,670
a bit in time, and this is qualitatively
going to be, very different from the rest

7
00:00:49,670 --> 00:00:53,210
of the course, which is going to be mostly
algorithms.

8
00:00:53,210 --> 00:00:57,789
And will start with the simplest algorithm
like, depth first search, breadth first search

9
00:00:57,789 --> 00:01:01,179
and
so on, move on to heuristic search, in which

10
00:01:01,179 --> 00:01:07,510
we look at how search can be guided,
towards the solution that we are trying to

11
00:01:07,510 --> 00:01:13,090
find, and we look at algorithm like hill
climbing, and tabu search, and ..We will find

12
00:01:13,090 --> 00:01:15,590
that even that is not
going to be good enough, so we will try some

13
00:01:15,590 --> 00:01:20,118
randomized approaches like simulated
annealing, genetic algorithms, and ant colony

14
00:01:20,118 --> 00:01:21,118
optimization.

15
00:01:21,118 --> 00:01:24,849
.These are basically optimization techniques,
but we will try to see them from the search

16
00:01:24,849 --> 00:01:33,299
perspective, when we will look at, very well
known algorithm called A star and it is

17
00:01:33,299 --> 00:01:40,030
variations, which we will see. Then as I mentioned
earlier that we will look at, something

18
00:01:40,031 --> 00:01:44,749
called goal trees or problem decomposition
that if you want to solve a problem, and you

19
00:01:44,748 --> 00:01:49,328
want to break it up into parts, and solve
each parts separately, that technique is called

20
00:01:49,328 --> 00:01:52,729
problem decomposition.
Let to an area called rule based systems which

21
00:01:52,730 --> 00:01:59,900
we will look at, will also do game
playing, may perhaps not as late as this,

22
00:01:59,900 --> 00:02:05,079
may be somewhere here. So that, I can give
you

23
00:02:05,078 --> 00:02:10,149
one assignment, to start off with which is
to implement the game playing program? And

24
00:02:10,149 --> 00:02:15,680
finally, depending on how much time we have
left, we should have, something on

25
00:02:15,680 --> 00:02:22,650
planning and constraint satisfaction, which
is kind of preview of the course that we offer

26
00:02:22,650 --> 00:02:25,730
next semester.
In which we will study this algorithm like

27
00:02:25,729 --> 00:02:29,848
alphabeta algorithm, minimax algorithm, and
a

28
00:02:29,848 --> 00:02:34,098
heuristic version called S S S star. And then
depending upon how much time we have

29
00:02:34,098 --> 00:02:38,719
will spend some time on, these two topics
planning and constraint satisfaction, in which

30
00:02:38,719 --> 00:02:44,979
we look at, general algorithms for planning.
And we will see, by planning essentially we

31
00:02:44,979 --> 00:02:50,699
mean finding a sequence of actions, which
does something useful for you, and we will

32
00:02:50,699 --> 00:02:56,009
also look at logic and inferences. Because
it is not that we are just solving problems,

33
00:02:56,009 --> 00:02:58,669
of
how to do things, but we also making inferences,

34
00:02:58,669 --> 00:03:00,909
that if we know something, then we
know something else.

35
00:03:00,909 --> 00:03:06,829
So, that is a process of making inferences,
and the language that we use for

36
00:03:06,829 --> 00:03:11,939
representation is logic, and we will spend
some time that. So, these two topics are

37
00:03:11,938 --> 00:03:16,769
actually covered independently, and completely
in two different courses that we offer

38
00:03:16,769 --> 00:03:20,510
next semester. One is called planning and
constraint satisfaction, and the other one

39
00:03:20,509 --> 00:03:21,699
is
called knowledge representation reasoning,

40
00:03:21,699 --> 00:03:25,488
which is not the title we are using here.

41
00:03:25,489 --> 00:03:26,489
..

42
00:03:26,489 --> 00:03:32,128
So, the text book that we will follow is,
the book which I have just published, it is

43
00:03:32,128 --> 00:03:36,289
just
about come out and, there are some text books

44
00:03:36,289 --> 00:03:41,078
in A I which have been, very popular and,
earlier I was using a lot of a material from

45
00:03:41,079 --> 00:03:50,329
here. So, rich and knight book on A I, Russell
and Norvig, which is probably the most, well

46
00:03:50,329 --> 00:03:52,960
known text book at this point of time, and
a

47
00:03:52,960 --> 00:03:58,769
book by Winston which was written earlier.
Then there are certain specialized books,

48
00:03:58,769 --> 00:04:05,188
so these two books by Fogel and Michalewicz
is on certain aspects that we will cover,

49
00:04:05,188 --> 00:04:08,989
and this book by Judea pearl is something
we

50
00:04:08,989 --> 00:04:13,390
will use while game playing essentially. And
these two books which I will just mention

51
00:04:13,389 --> 00:04:18,639
again, deal with the history and the philosophy
part of A I essentially.

52
00:04:18,639 --> 00:04:19,639
..

53
00:04:19,639 --> 00:04:22,860
So, these two books that I mentioned, and
this is going to be the subject matter of

54
00:04:22,860 --> 00:04:27,410
the
first few lectures, the historical and the

55
00:04:27,410 --> 00:04:30,781
philosophical perspectives to A I. And you
can

56
00:04:30,781 --> 00:04:36,668
see that, is a topic, because we use this
word intelligence here, and that is something

57
00:04:36,668 --> 00:04:43,289
which has concerned people over a lot of time
essentially. And we want to see, what has

58
00:04:43,290 --> 00:04:49,660
been the thought, behind what is A I essentially.
So, these two books are, and I would

59
00:04:49,660 --> 00:04:59,330
recommend that you, read at least portions
of this, there is the book called A I the

60
00:04:59,329 --> 00:05:00,859
very
idea.

61
00:05:00,860 --> 00:05:08,270
And we will discuss shortly, why this book
is different from the rest, John Haugeland

62
00:05:08,269 --> 00:05:10,279
is
a philosopher by profession, not computer

63
00:05:10,279 --> 00:05:15,179
scientist, and he is looking at the
philosophical side of things that, one of

64
00:05:15,180 --> 00:05:17,269
the key questions we will ask. And today we
will

65
00:05:17,269 --> 00:05:23,930
start doing that is, can machines think, I
wanted to start already thinking about this

66
00:05:23,930 --> 00:05:29,168
question. And today we should discuss some
of these basic concepts, what is intelligence

67
00:05:29,168 --> 00:05:38,089
for example, and Haugeland looks into the
philosophy behind this, Pamela McCorduck is

68
00:05:38,089 --> 00:05:45,918
also from the social sciences, and she wrote
this book quite, long time ago, actually 1974

69
00:05:45,918 --> 00:05:51,019
or something like that.
And I hope you will notice that the title

70
00:05:51,019 --> 00:05:59,918
is, if nothing else at least a little provocative,
because she uses the pronoun, who for machines.

71
00:05:59,918 --> 00:06:05,098
So, she has machines who think, and
who is something that we normally, use for

72
00:06:05,098 --> 00:06:09,370
peoples essentially, human beings and so on
and so forth. So, she is talking about machines,

73
00:06:09,370 --> 00:06:11,939
who think not machines which think for

74
00:06:11,939 --> 00:06:18,199
.example, and therefore, already there is
a suggestion, that her own intimations is

75
00:06:18,199 --> 00:06:20,120
to
believe that, yes it is possible that machines

76
00:06:20,120 --> 00:06:23,220
can think.
And these two books, we will follow in the

77
00:06:23,220 --> 00:06:27,330
slides that I have prepared, are mostly from
these two books and a little bit from Wikipedia,

78
00:06:27,329 --> 00:06:32,318
so I will give you all those sources, from
the rest of the course I will not use slides

79
00:06:32,319 --> 00:06:34,009
very much, I we will just discuss things on
the

80
00:06:34,009 --> 00:06:39,829
board essentially. So, I want today’s class
to be little bit interactive, well not just

81
00:06:39,829 --> 00:06:43,469
today’s
class, but today’s class will be more interactive.

82
00:06:43,470 --> 00:06:48,720
And I wanted to start thinking about
question of what is intelligence, and we will

83
00:06:48,720 --> 00:06:53,220
discuss that, but before we do that, let us
just look at, what are the classical definitions

84
00:06:53,220 --> 00:06:57,780
that people have given, for this field of
artificial intelligence.

85
00:06:57,779 --> 00:06:58,779
.

86
00:06:58,779 --> 00:07:03,869
So, let us see first, what Herbert Simon has
to say, Herbert Simon was one of the

87
00:07:03,870 --> 00:07:14,418
founding persons in this area of A I, starting
in the 1950s, he and his collaborator Allen

88
00:07:14,418 --> 00:07:22,800
Newell, they founded the school at Carnegie
Mellon university. And we will see, their

89
00:07:22,800 --> 00:07:30,620
contribution as we go along, Simon also one
of the few people, who works in A I, whose

90
00:07:30,620 --> 00:07:35,810
got a Nobel prize. As you know, we do not
get Nobel prize in computer science, but

91
00:07:35,810 --> 00:07:43,069
Simon got one for economics, and he was the
multifaceted person, he did many things,

92
00:07:43,069 --> 00:07:50,750
as people used to be earlier.
So, his definition is we call programs intelligent,

93
00:07:50,750 --> 00:07:55,870
if they exhibit behaviors that would be
regarded intelligent, if they were done by

94
00:07:55,870 --> 00:07:58,720
human beings. So, this is the most common

95
00:07:58,720 --> 00:08:05,590
.definition of A I that people use, that it
is concerned with lighting programs or making

96
00:08:05,589 --> 00:08:13,560
machines do things, which should be considered
intelligent by, if they were done by

97
00:08:13,560 --> 00:08:17,949
human beings essentially. So, what are the
first things that A I people got into was,

98
00:08:17,949 --> 00:08:22,480
things like chess playing essentially, because
chess playing was always considered to be

99
00:08:22,480 --> 00:08:26,259
a hallmark of intelligent behaviors essentially.
It is only the bright, and the intelligent

100
00:08:26,259 --> 00:08:32,939
people who could play good chess.
.

101
00:08:32,940 --> 00:08:38,640
There is a long story of chess playing, the
first programs were written in 1950’s, one

102
00:08:38,639 --> 00:08:43,069
of
the first outline of the game was given by

103
00:08:43,070 --> 00:08:51,640
pone Neumann in the 60’s grand master called
David levy, I do not know whether I have it

104
00:08:51,639 --> 00:09:03,149
in my history, but may be it will come later.
So, let us write it here, around 1968 also,

105
00:09:03,149 --> 00:09:10,588
he wagered the bet that to chess program,
cannot beat him for the next ten years. Because,

106
00:09:10,589 --> 00:09:15,450
chess was considered to be something
which is very intellectual in nature, well

107
00:09:15,450 --> 00:09:21,970
luckily for him, he won his bet, which is
because it ended in 1978.

108
00:09:21,970 --> 00:09:29,360
But, many of you would know that, in the mid
90s, late 90s the then world champion

109
00:09:29,360 --> 00:09:36,680
Garry Kasparov was beaten by chess playing
program essentially. Chess in fact, it is

110
00:09:36,679 --> 00:09:40,578
not
so, intellectual in the sense that we tend

111
00:09:40,578 --> 00:09:48,189
to, talk about you know, philosophical sense.
Yes, it requires lot of computing machinery,

112
00:09:48,190 --> 00:09:52,820
and we will see that, if you have a lot of
computing machinery, you can play good chess.

113
00:09:52,820 --> 00:09:53,820
..

114
00:09:53,820 --> 00:10:03,920
Let us look at another old definition; this
is by Barr and Feigenbaum, also two old timers

115
00:10:03,919 --> 00:10:10,708
in A I, so his frictions says that, physicist
ask what kind of place is universe is, and

116
00:10:10,708 --> 00:10:13,419
seek
to characterize the behavior systematically.

117
00:10:13,419 --> 00:10:20,419
Biologists ask, what it means to be a physical
system to be living, and he says we in A I

118
00:10:20,419 --> 00:10:24,990
wonder, what kind of information processing
system can ask this such questions essentially.

119
00:10:24,990 --> 00:10:29,700
So, in other words, he asking about,
talking about intelligence, that physicists

120
00:10:29,700 --> 00:10:33,820
are asking questions about the physical world,
biologists are asking questions about the

121
00:10:33,820 --> 00:10:39,420
living creatures, what kind of information
processing system, could ask such questions.

122
00:10:39,419 --> 00:10:43,240
So, essentially saying what kind of system
would be intelligent, in that sense of the

123
00:10:43,240 --> 00:10:47,200
world
essentially, when Elaine Rich as I mentioned

124
00:10:47,200 --> 00:10:52,879
one of the popular books in A I, she wrote
one in eighty three or something or eighty

125
00:10:52,879 --> 00:11:02,750
six. And she gives a computer science flavor
to the definition; she says that, A I is the

126
00:11:02,750 --> 00:11:07,230
study of techniques for solving exponentially
hard problems in polynomial time essentially,

127
00:11:07,230 --> 00:11:11,139
by exploiting knowledge, about the
problem domain.

128
00:11:11,139 --> 00:11:15,850
Of course, those of you, who are diehard theory
people, would immediately object,

129
00:11:15,850 --> 00:11:20,360
saying that you cannot solve a hard problem
in polynomial time, because by definition,

130
00:11:20,360 --> 00:11:24,050
it
is a hard problem. But there are two counters

131
00:11:24,049 --> 00:11:31,189
to this, one is that, we may not necessarily,
be looking for solving them in polynomial

132
00:11:31,190 --> 00:11:37,120
time in the worst case. In certain situations
like, we will see travelling salesman problem,

133
00:11:37,120 --> 00:11:38,549
is one of the hardest problems, that people

134
00:11:38,549 --> 00:11:44,689
.have encountered. But given some constraints
on the problem, of how the edges are

135
00:11:44,690 --> 00:11:51,270
connected, what are the weights on the edges,
you can have much faster solutions.

136
00:11:51,269 --> 00:11:56,720
The second counter to this, objection that
you cannot sign, that you cannot solve

137
00:11:56,720 --> 00:12:02,509
problems in polynomial time is that we are
not seeking to find optimal solutions. And

138
00:12:02,509 --> 00:12:11,778
this is something, which many, many people
have observed, that human beings are not

139
00:12:11,778 --> 00:12:17,629
optimizers, we do not necessarily find, what
solutions? The solution that we considered

140
00:12:17,629 --> 00:12:23,278
to be optimal, we are what some people called
as satisfiers, satisfiers essentially, which

141
00:12:23,278 --> 00:12:27,019
says, that you are happy with the good solutions
essentially, you does not have to be

142
00:12:27,019 --> 00:12:32,200
optimal essentially.
So, just an example, with sort of strikes

143
00:12:32,200 --> 00:12:36,860
me once in a while, living in Chennai, that
if you

144
00:12:36,860 --> 00:12:41,879
have walking along one of the roads in I I
T, may be one thing that you want to optimize

145
00:12:41,879 --> 00:12:47,720
on, the amount of shade that you walk through,
but we do not have such dense ((Refer

146
00:12:47,720 --> 00:12:51,350
Time.) at everywhere there is shades, so you
have to choose a path essentially.

147
00:12:51,350 --> 00:12:56,839
And even if, one is conscious of the fact,
that one wants to walk through shade and with

148
00:12:56,839 --> 00:13:00,899
one does not mind walking a little bit longer.
So that, our objective function is to

149
00:13:00,899 --> 00:13:06,458
maximize shade, and not worry too much about
the length of our path, even then, we do

150
00:13:06,458 --> 00:13:11,099
not go into zigzag path that we would, if
we want to really follow the shade essentially.

151
00:13:11,100 --> 00:13:15,551
So, we do not optimize in that sense, even
when you want to be away from the sun, you

152
00:13:15,551 --> 00:13:21,570
are happy that if the path that we are following,
as enough lot of shade, not necessarily

153
00:13:21,570 --> 00:13:26,570
the maximum amount of shade essentially. So,
in that sense we do not solve, hard

154
00:13:26,570 --> 00:13:31,370
problems completely, we do not find optimal
solutions, but we tend to find good

155
00:13:31,370 --> 00:13:37,669
solutions essentially, and that is what we
do all the time. We go shopping; you do not,

156
00:13:37,669 --> 00:13:42,620
check in ten places then find the minimal
cost price, and then buy your product. Even

157
00:13:42,620 --> 00:13:45,970
though on the web nowadays you can do that
sort of a thing, but in general if you think

158
00:13:45,970 --> 00:13:52,320
that the price is reasonable, we go and buy
this stuff essentially.

159
00:13:52,320 --> 00:13:56,300
And one more definition, which is due to Charniak
and McDermott, who also wrote a

160
00:13:56,299 --> 00:14:02,809
very famous book, on A I very popular book
which, I use for part of my session, I do

161
00:14:02,809 --> 00:14:04,379
not
think I mentioned it may be I should added

162
00:14:04,379 --> 00:14:12,338
to the list there. They talk about A I, being
the study of mental faculties, through the

163
00:14:12,339 --> 00:14:18,649
use of computational models. So, we had said
earlier that, there are two approaches to

164
00:14:18,649 --> 00:14:23,708
A I, one is the cognitive approach which says,
which I, we are trying to understand intelligence.

165
00:14:23,708 --> 00:14:28,539
.And the other is the engineering approach
which says that, we want to build smart

166
00:14:28,539 --> 00:14:34,279
systems or smart apps if you want to say nowadays
essentially. So, what this definitions

167
00:14:34,279 --> 00:14:39,549
says is that, we want to study mental faculties,
and to do that we will be computational

168
00:14:39,549 --> 00:14:49,109
model, and use them for the studies actually,
where definition, which I like most, before

169
00:14:49,110 --> 00:14:52,528
I
come to that, look at these definitions. They

170
00:14:52,528 --> 00:14:58,070
are saying, if a human being does this, then
it is intelligent, and we want to sort of

171
00:14:58,070 --> 00:15:00,310
do something similar, so we want to mimic
human

172
00:15:00,309 --> 00:15:01,309
intelligence.
.

173
00:15:01,309 --> 00:15:05,809
So, the definition which I like most is come
from not a computer scientist, but from a

174
00:15:05,809 --> 00:15:13,268
philosopher, that we mentioned John Haugeland
in the book A I, the very idea. He says,

175
00:15:13,269 --> 00:15:18,310
that the fundamental goal of A I, is not merely
to mimic intelligence or produce some

176
00:15:18,309 --> 00:15:24,799
cleaver fake of intelligence, he says that
not the goal at all. A I wants the genuine

177
00:15:24,799 --> 00:15:28,259
article,
machines with minds, of their own in the full

178
00:15:28,259 --> 00:15:32,059
and the literal sense. Now, it is a very
interesting question, and we would debate

179
00:15:32,059 --> 00:15:34,539
it today a little bit, in the class, as to
what we

180
00:15:34,539 --> 00:15:39,139
mean by intelligence and can machine have
machines have it.

181
00:15:39,139 --> 00:15:43,310
And then you goes on to say, and all this
is in this book here, that this is not science

182
00:15:43,309 --> 00:15:49,489
friction, but real science based on the theoretical
conception, as deep and daring, namely

183
00:15:49,490 --> 00:15:55,009
that we are at the root computers ourselves,
essentially. So, if you are at the root,

184
00:15:55,009 --> 00:15:59,570
computers ourselves, which means if you are
at the root machines ourselves, then to

185
00:15:59,570 --> 00:16:02,959
answer the questions can machine think has
been . solve essentially,

186
00:16:02,958 --> 00:16:09,119
.because yes, human beings can think and therefore,
machines can think essentially. But

187
00:16:09,120 --> 00:16:13,649
the idea that we want to pursue, is that the
idea that thinking and computing are radically

188
00:16:13,649 --> 00:16:20,629
the same, is idea in his book, which is A
I the very idea, it is very interesting book.

189
00:16:20,629 --> 00:16:25,939
And for those of you of philosophically inclined,
should go and have look at it, and this

190
00:16:25,940 --> 00:16:30,730
idea, that thinking and computing are kind
of tied up together, goes back much before

191
00:16:30,730 --> 00:16:37,409
Haugeland. And we will see, either in today’s
class or in the next class, that the British

192
00:16:37,409 --> 00:16:42,230
philosophers Thomas Hobbes, was one of the
first person through, put forward this idea.

193
00:16:42,230 --> 00:16:46,480
Hobbes of course, was not a computer scientist,
in those days, there was no computer

194
00:16:46,480 --> 00:16:51,139
science, he was a political scientist, and
this kind of stuff.

195
00:16:51,139 --> 00:16:52,139
.

196
00:16:52,139 --> 00:16:59,490
So, let us, get to the fundamental questions,
and this is the part that, I want you to,

197
00:16:59,490 --> 00:17:04,940
give
answers to or what do you think about this

198
00:17:04,940 --> 00:17:08,789
question? So, I have not written any answers
for this. I have just written the questions,

199
00:17:08,789 --> 00:17:11,379
and I will write the answers on the board
as an

200
00:17:11,380 --> 00:17:16,860
when, they come out from, the class essentially.
So, the question you want to ask is, what

201
00:17:16,859 --> 00:17:21,099
is intelligence? I mean if there is going
to be ever a debate about whether machines

202
00:17:21,099 --> 00:17:23,329
can
be intelligent or not machines can think on

203
00:17:23,329 --> 00:17:25,679
are, first we should be clear is to, what
do we

204
00:17:25,680 --> 00:17:31,529
mean by intelligent, I mean if I write a program
is, let say the singular value

205
00:17:31,529 --> 00:17:38,160
decomposition of a matrix, would that is a
program intelligent, well I do not know.

206
00:17:38,160 --> 00:17:46,690
So, can I have some responses from the class,
what is intelligence, what is let us forget

207
00:17:46,690 --> 00:17:54,019
about what is thinking? Let us say, because
thinking is this thing, but when is, when

208
00:17:54,019 --> 00:18:01,859
.would something be call intelligent, what
is intelligence, what would you require in

209
00:18:01,859 --> 00:18:14,259
a
system or in agent, for you to call it intelligent,

210
00:18:14,259 --> 00:18:17,559
what are the fundamental characteristic
of intelligent behavior?

211
00:18:17,559 --> 00:18:22,230
. Ability to take decisions.
.

212
00:18:22,230 --> 00:18:39,049
That is very generic, yes definitely a part
of intelligence, but may be if you could expand

213
00:18:39,049 --> 00:18:43,750
on that, from a little bit. Example is you
know you have a small program, which says

214
00:18:43,750 --> 00:18:45,589
if
something, then something else, it is also

215
00:18:45,589 --> 00:18:48,019
doing taking some decision, by looking at
some

216
00:18:48,019 --> 00:18:50,359
data; obviously, you are looking at something
and taking a decision.

217
00:18:50,359 --> 00:19:00,079
. Use of knowledge to respond to new situations.
Use of knowledge of course, you will have

218
00:19:00,079 --> 00:19:16,859
to tell me, what do you mean by knowledge.
And this definition has a little bit of inconsistency,

219
00:19:16,859 --> 00:19:24,539
built into it, in the sense that, most of
the time when you use knowledge or experience,

220
00:19:24,539 --> 00:19:29,059
exploit experience we use them in
situations, which are similar, which are not

221
00:19:29,059 --> 00:19:35,190
entirely new in that sense. Well if by new
situation, you mean a new problem, then one

222
00:19:35,190 --> 00:19:38,750
has to ask the question, what do you mean
by that essentially? You know there is the

223
00:19:38,750 --> 00:19:45,099
. saying which says that,
you can never step into the same river twice,

224
00:19:45,099 --> 00:19:49,740
essentially, that is never the same thing.
But of course, nevertheless I will, I am not

225
00:19:49,740 --> 00:19:54,299
disputing, what you are saying, I am just
trying to get people to respond more, we do

226
00:19:54,299 --> 00:19:57,009
as human beings, you make extensive use of

227
00:19:57,009 --> 00:20:03,829
.knowledge, and we spend close to, what should
I say, twenty two years, twenty five

228
00:20:03,829 --> 00:20:07,919
years, acquiring knowledge . will later use,
essentially in our lives

229
00:20:07,920 --> 00:20:12,210
essentially. Human being, humans have a very
different kind of a species I think, I mean

230
00:20:12,210 --> 00:20:16,910
we are the only species, which has schools
up to twelfth standard, and then college four

231
00:20:16,910 --> 00:20:21,561
years after that and then, masters and may
be you know p h d in some cases. No other

232
00:20:21,560 --> 00:20:24,289
species spend so much time, acquiring knowledge
essentially.

233
00:20:24,289 --> 00:20:25,289
. Sir, we able to make inductive inferences,
and something which others senses

234
00:20:25,289 --> 00:20:37,769
just follow from your input, but to be able
to make some new.

235
00:20:37,769 --> 00:20:38,769
Ok
Assumptions

236
00:20:38,769 --> 00:20:53,190
So, I will just use a term inductive inferences
or in other words to generalize, ability to

237
00:20:53,190 --> 00:21:01,670
generalize. So, you go to the some hotel and
you ate masala dosa, and you are happy,

238
00:21:01,670 --> 00:21:05,289
you come back. Next time you go there, and
you have something else, let us say

239
00:21:05,289 --> 00:21:09,289
oottapam and you come back, and then you generalize,
that this hotel, gives you good

240
00:21:09,289 --> 00:21:13,539
food or you might say that, you know, south
Indian food is very good.

241
00:21:13,539 --> 00:21:19,840
These kind of inferences that we come to,
is making inductive inferences, you we look

242
00:21:19,840 --> 00:21:22,889
at
a few instances of something, and then from

243
00:21:22,890 --> 00:21:27,280
where, we generalize, that you know, it
holds for a certain class of things essentially.

244
00:21:27,279 --> 00:21:34,490
I see, a few leaves, and all of them are
green, then I conclude that all leaves are

245
00:21:34,490 --> 00:21:37,390
green essentially, which of course, does not
true

246
00:21:37,390 --> 00:21:43,150
at least not all the time, may be in Chennai
yes, when they, when we have leaves, but not

247
00:21:43,150 --> 00:21:51,430
in the rest of the world.
. Basically, spending that definition applicable,

248
00:21:51,430 --> 00:22:03,120
generalize and classify.
Classify would come in this making decisions,

249
00:22:03,119 --> 00:22:06,869
what else have is that all that we do as
human beings, is that all we lay our claim

250
00:22:06,869 --> 00:22:11,409
to for being intelligent.
. Choosing the best available of .

251
00:22:11,410 --> 00:22:23,769
Well when that comes here, choosing best options.
. Ability to learn.

252
00:22:23,769 --> 00:22:40,960
.Ability to learn yes, which is a little bit
difference from here, and we can say by learn

253
00:22:40,960 --> 00:22:50,660
we
mean acquire knowledge, one can learn from

254
00:22:50,660 --> 00:22:59,680
once own experience, you do to something
with gives a little bit of a pain. So, maybe

255
00:22:59,680 --> 00:23:05,230
you touch a hot stove or something like that,
two, three times, and then you learn, that

256
00:23:05,230 --> 00:23:08,150
is again inductive inferences essentially,
but to

257
00:23:08,150 --> 00:23:11,610
learn all kinds of things to learn facts.
.

258
00:23:11,609 --> 00:23:27,369
To learn relations between things, is something
that, we do quite effectively. So, what do

259
00:23:27,369 --> 00:23:34,309
you mean by this? Communication.
. not

260
00:23:34,309 --> 00:23:44,589
So, but there is a more fundamental thing,
to I mean, expressing well something,

261
00:23:44,589 --> 00:23:49,740
incidentally is something which is a feedback,
we get from all the companies which

262
00:23:49,740 --> 00:23:53,079
come to higher people here. Let us say that
our students are not good at communications

263
00:23:53,079 --> 00:23:57,509
essentially, but that is not the idea, even
that is not about your talking about I think,

264
00:23:57,509 --> 00:24:00,359
the
very fact that we can, communicate something.

265
00:24:00,359 --> 00:24:04,840
So, let me go to the fundamental thing,
what does this lie on, something which if

266
00:24:04,840 --> 00:24:10,909
is specific to the human species.
. speech

267
00:24:10,910 --> 00:24:28,240
Speech, the speech, before speech use of language,
language is something which is

268
00:24:28,240 --> 00:24:32,960
unique to; at least we think it is unique
to our species. There are doubts that you

269
00:24:32,960 --> 00:24:35,519
know
may be, whales communicate over long distances,

270
00:24:35,519 --> 00:24:37,480
and dolphins can communicate, and

271
00:24:37,480 --> 00:24:42,460
.that cannot stop, but we are not quite sure.
And we do see that, there are other creatures

272
00:24:42,460 --> 00:24:49,130
which make sounds, which are; obviously, aimed
or directed at least towards their own

273
00:24:49,130 --> 00:24:53,400
species, but it is not clear to us, what they
are proving actually.

274
00:24:53,400 --> 00:25:09,670
So, it is a use of language, which us enabled
us to carry forward knowledge. So, if you

275
00:25:09,670 --> 00:25:15,860
have a brilliant scientist like Newton, whose
thinking about the universe, and the world

276
00:25:15,859 --> 00:25:20,309
around him, and coming to conclusions, and
arriving at some understanding of how the

277
00:25:20,309 --> 00:25:30,819
world operates, the fruit of his effort is
available to us, and it is available to us,

278
00:25:30,819 --> 00:25:33,220
only
through the medium of language essentially.

279
00:25:33,220 --> 00:25:42,670
Because, we can talk to other people,
because we can write books, so printing of

280
00:25:42,670 --> 00:25:48,800
course, was another invention which help this
process, but this simply be able to communicate,

281
00:25:48,799 --> 00:25:53,329
to tell stories, this whole idea ((Refer
Time.)

282
00:25:53,329 --> 00:25:58,539
You know that is stories are passed on from
one person to the next, like all the stories

283
00:25:58,539 --> 00:26:04,020
that we hear in our subcontinent, the Ramayan
the Mahabharat and so on, where sort of

284
00:26:04,020 --> 00:26:11,240
overly conveyed from generation to generation.
And all that is possible, entirely through

285
00:26:11,240 --> 00:26:20,549
the use of language, it is language, which
has allowed us, to hold down to whatever

286
00:26:20,549 --> 00:26:26,909
knowledge we get from, our interactions with
the world, and pass it on to other people

287
00:26:26,910 --> 00:26:39,621
essentially, anything else, can one think
of. So, will take this, as part of thing,

288
00:26:39,621 --> 00:26:42,740
and then
we will see, whether machines can be intelligent.

289
00:26:42,740 --> 00:26:43,740
.

290
00:26:43,740 --> 00:26:49,279
.So, let me move on, a little bit and ask
the next question, this is not the very complicated

291
00:26:49,279 --> 00:26:53,319
question; I just want to be sure that we are
all on the same page, because I need talk

292
00:26:53,319 --> 00:26:56,619
of
machines thinking and so on. So, what do you

293
00:26:56,619 --> 00:27:03,839
mean by a machine, otherwise we will be
stuck with trying to answer a question, that

294
00:27:03,839 --> 00:27:08,750
can machines think, without knowing what
we mean by thinking, and without knowing what

295
00:27:08,750 --> 00:27:12,259
exactly we mean by machines
essentially. So, both these terms we should

296
00:27:12,259 --> 00:27:14,990
know, that is what do we mean by that
essentially.

297
00:27:14,990 --> 00:27:20,630
. Why which does a particular task repeated.
A device which does the particular task repeatedly.

298
00:27:20,630 --> 00:27:26,260
. However.
I am not going to write this here, is that

299
00:27:26,259 --> 00:27:35,879
complete enough definition of a machine.
. Device that has reduces human effort.

300
00:27:35,880 --> 00:27:42,570
A device that reduces human effort, what about
an exercising machine? Treadmill or

301
00:27:42,569 --> 00:27:44,159
something.
. Computations

302
00:27:44,160 --> 00:27:49,390
Something that there is computation, but computation
is only, one kind of activity that

303
00:27:49,390 --> 00:27:57,509
we consider, we have a machine which grains
coffee beans for you, I do not know that is

304
00:27:57,509 --> 00:28:05,230
doing computation. Now more fundamentally,
when will I call something a machine that

305
00:28:05,230 --> 00:28:18,400
is what I mean by the questions essentially?
So, if it is not a machine, what can it be?

306
00:28:18,400 --> 00:28:30,090
. It follows the cable instructions; you instructed
and do the work for you. Does

307
00:28:30,089 --> 00:28:32,038
not think on it is own.
He says, does not think on it is own says

308
00:28:32,038 --> 00:28:34,539
. get the answer to the
question that can machines think. So, machines

309
00:28:34,539 --> 00:28:39,649
are thinks, which cannot think on their
own. Now, this bit about following instructions,

310
00:28:39,650 --> 00:28:47,220
I do not know, I mean there are, of
course at some stage, in the life of the machine,

311
00:28:47,220 --> 00:28:51,829
there are instructions given to a machine.
So, but if I have a air conditional like in

312
00:28:51,829 --> 00:28:54,429
this room or thermostats somewhere, it is
not

313
00:28:54,430 --> 00:28:55,750
really following instructions.

314
00:28:55,750 --> 00:29:00,170
.But . some coding or something.
Yes some that is what I say, that some stages

315
00:29:00,170 --> 00:29:02,660
it is life, some instructions were given to
it,

316
00:29:02,660 --> 00:29:07,090
but then I can say the same thing about you
as a person, that you are following

317
00:29:07,089 --> 00:29:10,569
instructions, your parents said go and attend
lectures, do not bunk classes, that is why

318
00:29:10,569 --> 00:29:19,349
you are sitting here in this class . more
fundamentally, what is this,

319
00:29:19,349 --> 00:29:20,699
when would I call something on machine.
.

320
00:29:20,700 --> 00:29:37,740
So, let me give a circular definition, something
which acts mechanically; of course, as

321
00:29:37,740 --> 00:29:40,519
. it is a circular definition, that is using
the term machine and

322
00:29:40,519 --> 00:29:45,070
mechanical, they are related to each other.
So, it is not really a good definition in

323
00:29:45,070 --> 00:29:47,740
that
sense, but it gives us an idea, what I am

324
00:29:47,740 --> 00:29:50,170
trying to convey essentially. Because, we
can

325
00:29:50,170 --> 00:29:56,789
express this more easily, when do you say
that something is acting mechanically, and

326
00:29:56,789 --> 00:30:01,690
I
do not want the answer that without thinking,

327
00:30:01,690 --> 00:30:04,600
because thinking is a something, which
happens at a different level all together

328
00:30:04,599 --> 00:30:10,189
as we will see.
Basically in a well-defined manner, according

329
00:30:10,190 --> 00:30:18,590
to certain rules, let us say laws of physics,
if it is a physical machine or some other

330
00:30:18,589 --> 00:30:24,399
mathematical laws, if it is some computing
machine, something which operates, according

331
00:30:24,400 --> 00:30:35,500
to fixed set of rules. So, the question that
one ask is, and will come to that in a moment,

332
00:30:35,500 --> 00:30:42,349
so this is the question which has raised.
So, just to be cleared is a computer a machine,

333
00:30:42,349 --> 00:30:46,669
it does operate according to some very
well defined laws and so on.

334
00:30:46,670 --> 00:30:52,160
.Of course, a computer is a, very special
kind of a machine, it is a very flexible kind

335
00:30:52,160 --> 00:30:55,860
of a
machine, which says, so this whole idea store

336
00:30:55,859 --> 00:31:03,459
program, which we discovered? It is
discovered, not quite discovered, but at least,

337
00:31:03,460 --> 00:31:07,220
brought forward by Charles Babbage which
says that, you can have a same machine, and

338
00:31:07,220 --> 00:31:10,990
you can put in a different program. And it
will do something different for you essentially,

339
00:31:10,990 --> 00:31:14,710
make it a very flexible machine, but
nevertheless, it is the machine, because at

340
00:31:14,710 --> 00:31:18,870
the base, there is something which is very
repetitive which is going on.

341
00:31:18,869 --> 00:31:23,190
And whenever we say, machine in the rest of
this course, basically we will mean a

342
00:31:23,191 --> 00:31:27,890
program in computer. So, when we say, can
a machine think; then it means can we

343
00:31:27,890 --> 00:31:32,480
program a computer, so that it appears to
be thinking or is thinking, as this. So, this

344
00:31:32,480 --> 00:31:38,019
is a
question that is fundamental in the sense,

345
00:31:38,019 --> 00:31:43,910
there was a edging debate as we will see some
arguments against thinking, in the next slide.

346
00:31:43,910 --> 00:31:48,470
In the last fifty years, sixty years people
have been talking about, whether machines

347
00:31:48,470 --> 00:31:57,140
can think or not.
So, what does, so does anyone here, have a

348
00:31:57,140 --> 00:32:01,870
strong opinion either side. So, when I say,
by

349
00:32:01,869 --> 00:32:05,789
this time, I mean a computer program, can
I program a computers, so it is a thinking

350
00:32:05,789 --> 00:32:17,009
machine, is that possible at all. And we try
to find some aspects of what we call

351
00:32:17,009 --> 00:32:22,049
intelligent behavior or is there something
missing that we have not mentioned here, we

352
00:32:22,049 --> 00:32:29,509
forgot to mention here, which the computer
cannot do, can never do, is there something

353
00:32:29,509 --> 00:32:38,299
like the halting problem . situation here.
So, does anyone have a

354
00:32:38,299 --> 00:32:42,329
opinion either ways, there is anyone strongly
feel that yes machines can think, there is

355
00:32:42,329 --> 00:32:47,569
nothing fundamentally against it or there
anyone have a opinion which says, no machines

356
00:32:47,569 --> 00:32:51,179
cannot think, only we human beings can think
essentially.

357
00:32:51,180 --> 00:32:58,240
. . did not tell what is thinking?
Well, I that is the first question I started

358
00:32:58,240 --> 00:33:00,599
asking you will. So, we wrote all this stuff
by

359
00:33:00,599 --> 00:33:03,939
saying that if you are using this.
. intelligence.

360
00:33:03,940 --> 00:33:10,140
So, we sort of say that they are closely correlated,
thinking is the process how to of

361
00:33:10,140 --> 00:33:23,810
which intelligence arises, we might say. So,
no one has the strong opinion I take it

362
00:33:23,809 --> 00:33:31,899
essentially. So, that is fine, there is nothing
either ways, and finally, as Haugeland said,

363
00:33:31,900 --> 00:33:36,450
I
mean, I that the and to what Haugeland thinks

364
00:33:36,450 --> 00:33:38,640
about this question, that are we machines

365
00:33:38,640 --> 00:33:45,259
.is already here, in his answers essentially,
he thinks that we are machines. But, is anyone

366
00:33:45,259 --> 00:33:52,069
here, who feels that strongly about this,
that yes we are machines or no we are not

367
00:33:52,069 --> 00:34:04,369
machines, we are flesh and blood creatures
of carbon, we are not made of silicon, any

368
00:34:04,369 --> 00:34:09,358
strong views.
So, supposing I would to say, let us try and

369
00:34:09,358 --> 00:34:13,059
put forward the idea that we are machines,
what is the argument that you would give,

370
00:34:13,059 --> 00:34:15,659
to say that yes, we are also machines. So,
one

371
00:34:15,659 --> 00:34:22,389
of the fundamental objections, the people
ask, there is that, you know machines versus

372
00:34:22,389 --> 00:34:31,260
whatever it is, which is called as free will.
So, when I asked you little while ago as to

373
00:34:31,260 --> 00:34:37,830
what would be, if you were not a machine,
then the answer that some people give is that,

374
00:34:37,829 --> 00:34:44,480
you have a own free will. So, in some sense,
a machine does not have it any free will

375
00:34:44,480 --> 00:34:49,860
essentially, a machine operates according
to fix set of instructions, and fix set of

376
00:34:49,860 --> 00:34:53,599
laws,
and always obeys those instructions and laws

377
00:34:53,599 --> 00:34:58,019
essentially.
Whereas, free will, which you do not understand,

378
00:34:58,019 --> 00:35:01,630
we do not know whether we have free
will or not, I mean people claim that human

379
00:35:01,630 --> 00:35:07,300
beings have free will, but they all go and
vote for some congress and b j p all the time

380
00:35:07,300 --> 00:35:13,500
essentially. So, but anyway, what is this
thing called free will, basically says that

381
00:35:13,500 --> 00:35:21,139
we make choices, that we have, the ones who
decide, how our lives will be, how what we

382
00:35:21,139 --> 00:35:26,319
will do in the next instant, and thinks like
that. You know, your open philosophy is like

383
00:35:26,320 --> 00:35:33,140
existentialism dealt quite a bit, in the post
what period, about this notion of free will,

384
00:35:33,139 --> 00:35:38,190
and you know making choices think ((Refer
Time.)

385
00:35:38,190 --> 00:35:43,309
So, if you want machines, then we would not
have something called free will; or is that

386
00:35:43,309 --> 00:35:49,480
a
contradiction; or if we are machines do we

387
00:35:49,480 --> 00:35:59,190
like, some of the Indian thought says, that
everything is free decided, like this say,

388
00:35:59,190 --> 00:36:05,030
whatever have to happen will happen essentially.
Of course, then we are all machines, and then,

389
00:36:05,030 --> 00:36:10,840
there is no second thought about it, but if
I

390
00:36:10,840 --> 00:36:15,360
want to sort of deconstruct say, we are machines,
because of this reason, I could sort of

391
00:36:15,360 --> 00:36:29,130
give you an argument, which says that. We
grow out of a single cell, to start with

392
00:36:29,130 --> 00:36:35,809
instructions written in our genetic code,
about how to will our bodies, what color to

393
00:36:35,809 --> 00:36:39,269
of
eyes to have, all kind of things.

394
00:36:39,269 --> 00:36:48,460
And then essentially, we build ourselves using
this thing and therefore, we become

395
00:36:48,460 --> 00:36:54,130
human beings and, just like computers are
flexible, and they can do different things,

396
00:36:54,130 --> 00:36:56,210
at
different times. We also flexible, may be

397
00:36:56,210 --> 00:36:58,159
a little bit more than the current day computers,

398
00:36:58,159 --> 00:37:03,480
.but we are in the end, we are machines essentially
or I could give you an argument which

399
00:37:03,480 --> 00:37:09,750
says that, see our brain is made up of a,
ten to hundred billion neurons, all of them

400
00:37:09,750 --> 00:37:13,789
operate in by a very simple mechanical procedure.
So, our brains are mechanical in

401
00:37:13,789 --> 00:37:19,199
nature, and therefore, since a brains control
us we are mechanical in nature, I could give

402
00:37:19,199 --> 00:37:22,989
argument like this. So, what will you say
against it, I mean if you were to say anything

403
00:37:22,989 --> 00:37:28,189
against it.
. We have something called emotion that is

404
00:37:28,190 --> 00:37:29,570
not in machines.
We have something called emotion that is not

405
00:37:29,570 --> 00:37:33,160
in machine essentially.
. We are biased to our emotion.

406
00:37:33,159 --> 00:37:36,960
But how do you know, it is not in the machine.
. Suppose, I turnoff my computer.

407
00:37:36,960 --> 00:37:43,349
Suppose you are system patches, can we say
it is angry with you, I mean it may not

408
00:37:43,349 --> 00:37:49,699
display it in other ways I think, no more
seriously, why should we say that, machines

409
00:37:49,699 --> 00:38:06,609
cannot have emotions. So, I will pointed to
a book, it is called the emotion machine,

410
00:38:06,610 --> 00:38:13,539
and
it is written by a guy called Marvin Minsky,

411
00:38:13,539 --> 00:38:18,980
was also one of the founders of A I. As we
will see the history of A I, as we go along,

412
00:38:18,980 --> 00:38:27,469
he founded the m i t A I lab, along with John
McCarthy, and he has it is in the last five,

413
00:38:27,469 --> 00:38:33,799
six years odd, he is written this book called,
the emotion machine essentially.

414
00:38:33,800 --> 00:38:38,769
So, it actually goes . again the slightly
longer divide as so what do

415
00:38:38,769 --> 00:38:43,829
you mean by emotion and so on and so forth.
I could try to characterize emotion by

416
00:38:43,829 --> 00:38:48,840
saying that, you have memories, and then you
have some value, labels attached to

417
00:38:48,840 --> 00:38:53,380
memories, that some memories are good; some
memories are bad. And then you have

418
00:38:53,380 --> 00:38:57,050
states, which are attached to those value
labels, so you are happy or you are sad. So,

419
00:38:57,050 --> 00:38:59,100
one
could talk about things like that, but is

420
00:38:59,099 --> 00:39:03,889
it something, which is exclusive to us, I
do not

421
00:39:03,889 --> 00:39:12,118
know, and do creatures like dogs and cats
have emotions.

422
00:39:12,119 --> 00:39:13,329
. Yes

423
00:39:13,329 --> 00:39:19,279
.They have, but are they also intelligent
or that is another question, is intelligence

424
00:39:19,280 --> 00:39:23,750
the
prerogative of human beings, only or do we

425
00:39:23,750 --> 00:39:29,170
allow dogs and cats, and deer and monkey,
to be intelligent or not.

426
00:39:29,170 --> 00:39:35,450
. Yes
But, if you go down this, ladder of life,

427
00:39:35,449 --> 00:39:37,600
so to speak, then you have dogs and cats,
then

428
00:39:37,601 --> 00:39:42,400
you have mosquitoes somewhere here, then you
have bacteria, then you have virus. So,

429
00:39:42,400 --> 00:39:55,269
at which point, you stop essentially. We will
we are not here to answer this question, we

430
00:39:55,269 --> 00:39:59,791
are here to keep in mind, that these questions
have been asked by many people, and this

431
00:39:59,791 --> 00:40:04,500
is not the goal, our goal to you know, it
is not a course on philosophy, but still we

432
00:40:04,500 --> 00:40:10,559
should
be aware of it. So, here small cartoon I got

433
00:40:10,559 --> 00:40:15,190
from, so our, if we were machines yes then,
I

434
00:40:15,190 --> 00:40:21,460
suppose our admiration would be mutual happy
or if you want to call as admiration.

435
00:40:21,460 --> 00:40:22,460
.

436
00:40:22,460 --> 00:40:30,090
So, let me give you some arguments, which
are well known in literature, which claim

437
00:40:30,090 --> 00:40:35,880
that machines can, the question we asking
is, can the machine think, can machine think.

438
00:40:35,880 --> 00:40:42,630
So, what are the objections, the first . guy
call Herbert Dreyfus says

439
00:40:42,630 --> 00:40:47,760
that, intelligence depends upon unconscious
instincts, that can never be captured in

440
00:40:47,760 --> 00:40:57,320
formal rules essentially. So, you cannot read
this, I did not know how to make this a bit

441
00:40:57,320 --> 00:41:05,870
stronger, darker, whether basically a Wikipedia
page, which is critiques of A I,

442
00:41:05,869 --> 00:41:06,969
essentially.

443
00:41:06,969 --> 00:41:14,669
.Dreyfus spent, he has made a carrier out
of saying that A I is not possible essentially.

444
00:41:14,670 --> 00:41:18,389
So,
at least he is made a carrier out of it, what

445
00:41:18,389 --> 00:41:26,269
you think about these unconscious instincts
that can never be captured in formal rules.

446
00:41:26,269 --> 00:41:33,610
So, this is one of the arguments which people
say these kinds of arguments which say that

447
00:41:33,610 --> 00:41:37,160
we often do not know what we are doing?
Why we are doing something? I did this, but

448
00:41:37,159 --> 00:41:44,549
I did not know why I did this, but does this
say that, I was doing something really mysterious,

449
00:41:44,550 --> 00:41:53,500
which I cannot reproduce in a
machine. Let us together argument by philosopher

450
00:41:53,500 --> 00:41:58,500
John Searle, it is called the Chinese
room argument, he says can an agent locked

451
00:41:58,500 --> 00:42:03,449
in a room processing questions in Chinese,
based on a set of syntactic rules, be said

452
00:42:03,449 --> 00:42:06,179
to understand Chinese. So, is an, it is a
thought

453
00:42:06,179 --> 00:42:12,219
experiment which John Searle proposes, it
is a very famous argument, just lookup the

454
00:42:12,219 --> 00:42:16,519
Chinese, whom argument on the web, when you
will get all these descriptions.

455
00:42:16,519 --> 00:42:26,000
So, the idea is that, supposing you as a English
speaking person; or whatever Hindi; or

456
00:42:26,000 --> 00:42:31,929
Tamil speaking person, you all locked up in
the room. And you are full of these slips

457
00:42:31,929 --> 00:42:35,549
of
paper, which have these syntactic rules, which

458
00:42:35,550 --> 00:42:40,400
says if you see this pattern, then send out
this response, if you see this pattern, then

459
00:42:40,400 --> 00:42:46,119
send out this response. You do not know, what
that thing is about, you see some patterns,

460
00:42:46,119 --> 00:42:49,670
and you have an instructed, to loop match
a

461
00:42:49,670 --> 00:42:54,450
pattern, and send out a response based on
that. And you are there somebody; from

462
00:42:54,449 --> 00:43:00,730
outside below the door slipping, sending you
slip of paper, with some patterns, then you

463
00:43:00,730 --> 00:43:05,019
make some other patterns on slips of paper,
and send them back essentially.

464
00:43:05,019 --> 00:43:11,599
You do not know, what is happening? What it
turns out apparently at the end of this, is

465
00:43:11,599 --> 00:43:15,579
that somebody is asking questions in Chinese,
and you are giving them answers in

466
00:43:15,579 --> 00:43:20,739
Chinese. So, John Searle says, and this is
the Chinese room experiment, thought

467
00:43:20,739 --> 00:43:26,599
experiment, says that supposing this were
to happen, would you say that, the person

468
00:43:26,599 --> 00:43:32,789
whose answering you, those Chinese. And he
says no, because the way that experiment

469
00:43:32,789 --> 00:43:38,409
has been described, and he says that therefore,
but his behavior looks like intelligent

470
00:43:38,409 --> 00:43:42,480
behavior, because he is giving you all the
answers, but he said really intelligence,

471
00:43:42,480 --> 00:43:43,670
he says
no essentially.

472
00:43:43,670 --> 00:43:50,530
And of course, there is a little bit of an
operational trap there, which is what I written

473
00:43:50,530 --> 00:43:54,360
here, how many rules will an agent need to
have, for the thought experiment to be

474
00:43:54,360 --> 00:44:02,280
convincing essentially. And we will see this
idea, again in a different form, as we go

475
00:44:02,280 --> 00:44:08,140
along, one more objection from the celebrated
mathematical physicist John Roger

476
00:44:08,139 --> 00:44:16,009
Penrose, you must have heard about him, those
who have Nobel laureate, he wrote this

477
00:44:16,010 --> 00:44:22,570
.book with, which became quite a hit essentially,
it was called the emperors you mind

478
00:44:22,570 --> 00:44:23,570
essentially.
.

479
00:44:23,570 --> 00:44:48,360
If you write the name, you know, so parading
the emperor’s new clothes, and he is also

480
00:44:48,360 --> 00:44:56,420
asking this question about, can one we can
machines think or not, his answer is that,

481
00:44:56,420 --> 00:44:58,260
no
machines cannot think. We are the only thinking

482
00:44:58,260 --> 00:45:03,600
creatures, and he says that there
something happening in our brains, which current

483
00:45:03,599 --> 00:45:07,019
day physics cannot understand, cannot
explain essentially. And that is something

484
00:45:07,019 --> 00:45:09,940
he says respective quantum mechanical, if
you

485
00:45:09,940 --> 00:45:13,700
want to go into the details, you should look
up the web, and read his book essentially,

486
00:45:13,699 --> 00:45:18,000
which is not so easy to read.
But still, he wrote a later book, I forgot

487
00:45:18,000 --> 00:45:21,300
it is name, which is the shorter version of
this

488
00:45:21,300 --> 00:45:28,480
book. So, that is another argument, then there
are arguments like, he mentioned emotion,

489
00:45:28,480 --> 00:45:36,599
intuition, consciousness, ethics. So, some
people say, it would not be ethical to have

490
00:45:36,599 --> 00:45:44,130
intelligent machines, so they cannot be intelligent.
Now, this is kind of round about

491
00:45:44,130 --> 00:45:50,430
argument which says, it would be bad for,
I do not know who, so we cannot have

492
00:45:50,429 --> 00:45:58,389
intelligent machines essentially. Of course,
we are very ethical people, and we go around

493
00:45:58,389 --> 00:46:05,190
suspending twenty eight year old IAS officers,
because of some small residues that we

494
00:46:05,190 --> 00:46:06,318
have against them.

495
00:46:06,318 --> 00:46:07,318
..

496
00:46:07,318 --> 00:46:14,989
So, there are many arguments, which a co ordination
and they have been many counters

497
00:46:14,989 --> 00:46:22,319
to the argument which I have not talked about,
because he wants to get on, to what

498
00:46:22,320 --> 00:46:33,250
Turing said. So, you all know Alan Turing,
he was very instrumental in tracking codes,

499
00:46:33,250 --> 00:46:44,000
during world war, this thing, what he says,
that he would have been one hundred and one

500
00:46:44,000 --> 00:46:52,340
years old. If he were alive today, what he
says last year was his birth centenary and

501
00:46:52,340 --> 00:46:55,320
lots
of things were going on, he says that the

502
00:46:55,320 --> 00:46:56,671
question whether machines can think is just
a

503
00:46:56,670 --> 00:47:00,019
meaningless question.
Because we are not able to, even describe

504
00:47:00,019 --> 00:47:02,559
with we made an attempt here, to say what
is

505
00:47:02,559 --> 00:47:07,000
thinking, but it not very clear to say, what
is thinking I mean I keep ((Refer Time:

506
00:47:07,000 --> 00:47:12,219
47:07)) and thinks like that are of course,
meaningless essentially. As his I guess g

507
00:47:12,219 --> 00:47:20,819
e and
certain essentially, what he did, was that,

508
00:47:20,820 --> 00:47:23,730
let us not get into this raising debate of,
can a

509
00:47:23,730 --> 00:47:29,000
machine think or not. He says I will give
you a test, which is called as a imitation

510
00:47:29,000 --> 00:47:32,340
game,
which we will see in the next slide, which

511
00:47:32,340 --> 00:47:41,240
is now known as the turing test, then nothing
to do with turing machines, of this he says,

512
00:47:41,239 --> 00:47:44,139
about this turing test, we will see in a
moment.

513
00:47:44,139 --> 00:47:45,139
..

514
00:47:45,139 --> 00:47:53,210
Let us first see the test, and then come back.
The turing test is like this, that there is

515
00:47:53,210 --> 00:47:57,590
a
human judge, in this something has happened

516
00:47:57,590 --> 00:48:02,289
to this anyway, there is a human judge
sitting on in those is a teletype, in current

517
00:48:02,289 --> 00:48:06,809
they were in may be on a mobile phone
chatting with someone. So, you are chatting

518
00:48:06,809 --> 00:48:11,099
with someone, you type in something, and
somebody else types backs something and so

519
00:48:11,099 --> 00:48:15,500
on and so forth. So, he imagines that
teletype, connected to a machine on the other

520
00:48:15,500 --> 00:48:18,650
side, but there is a wall in between, so you
do not know whether it is a machine or whether

521
00:48:18,650 --> 00:48:26,309
it is a human being essentially.
And what turing said, was that if he gave

522
00:48:26,309 --> 00:48:30,170
a figure like, seventy percent of the time,
the

523
00:48:30,170 --> 00:48:35,960
machine can fool the judge into thinking that
the judge is talking to a human being; then

524
00:48:35,960 --> 00:48:47,119
the machine is intelligent. We will come back
to, the test again, so what it turing feel,

525
00:48:47,119 --> 00:48:50,350
he
felt and this was in 1950, when he wrote this

526
00:48:50,349 --> 00:48:55,989
paper, called computer machinery and
intelligent, it is available on the web, if

527
00:48:55,989 --> 00:48:57,849
you go to many places, you will just get the
paper

528
00:48:57,849 --> 00:49:03,089
directly. He says that in about fifty years
of time, which is 2000 in year, 2000 will

529
00:49:03,090 --> 00:49:05,190
be
possible to program computers with a storage

530
00:49:05,190 --> 00:49:10,829
capacity of 10 is to 9, so 10 is to 9 was
considered to be a big number, and histories

531
00:49:10,829 --> 00:49:19,769
repeat with these kind of example.
Bill gates apparently had one said that, who

532
00:49:19,769 --> 00:49:26,989
on earth will need the memory more than
sixty four k essentially. So, he said that,

533
00:49:26,989 --> 00:49:31,599
with the capacity of 10 is to 9 to make them,
play the imitation game, the game that we

534
00:49:31,599 --> 00:49:35,739
do describe. So well, that an average
interrogator, will not have more than 70 percent

535
00:49:35,739 --> 00:49:36,979
chance of making the right

536
00:49:36,980 --> 00:49:41,420
.identification, after five minutes of questioning.
And many says, that I believe that the

537
00:49:41,420 --> 00:49:46,960
end of the century, which is at the end of
fifty years, use of words and general educated

538
00:49:46,960 --> 00:49:51,360
opinion will be altered so much, that one
will be able to speak of machines thinking

539
00:49:51,360 --> 00:49:57,480
without expecting, to be contradicted.
Very difficult to make predictions, in these

540
00:49:57,480 --> 00:50:00,860
kind of matters, David levy said that, he
no

541
00:50:00,860 --> 00:50:06,070
machine can beat him, Alan Turing says that,
all machine the machines will ((Refer

542
00:50:06,070 --> 00:50:11,880
Time.) pass turing test, both was wrong in
the sense, that we still cannot say that,

543
00:50:11,880 --> 00:50:16,019
you know, we have machines which pass turing
test. So, currently there is something

544
00:50:16,019 --> 00:50:21,809
called a Loebner prize, which has been instituted
by Agricola Loebner as a name

545
00:50:21,809 --> 00:50:28,099
suggest, it is an annual competition, where
they are judged by for human like response.

546
00:50:28,099 --> 00:50:34,150
So, it is not as here fooling something, but
for human like response, and there is a grand

547
00:50:34,150 --> 00:50:39,930
prize of 100000 dollars, in case who interested
in some pocket money, I mean say it is

548
00:50:39,929 --> 00:50:46,618
still open essentially. So, there are two,
so there is a question which I want to, ask

549
00:50:46,619 --> 00:50:49,610
a few
week do not have too much time, will have

550
00:50:49,610 --> 00:50:53,250
to stop soon. And we will start with this
in

551
00:50:53,250 --> 00:50:58,039
the next class, is to what you think of the
turing test, as a test of intelligence remembers,

552
00:50:58,039 --> 00:51:03,059
now he himself said that do not talk about
thinking and all, but just accept this test.

553
00:51:03,059 --> 00:51:04,059
.

554
00:51:04,059 --> 00:51:10,130
Let me just show you, some examples of this
year’s competition, which I got from the

555
00:51:10,130 --> 00:51:14,329
web, so this year, there are four finalist,
who are going to compete on September 14,

556
00:51:14,329 --> 00:51:17,909
this
finalist have been selected based on some

557
00:51:17,909 --> 00:51:22,929
earlier rounds, and this is the transcript
from,

558
00:51:22,929 --> 00:51:31,339
.the leader of those four best one. So, let
me just read it out, so there is a judge and

559
00:51:31,340 --> 00:51:34,440
there
this program called izar. So, the judge says

560
00:51:34,440 --> 00:51:39,550
hello, I am Ronan, that is the name of the
judge, what is your name, the program response,

561
00:51:39,550 --> 00:51:45,100
I am just try to imagine, how would you
write a program, which would respond like

562
00:51:45,099 --> 00:51:47,179
this.
This is the output of this program, which

563
00:51:47,179 --> 00:51:50,210
is called izar, it is says Ronan, it is about
time

564
00:51:50,210 --> 00:51:55,101
you contacted me, I was waiting for you, my
name is izar, pronounced I zar, but you can

565
00:51:55,101 --> 00:52:01,130
call me izzy if you want, doing anything fun,
too much recursion in A I M l and so on

566
00:52:01,130 --> 00:52:06,329
and so forth. Judge says, at some later point
I have just not I have not given you the full

567
00:52:06,329 --> 00:52:12,469
essentially, I like bananas, which is your
favorite fruit. He says tell me more about,

568
00:52:12,469 --> 00:52:16,939
your
unknown, this is the trick, which the program

569
00:52:16,940 --> 00:52:22,409
is employing, to answer a question, which
is it cannot answer very easily, you are not

570
00:52:22,409 --> 00:52:24,480
only one. So, you have to build in this kind
of

571
00:52:24,480 --> 00:52:32,130
tricks, human being also do that, if you are
taking a viva about something, you know, I

572
00:52:32,130 --> 00:52:36,630
do not have a problem with banana, is that
your favorite fruit the obvious one and so

573
00:52:36,630 --> 00:52:39,539
on.
Then he says, I have been getting into hoomii,

574
00:52:39,539 --> 00:52:45,150
a type of mongolian throat singing. So,
you have to put in certain amounts of knowledge

575
00:52:45,150 --> 00:52:51,710
in your system, to be able to convince
the listen, so he is trying to impress.

576
00:52:51,710 --> 00:52:52,710
.

577
00:52:52,710 --> 00:52:58,869
So, let me leave you with a program which
was written in1960 or something, this

578
00:52:58,869 --> 00:53:03,589
program is called eliza, you must might have
heard about it, it was named after eliza

579
00:53:03,590 --> 00:53:10,460
Doolittle, who was a character in Bernard
Shaw’s play called Pygmalion, and we will

580
00:53:10,460 --> 00:53:18,369
.visit Pygmalion again later, it was a very
simple n l p program written, at m i t by

581
00:53:18,369 --> 00:53:26,039
weizenbaum in 1966. It use simple rules to
manipulate language, it would read what the

582
00:53:26,039 --> 00:53:29,259
users written, manipulated little bit, and
throw it back.

583
00:53:29,260 --> 00:53:34,540
So, it says, if you go and say for example,
somebody will say, so for example, if you

584
00:53:34,539 --> 00:53:39,130
want to say, I like bananas, if it simply
say, why do like bananas. So, it just twist

585
00:53:39,130 --> 00:53:41,769
that,
and send it back to you. And there popular

586
00:53:41,769 --> 00:53:47,119
version called doctor, which I am sure you
might have seen, it runs a script which makes

587
00:53:47,119 --> 00:53:49,409
it looks like psychotherapist essentially.
It

588
00:53:49,409 --> 00:53:53,299
of course, makes it easy to ask questions,
it can always one of the standard questions

589
00:53:53,300 --> 00:53:57,260
these program ask is, tell me more about your
family. You know, if they cannot say

590
00:53:57,260 --> 00:54:00,029
anything else, . tell you more about your
family, and as a human

591
00:54:00,030 --> 00:54:03,720
being, you would so this program is doing
some deep analysis, .

592
00:54:03,719 --> 00:54:11,439
So, here is the Russian scientist, who was
visiting Stanford, who was running a version

593
00:54:11,440 --> 00:54:25,309
of this, we just read this. So, I have colored
these things to show you that you know, it

594
00:54:25,309 --> 00:54:32,299
just twisting that sentence, in this thing.
So, these are, this is, so there was a scientist

595
00:54:32,300 --> 00:54:36,350
apparently, after this conversation he started
pouring out, all his words to this program

596
00:54:36,349 --> 00:54:43,389
and so on and so forth. And Weizenbaum found
that his secretary was all the time talking

597
00:54:43,389 --> 00:54:49,179
to this program, and apparently she was quite
furious, when she found out that

598
00:54:49,179 --> 00:54:51,919
Weizenbaum had access to those conversations
essentially.

599
00:54:51,920 --> 00:55:00,420
And nowadays of course, you know prism, and
everything, Weizenbaum actually found

600
00:55:00,420 --> 00:55:04,670
that peoples responses, words are disturbing
that he wrote a book, which says that no,

601
00:55:04,670 --> 00:55:07,329
no
computers cannot do all this kind of thing

602
00:55:07,329 --> 00:55:12,608
essentially. So, we are gullible, and I think
we

603
00:55:12,608 --> 00:55:19,730
will take it up, in the next class, with some
even older examples of how, we look at

604
00:55:19,730 --> 00:55:24,119
something, and we believe that it is doing
something in the intelligence for us essentially.

605
00:55:24,119 --> 00:55:28,600
Meanwhile I would like you to think about
this turing test, in the next class on

606
00:55:28,599 --> 00:55:57,000
Wednesday, we will start discussing, what
we think about the turing test essentially.

607
00:55:57,000 --> 00:56:07,000
.

