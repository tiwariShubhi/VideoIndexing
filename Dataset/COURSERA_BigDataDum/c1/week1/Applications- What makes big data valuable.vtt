WEBVTT

1
00:00:01.240 --> 00:00:04.508
Big data is now being
generated all around us.

2
00:00:04.508 --> 00:00:05.750
So what?

3
00:00:05.750 --> 00:00:07.450
It's the applications.

4
00:00:07.450 --> 00:00:12.170
It is the way in which big data can
serve human needs that makes it valued.

5
00:00:13.430 --> 00:00:17.971
Let's look at a few examples of the
applications big data is allowing us to

6
00:00:17.971 --> 00:00:19.226
imagine and build.

7
00:00:37.796 --> 00:00:43.420
Big data allows us to build better models,
which produce higher precision results.

8
00:00:44.470 --> 00:00:49.021
We are witnessing hugely innovative
approaches in how companies

9
00:00:49.021 --> 00:00:51.758
market themselves and sell products.

10
00:00:51.758 --> 00:00:53.958
How human resources are managed.

11
00:00:53.958 --> 00:00:56.178
How disasters are responded to.

12
00:00:56.178 --> 00:01:00.389
And many other applications that
evidenced based data is being

13
00:01:00.389 --> 00:01:02.460
used to influence decisions.

14
00:01:04.660 --> 00:01:06.670
What exactly does that mean?

15
00:01:06.670 --> 00:01:08.150
Here is one example.

16
00:01:08.150 --> 00:01:10.640
Many of you might have experienced it,
I do.

17
00:01:12.540 --> 00:01:16.140
Data, Amazon keeps some
things I've been looking at

18
00:01:16.140 --> 00:01:19.610
allows them to personalize
what they show me.

19
00:01:19.610 --> 00:01:24.300
Which hopefully helps narrow down
the huge raft of options I might get

20
00:01:24.300 --> 00:01:27.380
than just searching on dinner plates.

21
00:01:27.380 --> 00:01:32.307
Now, businesses can leverage technology
to make better informed decisions

22
00:01:32.307 --> 00:01:37.246
that are actually based on signals
generated by actual consumers, like me.

23
00:01:39.454 --> 00:01:43.980
Big data enables you to hear
the voice of each consumer as

24
00:01:43.980 --> 00:01:46.590
opposed to consumers at large.

25
00:01:47.920 --> 00:01:51.500
Now, many companies,
including Walmart and Target,

26
00:01:51.500 --> 00:01:57.160
use this information to personalize their
communications with their costumers, which

27
00:01:57.160 --> 00:02:01.240
in turns leads to better met consumer
expectations and happier customers.

28
00:02:03.550 --> 00:02:09.628
Which basically is to say, big data
has enabled personalized marketing.

29
00:02:09.628 --> 00:02:14.250
Consumers are copiously generating
publicly accessible data through

30
00:02:14.250 --> 00:02:16.560
social media sites,
like Twitter or Facebook.

31
00:02:17.690 --> 00:02:22.130
Through such data, the companies
are able to see their purchase history,

32
00:02:22.130 --> 00:02:26.970
what they searched for, what they watched,
where they have been, and

33
00:02:26.970 --> 00:02:29.650
what they're interested in
through their likes and shares.

34
00:02:30.920 --> 00:02:35.717
Let's look at some examples of how
companies are putting this information to

35
00:02:35.717 --> 00:02:39.868
build better marketing campaigns and
reach the right customers.

36
00:02:42.718 --> 00:02:46.985
One area we are all familiar with
are the recommendation engines.

37
00:02:46.985 --> 00:02:52.190
These engines leverage user patterns and
product features

38
00:02:52.190 --> 00:02:58.028
to predict best match product for
enriching the user experience.

39
00:02:58.028 --> 00:03:00.303
If you ever shopped on Amazon,

40
00:03:00.303 --> 00:03:04.596
you know you get recommendations
based on your purchase.

41
00:03:04.596 --> 00:03:07.861
Similarly, Netflix would
recommend you to watch

42
00:03:07.861 --> 00:03:10.590
new shows based on your viewing history.

43
00:03:12.610 --> 00:03:18.550
Another technique that companies use is
sentiment analysis, or in simple terms,

44
00:03:18.550 --> 00:03:22.550
analysis of the feelings around events and
products.

45
00:03:23.880 --> 00:03:27.900
Remember the blue plates I
purchased on Amazon.com?

46
00:03:27.900 --> 00:03:31.680
I not only can read the reviews
before purchasing them,

47
00:03:31.680 --> 00:03:35.460
I can also write a product
review once I receive my plates.

48
00:03:37.280 --> 00:03:40.500
This way, other customers can be informed.

49
00:03:41.880 --> 00:03:47.110
But more importantly, Amazon can keep
a watch on the product reviews and

50
00:03:47.110 --> 00:03:49.220
trends for a particular product.

51
00:03:49.220 --> 00:03:51.951
In this case, blue plates.

52
00:03:51.951 --> 00:03:58.300
For example, they can judge if a product
review is positive or negative.

53
00:03:59.940 --> 00:04:03.140
In this case,
while the first review is negative,

54
00:04:05.140 --> 00:04:07.530
the next two reviews are positive.

55
00:04:09.180 --> 00:04:13.130
Since these reviews are written in
English using a technique called natural

56
00:04:13.130 --> 00:04:16.780
language processing, and
other analytical methods,

57
00:04:16.780 --> 00:04:22.120
Amazon can analyze the general opinion of
a person or public about such a product.

58
00:04:24.130 --> 00:04:29.128
This is why sentiment analysis often
gets referred to as opinion mining.

59
00:04:31.298 --> 00:04:35.729
News channels are filled with
Twitter feed analysis every time

60
00:04:35.729 --> 00:04:39.420
an event of importance occurs,
such as elections.

61
00:04:40.810 --> 00:04:46.162
Brands utilize sentiment analysis
to understand how customers

62
00:04:46.162 --> 00:04:51.630
relate to their product,
positively, negatively, neutral.

63
00:04:51.630 --> 00:04:54.448
This depends heavily on use of
natural language processing.

64
00:04:57.183 --> 00:04:59.289
Mobile devices are ubiquitous and

65
00:04:59.289 --> 00:05:02.780
people almost always carry
their cellphones with them.

66
00:05:03.810 --> 00:05:07.200
Mobile advertising is a huge market for
businesses.

67
00:05:08.760 --> 00:05:13.581
Platforms utilize the sensors
in mobile devices,

68
00:05:13.581 --> 00:05:18.847
such as GPS, and
provide real time location based ads,

69
00:05:18.847 --> 00:05:23.456
offer discounts,
based on this deluge of data.

70
00:05:23.456 --> 00:05:28.063
This time, let's imagine that
I bought a new house and

71
00:05:28.063 --> 00:05:32.178
I happen to be in a few
miles range of a Home Depot.

72
00:05:32.178 --> 00:05:35.444
Sending me mobile coupons about paint,
shelves, and

73
00:05:35.444 --> 00:05:39.290
other new home related purchases
would remind me of Home Depot.

74
00:05:40.550 --> 00:05:43.590
There's a big chance I
would stop by Home Depot.

75
00:05:43.590 --> 00:05:44.790
Bingo!

76
00:05:44.790 --> 00:05:49.470
Now I would like to take a moment to
analyze what kinds of big data are needed

77
00:05:49.470 --> 00:05:50.270
to make this happen.

78
00:05:51.495 --> 00:05:55.990
There's definitely the integration
of my consumer information and

79
00:05:55.990 --> 00:06:00.710
the online and offline databases
that include my recent purchases.

80
00:06:00.710 --> 00:06:05.569
But more importantly,
the geolocation data that falls under

81
00:06:05.569 --> 00:06:09.128
a larger type of big data,
spacial big data.

82
00:06:09.128 --> 00:06:11.780
We will talk about spacial
data later in this class.

83
00:06:13.190 --> 00:06:17.770
Let's now talk about how the global
consumer behavior can be used for

84
00:06:17.770 --> 00:06:18.360
product growth.

85
00:06:20.170 --> 00:06:23.760
We are now moving from
personalize marketing

86
00:06:23.760 --> 00:06:26.230
to the consumer behavior as a whole.

87
00:06:27.920 --> 00:06:32.758
Every business wants to understand
their consumerâ€™s collective

88
00:06:32.758 --> 00:06:37.258
behavior in order to capture
the ever-changing landscape.

89
00:06:37.258 --> 00:06:42.809
Several big data products enable this
by developing models to capture user

90
00:06:42.809 --> 00:06:48.730
behavior and allow businesses to target
the right audience for their product.

91
00:06:50.340 --> 00:06:53.250
Or, develop new products for
uncharted territories.

92
00:06:55.570 --> 00:06:57.550
Let's look at this example.

93
00:06:57.550 --> 00:07:00.797
After an analysis of their sales for
weekdays,

94
00:07:00.797 --> 00:07:06.319
an airline company might notice that their
morning flights are always sold out,

95
00:07:06.319 --> 00:07:09.908
while their afternoon
flights run below capacity.

96
00:07:09.908 --> 00:07:15.545
This company might decide to add more
morning flights based on such analysis.

97
00:07:16.900 --> 00:07:21.550
Notice that they are not using
individual consumer choices, but

98
00:07:21.550 --> 00:07:26.760
using all the flights purchased without
consideration to who purchased them.

99
00:07:28.200 --> 00:07:29.150
They might, however,

100
00:07:29.150 --> 00:07:34.400
decide to pay closer attention to
the demographic of these consumers

101
00:07:34.400 --> 00:07:38.850
using big data to also add similar
flights in other geographical regions.

102
00:07:40.350 --> 00:07:45.240
With rapid advances in genome
sequencing technology,

103
00:07:45.240 --> 00:07:51.580
the life sciences industry is experiencing
an enormous draw in biomedical big data.

104
00:07:53.120 --> 00:07:59.168
This biomedical data is being used
by many applications in research and

105
00:07:59.168 --> 00:08:01.398
personalized medicine.

106
00:08:01.398 --> 00:08:06.400
Did you know genomics data is one of
the largest growing big data types?

107
00:08:06.400 --> 00:08:13.940
Between 100 million and 2 billion human
genomes could be sequenced by year 2025.

108
00:08:13.940 --> 00:08:14.520
Impressive.

109
00:08:16.700 --> 00:08:19.080
This [INAUDIBLE] sequence data demands for

110
00:08:19.080 --> 00:08:24.580
between 2 exabytes and
40 exabytes in data storage.

111
00:08:24.580 --> 00:08:30.190
In comparison, all of YouTube only
requires 1 to 2 exabytes a year.

112
00:08:32.530 --> 00:08:35.886
An exabyte is 10 to the power 18 bites.

113
00:08:35.886 --> 00:08:41.818
That is, 18 zeros after 40.

114
00:08:41.818 --> 00:08:48.270
Of course, analysis of such massive
volumes of sequence data is expensive.

115
00:08:48.270 --> 00:08:50.680
It could take up to 10,000
trillion CPU hours.

116
00:08:54.580 --> 00:08:59.040
One of the biomedical applications
that this much data is enabling

117
00:08:59.040 --> 00:09:00.450
is personalized medicine.

118
00:09:02.060 --> 00:09:06.879
Before personalized medicine,
most patients without a specific type and

119
00:09:06.879 --> 00:09:09.862
stage of cancer received
the same treatment,

120
00:09:09.862 --> 00:09:12.858
which worked better for
some than the others.

121
00:09:14.968 --> 00:09:20.086
Research in this area is enabling
development of methods to analyze

122
00:09:20.086 --> 00:09:25.472
large scale data to develop solutions
that tailor to each individual,

123
00:09:25.472 --> 00:09:28.900
and hence hypothesize
to be more effective.

124
00:09:30.450 --> 00:09:36.260
A person with cancer may now still receive
a treatment plan that is standard,

125
00:09:36.260 --> 00:09:38.620
such as surgery to remove a tumor.

126
00:09:39.870 --> 00:09:43.750
However, the doctor may
also be able to recommend

127
00:09:43.750 --> 00:09:45.460
some type of personalized
cancer treatment.

128
00:09:47.150 --> 00:09:51.900
A big challenge in biomedical big data
applications, like many other fields,

129
00:09:51.900 --> 00:09:56.860
is how we can integrate many types of data
sources to gain further insight problem.

130
00:09:58.300 --> 00:10:01.648
In one of our future lectures,
my colleagues here at

131
00:10:01.648 --> 00:10:06.670
the Supercomputer Center,
will explain how he and his colleague have

132
00:10:06.670 --> 00:10:11.940
used big data from a variety of sources
for personalized patient interventions.

133
00:10:13.840 --> 00:10:19.010
Another application of big data comes
from interconnected mesh of large

134
00:10:19.010 --> 00:10:24.490
number of sensors implanted
across smart cities.

135
00:10:24.490 --> 00:10:28.790
Analysis of data generated
from sensors in real time

136
00:10:28.790 --> 00:10:33.140
allows cities to deliver better
service quality to inhabitants.

137
00:10:33.140 --> 00:10:38.340
And reduce unwanted affect such
as pollution, traffic congestion,

138
00:10:38.340 --> 00:10:41.470
higher than optimal cost on
delivering urban services.

139
00:10:42.910 --> 00:10:44.750
Let's take our city, San Diego.

140
00:10:46.370 --> 00:10:51.794
San Diego generates a huge volumes
of data from many sources.

141
00:10:51.794 --> 00:10:57.676
Traffic sensors, satellites,
camera networks, and more.

142
00:10:57.676 --> 00:10:59.694
What if we could integrate and

143
00:10:59.694 --> 00:11:04.140
synthesize these data streams to
do even more for our community?

144
00:11:05.260 --> 00:11:07.000
Using such big data,

145
00:11:07.000 --> 00:11:12.170
we can work toward making San Diego
the prototype digital city.

146
00:11:12.170 --> 00:11:15.020
Not only for life-threatening hazards, but

147
00:11:15.020 --> 00:11:20.280
making our daily lives better, such as
managing traffic flow more efficiently or

148
00:11:20.280 --> 00:11:24.870
maximizing energy savings,
even as we'll see next, wildfires.

149
00:11:26.450 --> 00:11:31.390
If you want to read more,
here's a link to the AT Kearney report,

150
00:11:31.390 --> 00:11:34.120
where they talk about other
areas using big data.

151
00:11:35.580 --> 00:11:39.880
As a summary,
big data has a huge potential

152
00:11:39.880 --> 00:11:44.140
to enable models with higher
precision in many application areas.

153
00:11:45.230 --> 00:11:50.175
And these highly precise models
are influencing and transforming business.