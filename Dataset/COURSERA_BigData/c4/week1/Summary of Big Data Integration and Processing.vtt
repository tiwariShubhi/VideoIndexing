WEBVTT

1
00:00:00.910 --> 00:00:05.618
In this video, we will provide you with
a quick summary of the main points

2
00:00:05.618 --> 00:00:09.644
from our first three courses to
recall what you have learned.

3
00:00:09.644 --> 00:00:13.520
If you have just completed our third
course and do not need a refresher,

4
00:00:13.520 --> 00:00:15.470
you might skip to the next lecture.

5
00:00:18.140 --> 00:00:23.325
We started our first course explaining
how a new torrent of big data

6
00:00:23.325 --> 00:00:28.974
combined with cloud computing
capabilities to process data anytime and

7
00:00:28.974 --> 00:00:33.803
anywhere has been at the core of
the launch of the big data era.

8
00:00:33.803 --> 00:00:37.995
Such capabilities enable or
present opportunities for

9
00:00:37.995 --> 00:00:43.704
many dynamic data-driven applications,
including energy management,

10
00:00:43.704 --> 00:00:48.620
smart cities, precision medicine,
and smart manufacturing.

11
00:00:49.620 --> 00:00:54.163
These applications are increasingly
more data-driven, dynamic and

12
00:00:54.163 --> 00:00:58.470
heterogeneous in terms of
their technology needs.

13
00:00:58.470 --> 00:01:01.490
They're also more process-driven and

14
00:01:01.490 --> 00:01:06.130
need to be tackled using
a collaborative approach by a team that

15
00:01:06.130 --> 00:01:10.400
puts value on accountability and
reproducibility of the results.

16
00:01:11.840 --> 00:01:17.250
Overall, by modeling,
managing, integrating diverse

17
00:01:17.250 --> 00:01:22.260
data streams we add value
to our big data and

18
00:01:22.260 --> 00:01:26.030
improve our business even more
before we start analyzing it.

19
00:01:27.640 --> 00:01:29.080
A part of modeling and

20
00:01:29.080 --> 00:01:34.740
managing big data is focusing on
the dimensions of the scalability and

21
00:01:34.740 --> 00:01:39.080
considering the challenges associated with
these dimensions to pick the right tools.

22
00:01:40.990 --> 00:01:45.859
We also talked about characteristics
of big data, referring to some Vs

23
00:01:45.859 --> 00:01:51.360
like volume, variety, velocity,
veracity and valence.

24
00:01:52.500 --> 00:01:58.727
Each week presents a challenging
dimension of big data,

25
00:01:58.727 --> 00:02:06.010
namely size, complexity, speed,
quality and connectedness.

26
00:02:06.010 --> 00:02:08.530
We also added a sixth V,

27
00:02:08.530 --> 00:02:12.920
value, referring to the real reason
we are interested in big data.

28
00:02:14.550 --> 00:02:18.660
To turn it into an advantage in the
context of a problem using data science

29
00:02:18.660 --> 00:02:21.890
techniques, big data needs to be analyzed.

30
00:02:23.470 --> 00:02:30.530
We explained a five steps process for data
science that includes data acquisition,

31
00:02:30.530 --> 00:02:34.500
modeling, management,
integration, and analysis.

32
00:02:35.620 --> 00:02:38.370
The influence of big data pushes for

33
00:02:38.370 --> 00:02:42.710
alternative scalability approaches
at each step of the process.

34
00:02:44.820 --> 00:02:50.310
If we just focus on the scalability
challenges related to the three Vs,

35
00:02:50.310 --> 00:02:53.720
we can say big data has varying volume and

36
00:02:53.720 --> 00:02:59.020
velocity, requiring dynamic and
scalable batch and stream processing.

37
00:03:00.110 --> 00:03:05.715
Big data has variety, requiring management
of data in many different data systems,

38
00:03:05.715 --> 00:03:07.790
and integration of it at scale.

39
00:03:09.630 --> 00:03:12.470
In our introduction to
the big data course,

40
00:03:12.470 --> 00:03:16.590
we talked about the version of a layer
diagram for the tools in the Hadoop

41
00:03:16.590 --> 00:03:20.950
ecosystem, organized vertically
based on the interface.

42
00:03:22.520 --> 00:03:27.210
Low level interfaces for storage and
scheduling on the bottom

43
00:03:28.890 --> 00:03:32.610
and high level languages and
interactivity at the top.

44
00:03:33.820 --> 00:03:38.691
Most of the tools in the Hadoop ecosystem
were initially built to compliment

45
00:03:38.691 --> 00:03:43.880
the capabilities of Hadoop for distributed
file system management using HDFS.

46
00:03:45.060 --> 00:03:48.490
Data processing using
the MapReduce engine, and

47
00:03:48.490 --> 00:03:52.810
resource scheduling, and
negotiation using the YARN engine.

48
00:03:54.320 --> 00:03:57.580
Over time,
a number of new projects were built,

49
00:03:57.580 --> 00:04:03.010
either to add to these complementary
tools or to handle additional types of

50
00:04:03.010 --> 00:04:08.640
big data management and processing not
available in Hadoop, just like Spark.

51
00:04:10.260 --> 00:04:15.430
Arguably, the most important
change to Hadoop over time

52
00:04:15.430 --> 00:04:19.960
was the separation of YARN from
the MapReduce programming model

53
00:04:19.960 --> 00:04:22.590
to solely handle resource
management concerns.

54
00:04:24.060 --> 00:04:29.850
This allowed for Hadoop to be extensible
to different programming models and enable

55
00:04:29.850 --> 00:04:34.640
the development of a number of processing
engines for batch and stream processing.

56
00:04:36.140 --> 00:04:40.500
Another way to look at the vast number of
tools that have been added to the Hadoop

57
00:04:40.500 --> 00:04:44.420
ecosystem is from the point of
view of their functionality

58
00:04:44.420 --> 00:04:45.990
in the big data processing pipeline.

59
00:04:47.090 --> 00:04:52.680
Simply put, these are associated
with three distinct layers for

60
00:04:52.680 --> 00:04:57.660
data management and storage,
for data processing and

61
00:04:57.660 --> 00:05:00.780
for resource coordination and
workflow management.

62
00:05:02.360 --> 00:05:08.122
In our second course, we talked in detail
about the bottom layer in this diagram,

63
00:05:08.122 --> 00:05:10.810
namely data management and storage.

64
00:05:12.920 --> 00:05:18.890
While this layer includes Hadoop's HDFS,
there are a number of other systems

65
00:05:18.890 --> 00:05:25.680
that rely on HDFS as a file system or
implement their own no-SQL storage option.

66
00:05:25.680 --> 00:05:30.255
As big data can have a variety of
structured, semi-structured, and

67
00:05:30.255 --> 00:05:35.730
unstructured formats and
gets analyzed through a variety of tools,

68
00:05:35.730 --> 00:05:38.880
many tools were introduced to
fit this variety of needs.

69
00:05:40.210 --> 00:05:43.040
We call these big data management systems.

70
00:05:44.510 --> 00:05:48.690
We reviewed Redis and Aerospike as

71
00:05:48.690 --> 00:05:53.180
key value stores where each data item
is identified with a unique key.

72
00:05:55.670 --> 00:06:00.200
We also got some practical
experience with Lucene and

73
00:06:00.200 --> 00:06:04.842
Gephi as vector and
graph-stores respectively.

74
00:06:06.310 --> 00:06:10.660
We also talked about Vertica as
a column-store database where

75
00:06:10.660 --> 00:06:14.570
information is stored in
columns rather than rows.

76
00:06:16.660 --> 00:06:20.998
Cassandra and
HBase are also in this category.

77
00:06:20.998 --> 00:06:27.749
Finally, we introduced Solr and
Asterisk DB for managing unstructured and

78
00:06:27.749 --> 00:06:32.822
semi-structured text and
MongoDB as a document store.

79
00:06:35.591 --> 00:06:40.444
The processing layer is where
all these different types

80
00:06:40.444 --> 00:06:45.091
of data get retrieved,
integrated, and analyzed,

81
00:06:45.091 --> 00:06:49.343
which was the primary
focus of our third course.

82
00:06:49.343 --> 00:06:52.451
In the integration and processing layer,

83
00:06:52.451 --> 00:06:57.283
we roughly refer to the tools that
are built on top of HTFS and YARN,

84
00:06:57.283 --> 00:07:01.965
although some of them were with
other storage and file systems.

85
00:07:03.675 --> 00:07:10.064
YARN is a significant enable of many of
these tools making a number of batch and

86
00:07:10.064 --> 00:07:16.277
stream processing engines like Storm,
Spark, Flink and Beam possible.

87
00:07:16.277 --> 00:07:20.373
This layer also includes tools
like Hive and Spark SQL for

88
00:07:20.373 --> 00:07:24.894
bringing a query interface on top
of the storage layer, Pig for

89
00:07:24.894 --> 00:07:30.014
scripting simple big data pipelines
using the MapReduce framework and

90
00:07:30.014 --> 00:07:33.512
a number of specialized
analytical libraries,

91
00:07:33.512 --> 00:07:36.775
formation learning, and graph analytics.

92
00:07:36.775 --> 00:07:43.538
Giraph and GraphX of Spark are examples
of such libraries for graph processing.

93
00:07:43.538 --> 00:07:46.448
Mahout on top of the Hadoop stack and

94
00:07:46.448 --> 00:07:50.820
MLlib of Spark Are two options for
machine learning.

95
00:07:51.970 --> 00:07:55.665
Although we had a basic overview
of graph processing and

96
00:07:55.665 --> 00:07:59.991
machine learning for big data
analytics earlier in our second and

97
00:07:59.991 --> 00:08:03.860
third courses,
we haven't gone into the details there.

98
00:08:03.860 --> 00:08:09.576
In this course, we will use Spark's MLlib
as one of our two main tools,

99
00:08:09.576 --> 00:08:15.692
providing a deeper introduction to
the machine learning library of Spark.

100
00:08:15.692 --> 00:08:22.075
The third and top layer in our diagram is
the coordination and management layer.

101
00:08:22.075 --> 00:08:25.888
This is where integrations,
scheduling, coordination, and

102
00:08:25.888 --> 00:08:30.840
monitoring of applications across many
tools in the bottom two layers take place.

103
00:08:31.890 --> 00:08:36.940
This layer is also where the results of
the big data analysis get communicated

104
00:08:36.940 --> 00:08:42.030
to other programs, websites, visualization
tools and business intelligence tools.

105
00:08:43.740 --> 00:08:48.905
Workflow management systems help to
develop automated solutions that

106
00:08:48.905 --> 00:08:53.835
can manage and coordinate the process
of combining data management and

107
00:08:53.835 --> 00:09:00.165
analytical tasks in a big data pipeline as
a configurable, structured set of steps.

108
00:09:01.275 --> 00:09:04.275
Workflow driven thinking also matches

109
00:09:04.275 --> 00:09:08.810
this basic process of data science
that we overviewed before.

110
00:09:08.810 --> 00:09:12.510
Oozie is an example workflow
scheduler that can interact with

111
00:09:12.510 --> 00:09:15.620
many of the tools in the integration and
processing layer.

112
00:09:16.740 --> 00:09:21.364
Zookeeper is the resource
coordination tool which monitors and

113
00:09:21.364 --> 00:09:26.680
manages and coordinates all these
tools and named after animal.

114
00:09:28.510 --> 00:09:32.950
Now that we've reviewed all three
layers we are ready to come back to

115
00:09:32.950 --> 00:09:38.790
the integration and processing layer, but
now in the context of machine learning.

116
00:09:38.790 --> 00:09:42.060
In which we will use machine
learning techniques to

117
00:09:42.060 --> 00:09:46.840
apply to our five step data science
process and analyze big data.

118
00:09:48.570 --> 00:09:54.370
Just a simple Google search for
big data processing pipelines will bring

119
00:09:54.370 --> 00:09:58.950
a vast number of pipelines with
a large number of technologies

120
00:09:58.950 --> 00:10:03.520
that support scalable data cleaning,
preparation, and analysis.

121
00:10:05.080 --> 00:10:09.650
How do we make sense of all of it to
make sure we use the right tools for

122
00:10:09.650 --> 00:10:10.240
our application?

123
00:10:11.320 --> 00:10:14.580
How do we pick the right
pre-processing and

124
00:10:14.580 --> 00:10:17.780
machine learning techniques to
start doing predictive modeling?

125
00:10:19.450 --> 00:10:24.190
Over the next few weeks Dr.
Mei will walk you through some of the most

126
00:10:24.190 --> 00:10:29.515
fundamental machine learning techniques,
along with introductory hands

127
00:10:29.515 --> 00:10:35.102
on exercises we designed for you to ease
you into the world of machine learning.

128
00:10:35.102 --> 00:10:36.418
Let's get started.