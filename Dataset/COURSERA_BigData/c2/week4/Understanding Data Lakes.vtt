WEBVTT

1
00:00:01.000 --> 00:00:05.890
With big data streaming from different
sources in varying formats, models, and

2
00:00:05.890 --> 00:00:10.650
speeds it is no surprise that we
need to be able to ingest this data

3
00:00:10.650 --> 00:00:13.970
into a fast and scalable storage system

4
00:00:13.970 --> 00:00:18.900
that is flexible enough to serve many
current and future analytical processes.

5
00:00:20.410 --> 00:00:25.730
This is when traditional data warehouses
with strict data models and data

6
00:00:25.730 --> 00:00:31.160
formats don't fit the big data challenges
for streaming and batch applications.

7
00:00:32.760 --> 00:00:38.700
The concept of a data lake was created in
response of these data big storage and

8
00:00:38.700 --> 00:00:39.890
processing challenges.

9
00:00:41.140 --> 00:00:45.460
After this video you
will be able to describe

10
00:00:45.460 --> 00:00:48.880
how data lakes enable batch
processing of streaming data.

11
00:00:50.410 --> 00:00:55.390
Explain the difference between
schema on write and schema on read.

12
00:00:56.680 --> 00:01:00.320
Organize data streams and data lakes and

13
00:01:00.320 --> 00:01:04.720
data warehouses on a spectrum of
big data management and storage.

14
00:01:07.080 --> 00:01:08.080
What is a data lake?

15
00:01:09.140 --> 00:01:15.450
Simply speaking, a data lake is
a part of a big data infrastructure

16
00:01:15.450 --> 00:01:20.270
that many streams can flow into and

17
00:01:20.270 --> 00:01:23.680
get stored for
processing in their original form.

18
00:01:23.680 --> 00:01:28.140
We can think of it as a massive
storage depository with huge

19
00:01:28.140 --> 00:01:33.560
processing power and ability to handle
a very large number of concurrence,

20
00:01:33.560 --> 00:01:35.970
data management and analytical tasks.

21
00:01:37.370 --> 00:01:42.660
In 2010,
the Pentaho Corporation's CTO James Dixon

22
00:01:42.660 --> 00:01:44.510
defined a data link as follows.

23
00:01:45.930 --> 00:01:50.830
If you think of a datamart as a store
of bottled water, cleansed and

24
00:01:50.830 --> 00:01:54.090
packaged and structured for
easy consumption,

25
00:01:54.090 --> 00:01:59.320
the data lake is a large body of
water in a more natural state.

26
00:01:59.320 --> 00:02:04.940
The contents of the data lake stream
in from a source to fill the lake,

27
00:02:04.940 --> 00:02:11.980
and various users of the lake can come
to examine it, dive in, or take samples.

28
00:02:11.980 --> 00:02:14.000
A data lake works as follows.

29
00:02:15.140 --> 00:02:17.600
The data gets loaded from its source,

30
00:02:19.160 --> 00:02:22.140
stored in its native
format until it is needed

31
00:02:23.330 --> 00:02:28.240
at which time the applications can freely
read the data and add structure to it.

32
00:02:29.500 --> 00:02:33.250
This is what we call schema on read.

33
00:02:33.250 --> 00:02:38.070
In a traditional data warehouse,
the data is loaded into the warehouse

34
00:02:38.070 --> 00:02:42.670
after transforming it into a well
defined and structured format.

35
00:02:42.670 --> 00:02:45.398
This is what we call schema on write.

36
00:02:45.398 --> 00:02:51.078
Any application using the data needs to
know this format in order to retrieve and

37
00:02:51.078 --> 00:02:52.110
use the data.

38
00:02:53.330 --> 00:02:54.990
In this approach,

39
00:02:54.990 --> 00:02:58.882
data is not loaded into the warehouse
unless there is a use for it.

40
00:02:58.882 --> 00:03:04.030
However, schema on read
approach of data lakes ensures

41
00:03:04.030 --> 00:03:09.040
all data is stored for
a potentially unknown use at a later time.

42
00:03:09.040 --> 00:03:12.110
So how is a data lake
from a data warehouse?

43
00:03:13.540 --> 00:03:18.650
A traditional data warehouse
stores data in a hierarchical file

44
00:03:19.820 --> 00:03:22.973
system with a well-defined structure.

45
00:03:22.973 --> 00:03:29.590
However, a data lake stores data as
flat files with a unique identifier.

46
00:03:29.590 --> 00:03:33.550
This often gets referred to as
object storage in big data systems.

47
00:03:36.250 --> 00:03:42.330
In data lakes each data is stored
as a binary large object or

48
00:03:42.330 --> 00:03:45.460
BLOB and is assigned a unique identifier.

49
00:03:46.460 --> 00:03:53.620
In addition, each data object is
tagged with a number of metadata tags.

50
00:03:54.860 --> 00:03:58.230
The data can be searched
using these metadata tags

51
00:03:58.230 --> 00:04:00.400
to retrieve it when there
is a need to access it.

52
00:04:01.820 --> 00:04:03.405
From a users perspective,

53
00:04:03.405 --> 00:04:08.672
metadata is stored is not a problem as
long as it is accessible when needed.

54
00:04:08.672 --> 00:04:15.780
In Hadoop data architectures,
data is loaded into HDFS and processed

55
00:04:15.780 --> 00:04:20.410
using the appropriate data management and
analytical systems on commodity clusters.

56
00:04:21.860 --> 00:04:27.080
The selection of the tools is based on the
nature of the problem being solved, and

57
00:04:27.080 --> 00:04:28.540
the data format being accessed.

58
00:04:30.090 --> 00:04:32.920
We will talk more about
the processing of data streams and

59
00:04:32.920 --> 00:04:35.820
data lakes in the next course
in this specialization.

60
00:04:37.520 --> 00:04:43.250
To summarize a data lake is
a storage architecture for

61
00:04:43.250 --> 00:04:45.190
big data collection and processing.

62
00:04:46.670 --> 00:04:50.060
It enables collection of
all data suitable for

63
00:04:50.060 --> 00:04:53.060
analysis today and
potentially in the future.

64
00:04:54.410 --> 00:04:57.450
Regardless of the data source,
structure, and

65
00:04:57.450 --> 00:05:03.120
format it supports storage of data and
transforms it only when it is needed.

66
00:05:04.500 --> 00:05:09.940
A data lake ideally supports all parts
of the user base to benefit from

67
00:05:09.940 --> 00:05:15.790
this architecture, including business,
storage, analytics and computing experts.

68
00:05:17.240 --> 00:05:21.310
Finally, And perhaps most importantly,

69
00:05:21.310 --> 00:05:25.790
data lakes are infrastructure components
within a big data architecture

70
00:05:25.790 --> 00:05:29.980
that can evolve over time based
on application-specific needs.