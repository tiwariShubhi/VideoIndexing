WEBVTT

1
00:00:10.512 --> 00:00:14.240
Different data sources in the game
industry include using your finger.

2
00:00:14.240 --> 00:00:16.408
What type of device is coming from?

3
00:00:16.408 --> 00:00:18.600
The amount of headsets.

4
00:00:18.600 --> 00:00:19.953
It's pretty much infinite,

5
00:00:19.953 --> 00:00:22.720
as far as the number of ways we
can bring data in from the game.

6
00:00:22.720 --> 00:00:27.602
And it could be joystick or mouse,
keyboards, there's lots of ways

7
00:00:27.602 --> 00:00:31.726
as well as what happens inside
the game itself as far cars or

8
00:00:31.726 --> 00:00:35.537
the driving, tires,
flying machines, anything.

9
00:00:42.179 --> 00:00:45.479
The volume of data,
it really depends on the type of game and

10
00:00:45.479 --> 00:00:47.592
how often they want to send the data in.

11
00:00:47.592 --> 00:00:51.260
How many types of events they've tagged
and how many users are playing the game.

12
00:00:51.260 --> 00:00:54.891
So if you have a user, you've 5 million
users that are playing your game and

13
00:00:54.891 --> 00:00:57.844
you're tapping and
you're tracking each tap of the screen,

14
00:00:57.844 --> 00:01:00.963
of where they went or each click of
the mouse as they were using it,

15
00:01:00.963 --> 00:01:02.982
you're going to get
a lot of volume of data.

16
00:01:02.982 --> 00:01:07.854
And so
you need to be prepared to bring in a lot

17
00:01:07.854 --> 00:01:13.140
of different data very, very quickly.

18
00:01:13.140 --> 00:01:16.322
As far as the variety of data, it depends.

19
00:01:16.322 --> 00:01:18.520
You have round pizzas and
you have round tires.

20
00:01:18.520 --> 00:01:19.513
I mean, they're completely different.

21
00:01:19.513 --> 00:01:23.816
They're both round, but there's different
ways that you're going to want to know how

22
00:01:23.816 --> 00:01:27.104
many pepperoni are on one pizza and
how many lug nuts go on a tire.

23
00:01:27.104 --> 00:01:29.510
So the variety is really unlimited,
as well.

24
00:01:29.510 --> 00:01:31.122
It really just depends on each game.

25
00:01:31.122 --> 00:01:34.430
So, you have to be prepared to
bring in all kinds of data.

26
00:01:34.430 --> 00:01:38.851
Touch data, wheel data,
track speeds, anything.

27
00:01:38.851 --> 00:01:43.628
And if you put taxonomy together that
you can define as an example of verb,

28
00:01:43.628 --> 00:01:49.021
object, location, value and any number
of other sources, then you can basically

29
00:01:49.021 --> 00:01:54.290
track anything you want as long as they
all fall into the same kind of buckets.

30
00:01:54.290 --> 00:01:56.705
And the buckets can be different
sizes based on the type of events.

31
00:01:56.705 --> 00:01:59.804
They don't all need to be 4,
some can be 2, some can be 20,

32
00:01:59.804 --> 00:02:01.218
it doesn't really matter.

33
00:02:08.280 --> 00:02:12.384
The modeling challenge has really come
down to who designs the structure at which

34
00:02:12.384 --> 00:02:15.355
you store your data and
how you want to retrieve that data.

35
00:02:15.355 --> 00:02:19.488
Those kind of of storage and
retrieval models are very, very important,

36
00:02:19.488 --> 00:02:22.098
because what it really
comes down to is speed.

37
00:02:22.098 --> 00:02:25.119
You can record a lot of data and
it can take you five years to query it,

38
00:02:25.119 --> 00:02:26.710
it doesn't really do you any good.

39
00:02:26.710 --> 00:02:31.347
So you need to make sure you plan for
reporting speed, because that's ultimately

40
00:02:31.347 --> 00:02:35.865
what within the organisation needs is
the ability to report on it very quickly.

41
00:02:35.865 --> 00:02:40.781
The management challenges really come
down to trying to figure out what data to

42
00:02:40.781 --> 00:02:41.306
store.

43
00:02:41.306 --> 00:02:44.657
A lot of times we go into various
companies and you've got producers sitting

44
00:02:44.657 --> 00:02:47.810
across the hall from designers, and
they don't even know each other.

45
00:02:47.810 --> 00:02:50.823
They don't realize what they want and
the programmer says,

46
00:02:50.823 --> 00:02:54.606
I'm going to put these events in and the
product manager who wants to figure out

47
00:02:54.606 --> 00:02:58.118
how many times somebody crashed says,
well, I need these events in.

48
00:02:58.118 --> 00:03:02.436
So unless they're communicating, you're
going to get the wrong type of data.

49
00:03:02.436 --> 00:03:06.241
So the management challenge is trying
to make sure everybody communicates,

50
00:03:06.241 --> 00:03:08.639
they decide on the taxonomy and
the structure and

51
00:03:08.639 --> 00:03:12.350
then we can go forward with tagging and
getting in the entire game working.

52
00:03:18.226 --> 00:03:20.469
We process, stayed in two main ways.

53
00:03:20.469 --> 00:03:22.107
One is streaming data.

54
00:03:22.107 --> 00:03:24.667
One is batched or scheduled data.

55
00:03:24.667 --> 00:03:28.653
Streaming data has scripts that run
instantly the minute the data arrives.

56
00:03:28.653 --> 00:03:31.222
And so as the data come in,
it gets processed and

57
00:03:31.222 --> 00:03:33.160
then stored In a reporting format.

58
00:03:33.160 --> 00:03:39.347
So they can easily generate reports
up to the second very, very quickly.

59
00:03:39.347 --> 00:03:42.671
Batch processing data really depends on
the type of data where it's coming from.

60
00:03:42.671 --> 00:03:46.689
Most of the time when we download
data from iTunes or YouTube or

61
00:03:46.689 --> 00:03:50.885
something like that, it comes in a CSV or
a very similar format.

62
00:03:50.885 --> 00:03:53.038
There's not really a lot of
processing we need to do.

63
00:03:53.038 --> 00:03:55.451
It's more of ingesting that data.

64
00:03:55.451 --> 00:03:59.788
There are processes we need to run
with some type of batch data, but

65
00:03:59.788 --> 00:04:03.040
most of the batch data we
receive comes in as a CSV or

66
00:04:03.040 --> 00:04:05.914
other similar already processed formats.

67
00:04:05.914 --> 00:04:10.228
So typically, while you can do processing
in both modes most processing typically

68
00:04:10.228 --> 00:04:14.497
happens with the streaming real-time data
than it does with offline batch data.

69
00:04:20.394 --> 00:04:26.260
We actually didn't use any
technology in the a big data space.

70
00:04:26.260 --> 00:04:28.684
We created our own, from scratch.

71
00:04:28.684 --> 00:04:32.280
What we did was we decided
what kind of model we wanted.

72
00:04:32.280 --> 00:04:33.475
How we were going to store data?

73
00:04:33.475 --> 00:04:35.112
How we were going to retrieve data?

74
00:04:35.112 --> 00:04:37.574
And ultimately,
how we were going to reduce the data?

75
00:04:37.574 --> 00:04:40.772
Because the more and more and more data
you have, the slower it is to actually do

76
00:04:40.772 --> 00:04:43.692
a query, because you have to look through
all the different pieces of data.

77
00:04:43.692 --> 00:04:47.148
A lot of databases solve this problem for
you, but they were really doing it in more

78
00:04:47.148 --> 00:04:50.170
generic way were we needed
something very specific.

79
00:04:50.170 --> 00:04:55.020
So we started from scratch building our
own data storage and retrieval, and

80
00:04:55.020 --> 00:04:57.003
reporting from the ground up.

81
00:04:57.003 --> 00:05:01.097
When it came to scalability,
it was really about designing the parts of

82
00:05:01.097 --> 00:05:03.906
the system that could be
independently scaled.

83
00:05:03.906 --> 00:05:07.773
So if data's coming in in real-time,
we send that into what we call a gateway.

84
00:05:07.773 --> 00:05:10.155
And the gateway could be three gateways,
let's say.

85
00:05:10.155 --> 00:05:11.922
But if the data starts
getting over loaded,

86
00:05:11.922 --> 00:05:13.362
I just have to add another gateway.

87
00:05:13.362 --> 00:05:16.383
And a gateway is just this little
light layer that just receives data,

88
00:05:16.383 --> 00:05:19.605
passes it on and goes back to it's job,
doesn't do anything else.

89
00:05:19.605 --> 00:05:22.296
So it can receive a lot
of data very quickly, but

90
00:05:22.296 --> 00:05:24.124
also I can just add another one.

91
00:05:24.124 --> 00:05:27.309
And it just automatically logs in and
adds itself to a list and

92
00:05:27.309 --> 00:05:30.813
now the data is being distributed
amongst four gateways instead.

93
00:05:30.813 --> 00:05:32.043
Query engine is the same way.

94
00:05:32.043 --> 00:05:34.720
When you're doing queries to try
to get data out of the system, so

95
00:05:34.720 --> 00:05:35.704
you can build reports.

96
00:05:35.704 --> 00:05:39.151
If I need more query engines,
because people are doing more reporting,

97
00:05:39.151 --> 00:05:40.733
we can add more query engines.

98
00:05:40.733 --> 00:05:44.722
So, the idea behind scalability is
trying to break the services up into

99
00:05:44.722 --> 00:05:47.390
the type of services that
they most make sense.

100
00:05:47.390 --> 00:05:48.466
So that if you need to,

101
00:05:48.466 --> 00:05:51.820
you can add just the service without
rebuilding the entire platform.

102
00:05:58.367 --> 00:06:01.825
My advice for people designing systems for
big data is to first,

103
00:06:01.825 --> 00:06:04.398
try to understand what
you want to accomplish.

104
00:06:04.398 --> 00:06:05.763
What's the goal?

105
00:06:05.763 --> 00:06:08.695
I mean, we're going to ingest everything
and we're going to report on everything.

106
00:06:08.695 --> 00:06:15.518
It's not really something that you can
achieve without some special thought.

107
00:06:15.518 --> 00:06:18.790
If you're going to focus on,
your area's going to be say gardening,

108
00:06:18.790 --> 00:06:22.419
then look at what kind of things you're
going to do in the gardening area and

109
00:06:22.419 --> 00:06:24.880
try to focus on what that
type of data is going to be.

110
00:06:24.880 --> 00:06:27.722
This isn't going to restrict you
to only being a gardener, but

111
00:06:27.722 --> 00:06:30.507
it is going to give you focus
on how to design your system, so

112
00:06:30.507 --> 00:06:32.701
that they're actually going to work for
you.

113
00:06:32.701 --> 00:06:36.912
You're going to continually evolve your
systems, add more things to them and

114
00:06:36.912 --> 00:06:37.580
grow them.

115
00:06:37.580 --> 00:06:40.804
I wouldn't suggest starting with
an unlimited variety of options and

116
00:06:40.804 --> 00:06:42.944
hoping you're going to
solve all the problems.

117
00:06:42.944 --> 00:06:49.185
Start with the goal of what your current
solution is and expand from there.

118
00:06:55.600 --> 00:06:58.971
Data can be fun, but
it can also be overwhelming.

119
00:06:58.971 --> 00:07:04.051
So, try to keep the data in mind
without keeping the world in mind and

120
00:07:04.051 --> 00:07:06.291
I think you'll be just fine.